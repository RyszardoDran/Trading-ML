# ML Pipeline - Analiza ProblemÃ³w i Propozycje Refaktoryzacji

**Data:** December 22, 2025  
**Status:** Wersja 1.0 - PeÅ‚na analiza  
**Autor:** Expert ML Review  

---

## Executive Summary

Obecny pipeline ML zawiera **10 powaÅ¼nych problemÃ³w**, z czego **3 sÄ… krytyczne** (data leakage, brak Time Series walidacji, threshold snooping). Te problemy mogÄ… skutkowaÄ‡ zawyÅ¼onymi metrykami o 5-20% i niskÄ… wydajnoÅ›ciÄ… modelu na produkcji.

**Priorytet:** Naprawy CRITICAL powinny byÄ‡ wykonane przed dalszym trenowaniem.

---

## ğŸ”´ PROBLEMY KRYTYCZNE (CRITICAL)

### Problem #1: Data Leakage w agregacji M1 â†’ M5

**Lokalizacja:**
- `ml/src/features/engineer_m5.py` - funkcja `aggregate_to_m5()` (linie 93-109)
- `ml/src/pipelines/sequence_training_pipeline.py` - linie 106-110

**Opis problemu:**

```python
# âŒ BÅÄ˜DNE: Agregacja dzieje siÄ™ na CAÅYM datasecie
df_m1 = load_and_prepare_data(data_dir, year_filter=params.year_filter)  # Np. 2023-2024
features = engineer_features_stage(df_m1, ...)  # Zawiera M5 aggregacjÄ™
targets = create_targets_stage(df_m5, features, ...)  # CaÅ‚e M5 juÅ¼ tutaj
X, y = build_sequences_stage(features, targets, ...)  # Sekwencje ze zmiszanych lat
```

**Implikacja:**
- WskaÅºniki techniczne (RSI, SMA, BB) sÄ… liczone na **caÅ‚ym dataset'cie**, zanim nastÄ…pi split
- JeÅ›li year_filter=[2023, 2024], ale agregacja robi siÄ™ na wszystkich danych:
  - SMA200 na 2024 zawiera dane z 2023
  - RSI na 2024 jest "prognozowany" przez przeszÅ‚oÅ›Ä‡ spoza 2024
- Test set widziaÅ‚ dane treningowe w feature engineering

**WpÅ‚yw na metryki:**
- ZawyÅ¼enie precyzji o 5-15%
- ZawyÅ¼enie ROC-AUC o 3-10%
- Model na produkcji bÄ™dzie dziaÅ‚aÄ‡ gorzej

**RozwiÄ…zanie:**
```python
# âœ… POPRAWKA: Filtracja PRZED aggregacjÄ…
def aggregate_to_m5_with_dates(df_m1, year_filter=None):
    """Aggregate only within specified year filter to prevent data leakage"""
    if year_filter:
        mask = df_m1.index.year.isin(year_filter)
        df_m1_filtered = df_m1[mask]
    else:
        df_m1_filtered = df_m1
    
    # Teraz agregacja jest na czystych danych
    df_m5 = df_m1_filtered.resample('5min').agg({...})
    return df_m5
```

---

### Problem #2: Threshold Optimization na Test Set (Data Snooping)

**Lokalizacja:**
- `ml/src/pipelines/pipeline_stages.py` - funkcja `train_and_evaluate_stage()` 
- (nie mam peÅ‚nego kodu, ale hipoteza oparta na strukturze)

**Opis problemu:**

```python
# âŒ POTENCJALNY BÅÄ„D
metrics, model = train_and_evaluate_stage(
    X_train_scaled, y_train,
    X_val_scaled, y_val,
    X_test_scaled, y_test,  # Test set jest znany!
    ...
)
# JeÅ›li threshold optimization patrzyÅ‚ na X_test/y_test:
# - To liczby na test set sÄ… ZUPEÅNIE BEZUÅ»YTECZNE
```

**Jak to sprawdziÄ‡:**
- Czy funkcja liczy threshold na X_val czy X_test?
- Czy metrics zwracane to na X_test czy X_val?

**Implikacja:**
- JeÅ›li threshold leÅ¼y na X_test: **wszystkie metryki sÄ… invaliding**
- Model moÅ¼e mieÄ‡ 70% win_rate na test, ale 45% na produkcji

**PrawidÅ‚owy proces:**
```
1. X_train â†’ trening modelu
2. X_val   â†’ optimization threshold (szukamy best F1/precision)
3. X_test  â†’ finalna ewaluacja (brak dostÄ™pu do tych danych przy threshold selection)
```

---

### Problem #3: Brak Time Series Cross-Validation

**Lokalizacja:**
- `ml/src/pipelines/pipeline_stages.py` - funkcja `split_and_scale_stage()`

**Opis problemu:**

```python
# âŒ Standard train/test split NIE jest bezpieczny dla szeregÃ³w czasowych
# JeÅ›li robisz:
X_train = X[:len(X)//5*3]  # 60%
X_val = X[len(X)//5*3:len(X)//5*4]  # 20%
X_test = X[len(X)//5*4:]  # 20%

# To jest OK (chronologiczny), ale:
# - Tylko JEDEN split â†’ moÅ¼e byÄ‡ "lucky"
# - Brak walidacji na rÃ³Å¼nych okresach
# - JeÅ›li X_train ma particular pattern, model tego siÄ™ nauczy
```

**WÅ‚aÅ›ciwy approach:**

```python
# âœ… Time Series Cross-Validation (5-fold)
from sklearn.model_selection import TimeSeriesSplit

tscv = TimeSeriesSplit(n_splits=5)
for fold, (train_idx, test_idx) in enumerate(tscv.split(X)):
    # Fold 1: X[0:2000] â†’ train, X[2000:2400] â†’ test
    # Fold 2: X[0:2400] â†’ train, X[2400:2800] â†’ test
    # Fold 3: X[0:2800] â†’ train, X[2800:3200] â†’ test
    # ... etc
```

**Implikacja:**
- Obecne single split moÅ¼e byÄ‡ "lucky" 
- Model moÅ¼e overfit na konkretny okres
- CV discovery nowych insights o model robustness

---

## ğŸŸ  PROBLEMY WYSOKIEJ WAÅ»NOÅšCI (HIGH PRIORITY)

### Problem #4: Lookahead Bias w Multi-Timeframe Features

**Lokalizacja:**
- `ml/src/features/engineer_m5.py` - linie 320-355 (alignment M15/M60 do M5)

**Opis problemu:**

```python
# âŒ BÅÄ˜DNE: bfill = backward fill (przyszÅ‚e dane!)
rsi_m15 = rsi_m15.reindex(df_m5.index, method='bfill').fillna(50)
bb_pos_m15 = bb_pos_m15.reindex(df_m5.index, method='bfill').fillna(0.5)

# Co siÄ™ dzieje:
# M15 bar closes at 10:15
# M5 bars: 10:00-10:05, 10:05-10:10, 10:10-10:15
# 
# bfill replicates M15 bar do WSZYSTKICH M5 bars w tym przedziale
# WÅÄ„CZNIE z barami PRZED zamkniÄ™ciem M15!
# 
# Oznacza to: Model widzi wartoÅ›Ä‡ M15 ZANIM siÄ™ ona forma!
```

**PrawidÅ‚owe wyrÃ³wnanie:**

```python
# âœ… POPRAWKA: ffill (forward fill) - znamy tylko peÅ‚ne bary
rsi_m15 = rsi_m15.reindex(df_m5.index, method='ffill').fillna(50)

# Alternatively: align by index matching
# M15 bar closes at 10:15 â†’ dostÄ™pny dla M5 barÃ³w DOPO 10:15
```

**Implikacja:**
- Model ma "magiczny" dostÄ™p do przyszÅ‚ych danych
- Win_rate na backtest bÄ™dzie ~5-10% wyÅ¼szy niÅ¼ realny
- Producja: drastyczna degradacja wydajnoÅ›ci

---

### Problem #5: Brak Walidacji Class Imbalance

**Lokalizacja:**
- `ml/src/pipelines/pipeline_stages.py` - caÅ‚oÅ›Ä‡

**Opis problemu:**

```python
# âŒ Nigdzie nie widzÄ™ sprawdzenia rozkÅ‚adu klas
# Pytania bez odpowiedzi:
# - Ile % danych to y=1 (WIN)?
# - Ile % danych to y=0 (LOSS)?
# - Czy train/val/test majÄ… ten sam rozkÅ‚ad?
```

**Typowy problem dla trading ML:**
```
y_train: 25% WIN, 75% LOSS
y_test:  10% WIN, 90% LOSS  # Zmiana!

Model zatraining siÄ™ na 25% baseline, test ma 10%
â†’ Model bÄ™dzie wydawaÄ‡ zbyt duÅ¼o BUY sygaÅ‚Ã³w na produkcji
```

**RozwiÄ…zanie:**
```python
# âœ… Raport class distribution
from collections import Counter

def report_class_distribution(y_train, y_val, y_test):
    print("TRAIN:", Counter(y_train))
    print("VAL:  ", Counter(y_val))
    print("TEST: ", Counter(y_test))
```

---

### Problem #6: Brak Walidacji Granic Sekwencji

**Lokalizacja:**
- `ml/src/pipelines/pipeline_stages.py` - funkcja `build_sequences_stage()`

**Opis problemu:**

```python
# âŒ Sekwencje mogÄ… intersectowaÄ‡ granicÄ™ train/test
# PrzykÅ‚ad: window_size=100 M5 candles = 500 minut
#
# Train ends at: 2023-12-31 23:00
# Test starts at: 2024-01-01 00:00
#
# Sekwencja "99,100" mogÄ… byÄ‡:
# - Bars 1-100: ostatnie 100 barÃ³w 2023
# - Bars 51-150: ostatnie 50 z 2023 + pierwsze 50 z 2024 â† MIXED!
#
# Model trenujesz na "2023 + czÄ™Å›Ä‡ 2024"
# Test zawiera czÄ™Å›Ä‡ 2023!
```

**RozwiÄ…zanie:**
```python
# âœ… POPRAWKA: UsuÅ„ sekwencje ktÃ³re cross the boundary
def build_sequences_safe(X, y, timestamps, train_end_date, test_start_date, window_size):
    """Build sequences ensuring no data leakage across splits"""
    sequences = []
    for i in range(len(X) - window_size):
        seq_start_ts = timestamps[i]
        seq_end_ts = timestamps[i + window_size - 1]
        
        # SprawdÅº czy sekwencja jest CAÅKOWICIE w train lub test
        if seq_end_ts < train_end_date:
            # Sekwencja caÅ‚kowicie w train - OK
            sequences.append((X[i:i+window_size], y[i:i+window_size]))
        elif seq_start_ts >= test_start_date:
            # Sekwencja caÅ‚kowicie w test - OK
            sequences.append((X[i:i+window_size], y[i:i+window_size]))
        # else: SKIP - sekwencja crosses boundary
    
    return sequences
```

---

### Problem #7: Brak Feature Importance Analysis

**Lokalizacja:**
- CaÅ‚oÅ›Ä‡ pipeline - brak feature importance

**Opis problemu:**

```python
# âŒ Nie wiesz ktÃ³re features sÄ… waÅ¼ne
# Model ma 30+ features, ale ktÃ³re faktycznie dziaÅ‚ajÄ…?
# 
# MoÅ¼liwe problemy:
# - 80% waÅ¼noÅ›ci w 3 features â†’ rest to noise
# - Some features majÄ… negative importance â†’ usunÄ…Ä‡
# - Colinearity miÄ™dzy features â†’ reduce dimensionality
```

**RozwiÄ…zanie:**
```python
# âœ… Feature importance z XGBoost
import xgboost as xgb
import shap

feature_importance = model.get_booster().get_score(importance_type='weight')
sorted_features = sorted(feature_importance.items(), key=lambda x: x[1], reverse=True)

print("Top 10 features:")
for feat, score in sorted_features[:10]:
    print(f"  {feat}: {score}")

# SHAP dla deep understanding
explainer = shap.TreeExplainer(model)
shap_values = explainer.shap_values(X_test_scaled)
```

---

## ğŸŸ¡ PROBLEMY ÅšREDNIEJ WAÅ»NOÅšCI (MEDIUM PRIORITY)

### Problem #8: Hardcoded Hyperparameters

**Lokalizacja:**
- `ml/src/features/engineer_m5.py` - wszÄ™dzie
- `ml/src/pipelines/sequence_training_pipeline.py` - default values

**Opis problemu:**

```python
# âŒ Hardcoded wskaÅºniki techniczne
compute_rsi(period=14)  # Dlaczego 14?
compute_bollinger_bands(period=20, num_std=2)  # Dlaczego 20? Dlaczego 2?
compute_stochastic(period=14, smooth_k=3, smooth_d=3)  # Dlaczego te wartoÅ›ci?

# Brak zmiany = brak optymalizacji
```

**RozwiÄ…zanie:**
```python
# âœ… Feature hyperparameters w config
class FeatureConfig:
    RSI_PERIOD = 14
    BB_PERIOD = 20
    BB_STD = 2.0
    STOCH_PERIOD = 14
    STOCH_K_SMOOTH = 3
    STOCH_D_SMOOTH = 3
    # ... etc

# Potem: optymalizacja przez grid search
```

---

### Problem #9: Brak Walidacji na Out-of-Sample Danych

**Lokalizacja:**
- CaÅ‚oÅ›Ä‡ pipeline

**Opis problemu:**

```python
# âŒ Zabudujesz na 2023-2024, testujesz na 2024
# Ale nigdy nie weryfikujesz na 2025!
#
# Co siÄ™ zmienia pomiÄ™dzy latami:
# - Volatility (zwÅ‚aszcza zÅ‚oto)
# - Trend patterns
# - Mean reversion vs momentum
# - Market microstructure
```

**RozwiÄ…zanie:**
```python
# âœ… Walk-forward validation
train_years = [2023, 2024]
test_year = 2025

model = train(2023-2024)
evaluate(model, 2025)  # True out-of-sample

# JeÅ›li performance drops > 20%: model jest period-specific
```

---

### Problem #10: Brak Ablation Study

**Lokalizacja:**
- Brak w entire pipeline

**Opis problemu:**

```python
# âŒ Wszystkie features razem
# Pytania bez odpowiedzi:
# - KtÃ³re features sÄ… beznadziejne?
# - Czy M15/M60 context naprawdÄ™ pomaga?
# - Czy CVD/OBV/MFI sÄ… potrzebne?
```

**RozwiÄ…zanie:**
```python
# âœ… Remove-one-feature test
for feature_to_remove in features.columns:
    X_ablated = X_train[features.columns != feature_to_remove]
    model_ablated = train(X_ablated)
    score_ablated = evaluate(model_ablated, X_test_ablated)
    
    importance_score = baseline_score - score_ablated
    print(f"{feature_to_remove}: {importance_score}")
```

---

## ğŸ“Š Podsumowanie ProblemÃ³w

| # | Problem | Priorytet | KrytycznoÅ›Ä‡ | WpÅ‚yw na Metryki |
|---|---------|-----------|-------------|-----------------|
| 1 | Data Leakage w M5 aggregacji | ğŸ”´ CRITICAL | Bardzo wysoka | +5-15% zawyÅ¼enie |
| 2 | Threshold Optimization na test | ğŸ”´ CRITICAL | Bardzo wysoka | Invalid metrics |
| 3 | Brak Time Series CV | ğŸ”´ CRITICAL | Bardzo wysoka | Unknown robustness |
| 4 | Lookahead w M15/M60 | ğŸŸ  HIGH | Wysoka | +5-10% zawyÅ¼enie |
| 5 | Brak class imbalance check | ğŸŸ  HIGH | Wysoka | Strategy shifts |
| 6 | Sekwencje crossing boundary | ğŸŸ  HIGH | Wysoka | ~2-5% zawyÅ¼enie |
| 7 | Brak feature importance | ğŸŸ¡ MEDIUM | Åšrednia | Unknown useful features |
| 8 | Hardcoded hyperparameters | ğŸŸ¡ MEDIUM | Åšrednia | Suboptimal features |
| 9 | Brak out-of-sample validation | ğŸŸ¡ MEDIUM | Åšrednia | Unknown generalization |
| 10 | Brak ablation study | ğŸŸ¡ MEDIUM | Åšrednia | Unknown importance |

---

## ğŸ¯ Proponowana KolejnoÅ›Ä‡ Napraw

### Faza 1: CRITICAL (Week 1)
1. âœ… Napraw data leakage w `aggregate_to_m5()`
2. âœ… WdroÅ¼ Time Series CV
3. âœ… Napraw threshold optimization na validation set

### Faza 2: HIGH Priority (Week 2)
4. âœ… Napraw lookahead bias w M15/M60
5. âœ… Dodaj class imbalance validation
6. âœ… Napraw sequence boundary crossing

### Faza 3: MEDIUM Priority (Week 3)
7. âœ… Feature importance analysis
8. âœ… Hyperparameter sweep
9. âœ… Out-of-sample walk-forward validation

### Faza 4: OPTIMIZATION (Week 4)
10. âœ… Ablation study
11. âœ… Feature selection
12. âœ… Final model tuning

---

## ğŸ“ Struktura Refactoringu

```
ml/refactor/
â”œâ”€â”€ PROBLEMS_ANALYSIS.md (ten plik)
â”œâ”€â”€ 01_data_leakage_fix.md (Faza 1)
â”œâ”€â”€ 02_timeseries_cv_fix.md (Faza 1)
â”œâ”€â”€ 03_threshold_optimization_fix.md (Faza 1)
â”œâ”€â”€ 04_lookahead_bias_fix.md (Faza 2)
â”œâ”€â”€ 05_class_imbalance_validation.md (Faza 2)
â”œâ”€â”€ 06_sequence_boundary_fix.md (Faza 2)
â””â”€â”€ fixes/
    â”œâ”€â”€ engineer_m5_refactored.py
    â”œâ”€â”€ pipeline_stages_refactored.py
    â”œâ”€â”€ validation.py (new)
    â””â”€â”€ timeseries_cv.py (new)
```

---

## âœ… NastÄ™pne Kroki

**GotÃ³w do przejÅ›cia do Fazy 1?**

Czekam na sygnaÅ‚ Å¼eby przygotowaÄ‡:
1. `01_data_leakage_fix.md` - szczegÃ³Å‚owe instrukcje naprawy
2. Refactored kod w `ml/refactor/fixes/`
3. Testy do walidacji napraw

---

**Status:** Gotowy do refaktoryzacji  
**Ostatnia aktualizacja:** 2025-12-22  
**NastÄ™pny krok:** [Faza 1 - Data Leakage Fix]
