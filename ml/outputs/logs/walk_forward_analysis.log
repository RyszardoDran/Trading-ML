2025-12-21 01:42:41,270 - __main__ - INFO - 
================================================================================
2025-12-21 01:42:41,277 - __main__ - INFO - WALK-FORWARD VALIDATION ANALYSIS
2025-12-21 01:42:41,278 - __main__ - INFO - ================================================================================
2025-12-21 01:42:41,278 - __main__ - INFO - Years: 2025
2025-12-21 01:42:41,278 - __main__ - INFO - Train window: 300 samples (~1500 minutes)
2025-12-21 01:42:41,279 - __main__ - INFO - Test window: 80 samples (~400 minutes)
2025-12-21 01:42:41,279 - __main__ - INFO - Step size: 40 samples (~200 minutes)
2025-12-21 01:42:41,287 - __main__ - INFO - ================================================================================

2025-12-21 01:42:41,287 - __main__ - INFO - Loading data...
2025-12-21 01:42:41,289 - ml.src.data_loading.loaders - INFO - Year filter applied: loading only [2025]
2025-12-21 01:42:41,350 - __main__ - INFO - Loaded 18,875 M1 candles
2025-12-21 01:42:41,351 - __main__ - INFO - Aggregating to M5...
2025-12-21 01:42:41,351 - ml.src.features.engineer_m5 - INFO - Aggregating 18875 M1 candles to M5...
2025-12-21 01:42:41,359 - ml.src.features.engineer_m5 - INFO - Aggregated to 3776 M5 candles (5.0x compression)
2025-12-21 01:42:41,360 - __main__ - INFO - Aggregated to 3,776 M5 candles
2025-12-21 01:42:41,360 - __main__ - INFO - Engineering features...
2025-12-21 01:42:41,360 - ml.src.features.engineer_m5 - INFO - Engineering M5 features...
2025-12-21 01:42:41,360 - ml.src.features.engineer_m5 - INFO - Aggregating 3776 M1 candles to M5...
2025-12-21 01:42:41,370 - ml.src.features.engineer_m5 - INFO - Aggregated to 3776 M5 candles (1.0x compression)
2025-12-21 01:42:41,373 - ml.src.features.engineer_m5 - INFO - Computing M5 primary features...
2025-12-21 01:42:41,653 - ml.src.features.engineer_m5 - INFO - Computing M15 context from M5...
2025-12-21 01:42:41,753 - ml.src.features.engineer_m5 - INFO - Computing M60 context from M5...
2025-12-21 01:42:41,792 - ml.src.features.engineer_m5 - INFO - M5 feature engineering complete: 3776 rows × 24 features
2025-12-21 01:42:41,792 - ml.src.features.engineer_m5 - INFO - Timeframe: M5 (5-minute candles)
2025-12-21 01:42:41,792 - ml.src.features.engineer_m5 - INFO - Date range: 2025-12-01 00:00:00 to 2025-12-18 17:35:00
2025-12-21 01:42:41,793 - __main__ - INFO - Engineered 24 features
2025-12-21 01:42:41,793 - __main__ - INFO - Creating targets...
2025-12-21 01:42:41,794 - ml.src.targets.target_maker - INFO - Creating targets (SL/TP simulation) for 3,776 candles...
2025-12-21 01:42:41,794 - ml.src.targets.target_maker - INFO - Parameters: SL=1×ATR, TP=3.0×ATR, min_hold=2min, max_horizon=60min
2025-12-21 01:42:41,794 - ml.src.targets.target_maker - INFO - Calculating M1 ATR(14) for SL/TP targets (fallback)
2025-12-21 01:42:41,801 - ml.src.targets.target_maker - INFO - Target creation complete: 3,716 valid targets
2025-12-21 01:42:41,802 - __main__ - INFO - Created targets: 871 positive, 2,845 negative
2025-12-21 01:42:41,803 - __main__ - INFO - Building sequences...
2025-12-21 01:42:41,803 - __main__ - ERROR - ERROR: SequenceFilterConfig.__init__() got an unexpected keyword argument 'session'
Traceback (most recent call last):
  File "C:\Users\Arek\Documents\Repos\Traiding\Trading-ML\ml\scripts\walk_forward_analysis.py", line 137, in main
    filter_config=SequenceFilterConfig(
                  ~~~~~~~~~~~~~~~~~~~~^
        enable_trend_filter=True,
        ^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<5 lines>...
        max_windows=200000,
        ^^^^^^^^^^^^^^^^^^^
    ),
    ^
TypeError: SequenceFilterConfig.__init__() got an unexpected keyword argument 'session'
2025-12-21 01:44:18,601 - __main__ - INFO - 
================================================================================
2025-12-21 01:44:18,602 - __main__ - INFO - WALK-FORWARD VALIDATION ANALYSIS
2025-12-21 01:44:18,602 - __main__ - INFO - ================================================================================
2025-12-21 01:44:18,602 - __main__ - INFO - Years: 2025
2025-12-21 01:44:18,602 - __main__ - INFO - Train window: 300 samples (~1500 minutes)
2025-12-21 01:44:18,603 - __main__ - INFO - Test window: 80 samples (~400 minutes)
2025-12-21 01:44:18,603 - __main__ - INFO - Step size: 40 samples (~200 minutes)
2025-12-21 01:44:18,603 - __main__ - INFO - ================================================================================

2025-12-21 01:44:18,603 - __main__ - INFO - Loading data...
2025-12-21 01:44:18,605 - ml.src.data_loading.loaders - INFO - Year filter applied: loading only [2025]
2025-12-21 01:44:18,655 - __main__ - INFO - Loaded 18,875 M1 candles
2025-12-21 01:44:18,655 - __main__ - INFO - Aggregating to M5...
2025-12-21 01:44:18,656 - ml.src.features.engineer_m5 - INFO - Aggregating 18875 M1 candles to M5...
2025-12-21 01:44:18,665 - ml.src.features.engineer_m5 - INFO - Aggregated to 3776 M5 candles (5.0x compression)
2025-12-21 01:44:18,665 - __main__ - INFO - Aggregated to 3,776 M5 candles
2025-12-21 01:44:18,666 - __main__ - INFO - Engineering features...
2025-12-21 01:44:18,666 - ml.src.features.engineer_m5 - INFO - Engineering M5 features...
2025-12-21 01:44:18,666 - ml.src.features.engineer_m5 - INFO - Aggregating 3776 M1 candles to M5...
2025-12-21 01:44:18,671 - ml.src.features.engineer_m5 - INFO - Aggregated to 3776 M5 candles (1.0x compression)
2025-12-21 01:44:18,675 - ml.src.features.engineer_m5 - INFO - Computing M5 primary features...
2025-12-21 01:44:18,920 - ml.src.features.engineer_m5 - INFO - Computing M15 context from M5...
2025-12-21 01:44:19,016 - ml.src.features.engineer_m5 - INFO - Computing M60 context from M5...
2025-12-21 01:44:19,055 - ml.src.features.engineer_m5 - INFO - M5 feature engineering complete: 3776 rows × 24 features
2025-12-21 01:44:19,055 - ml.src.features.engineer_m5 - INFO - Timeframe: M5 (5-minute candles)
2025-12-21 01:44:19,055 - ml.src.features.engineer_m5 - INFO - Date range: 2025-12-01 00:00:00 to 2025-12-18 17:35:00
2025-12-21 01:44:19,056 - __main__ - INFO - Engineered 24 features
2025-12-21 01:44:19,056 - __main__ - INFO - Creating targets...
2025-12-21 01:44:19,057 - ml.src.targets.target_maker - INFO - Creating targets (SL/TP simulation) for 3,776 candles...
2025-12-21 01:44:19,057 - ml.src.targets.target_maker - INFO - Parameters: SL=1×ATR, TP=3.0×ATR, min_hold=2min, max_horizon=60min
2025-12-21 01:44:19,058 - ml.src.targets.target_maker - INFO - Calculating M1 ATR(14) for SL/TP targets (fallback)
2025-12-21 01:44:19,065 - ml.src.targets.target_maker - INFO - Target creation complete: 3,716 valid targets
2025-12-21 01:44:19,065 - __main__ - INFO - Created targets: 871 positive, 2,845 negative
2025-12-21 01:44:19,066 - __main__ - INFO - Building sequences...
2025-12-21 01:44:19,069 - ml.src.sequences.sequencer - INFO - M5 alignment filter disabled; keeping all timestamps irrespective of minute alignment
2025-12-21 01:44:19,069 - ml.src.sequences.sequencer - INFO - Applied Trend Filter (dist_sma_200 > 0.00, ADX > 15.00): kept 1711/3667 (46.7%)
2025-12-21 01:44:19,069 - ml.src.sequences.sequencer - INFO - Pullback filter disabled; not constraining RSI_M5
2025-12-21 01:44:19,070 - ml.src.sequences.sequencer - INFO - Session filter 'london_ny': keeping 1,039 / 3,667 windows (28.3%)
2025-12-21 01:44:19,071 - __main__ - INFO - Built 1,039 sequences
2025-12-21 01:44:19,072 - ml.src.pipelines.walk_forward_validation - INFO - 
================================================================================
2025-12-21 01:44:19,072 - ml.src.pipelines.walk_forward_validation - INFO - [POINT 6] WALK-FORWARD CROSS-VALIDATION - Time-Series Validation
2025-12-21 01:44:19,072 - ml.src.pipelines.walk_forward_validation - INFO - ================================================================================
2025-12-21 01:44:19,073 - ml.src.pipelines.walk_forward_validation - INFO - Data size: 1,039 samples (1039 timestamps)
2025-12-21 01:44:19,073 - ml.src.pipelines.walk_forward_validation - INFO - Train window: 300 samples (~1500 minutes)
2025-12-21 01:44:19,074 - ml.src.pipelines.walk_forward_validation - INFO - Test window: 80 samples (~400 minutes)
2025-12-21 01:44:19,075 - ml.src.pipelines.walk_forward_validation - INFO - Step size: 40 samples (~200 minutes)
2025-12-21 01:44:19,076 - ml.src.pipelines.walk_forward_validation - INFO - No lookahead bias: test set is ALWAYS future relative to training set
2025-12-21 01:44:19,076 - ml.src.pipelines.walk_forward_validation - INFO - ================================================================================

2025-12-21 01:44:19,076 - ml.src.pipelines.walk_forward_validation - INFO - Fold 1:
2025-12-21 01:44:19,076 - ml.src.pipelines.walk_forward_validation - INFO -   Train: [0:300] = 300 samples
2025-12-21 01:44:19,085 - ml.src.pipelines.walk_forward_validation - INFO -   Test:  [300:380] = 80 samples
2025-12-21 01:44:19,271 - ml.src.training.sequence_xgb_trainer - INFO - Class balance (train): pos=48, neg=252, imbalance_ratio=5.25
2025-12-21 01:44:19,272 - ml.src.training.sequence_xgb_trainer - INFO - Applied scale_pos_weight=5.2500 to handle class imbalance
2025-12-21 01:44:19,272 - ml.src.training.sequence_xgb_trainer - INFO - [POINT 1] Cost-Sensitive Learning: using sample weights (mean=1.3200)
2025-12-21 01:44:19,272 - ml.src.training.sequence_xgb_trainer - INFO - Training XGBoost classifier...
2025-12-21 01:44:33,144 - ml.src.training.sequence_xgb_trainer - INFO - Training completed
2025-12-21 01:44:33,151 - ml.src.training.sequence_evaluation - INFO - Probability stats: min=0.0026, max=0.4800, mean=0.0785, std=0.0915
2025-12-21 01:44:33,160 - ml.src.training.sequence_evaluation - INFO - Using HYBRID optimization: EV with precision AND recall floors...
2025-12-21 01:44:33,284 - ml.src.training.sequence_evaluation - WARNING - No threshold met BOTH precision >= 0.55 AND recall >= 0.20 with >= 10 trades. Falling back to F1-optimized with precision floor.
2025-12-21 01:44:33,286 - ml.src.training.sequence_evaluation - WARNING - No threshold met precision >= 0.55 with >= 10 trades. Falling back to maximizing precision with stability constraint.
2025-12-21 01:44:33,289 - ml.src.training.sequence_evaluation - INFO - Confusion matrix@thr=0.50:
2025-12-21 01:44:33,290 - ml.src.training.sequence_evaluation - INFO -   [[TN=66, FP=0],
2025-12-21 01:44:33,290 - ml.src.training.sequence_evaluation - INFO -    [FN=14, TP=0]]
2025-12-21 01:44:33,298 - ml.src.pipelines.walk_forward_validation - INFO -   Results: WIN_RATE=0.00%, Precision=0.0000, Recall=0.0000, F1=0.0000
2025-12-21 01:44:33,298 - ml.src.pipelines.walk_forward_validation - INFO - Fold 2:
2025-12-21 01:44:33,299 - ml.src.pipelines.walk_forward_validation - INFO -   Train: [40:340] = 300 samples
2025-12-21 01:44:33,302 - ml.src.pipelines.walk_forward_validation - INFO -   Test:  [340:420] = 80 samples
2025-12-21 01:44:33,560 - ml.src.training.sequence_xgb_trainer - INFO - Class balance (train): pos=52, neg=248, imbalance_ratio=4.77
2025-12-21 01:44:33,560 - ml.src.training.sequence_xgb_trainer - INFO - Applied scale_pos_weight=4.7692 to handle class imbalance
2025-12-21 01:44:33,561 - ml.src.training.sequence_xgb_trainer - INFO - [POINT 1] Cost-Sensitive Learning: using sample weights (mean=1.3467)
2025-12-21 01:44:33,562 - ml.src.training.sequence_xgb_trainer - INFO - Training XGBoost classifier...
2025-12-21 01:44:48,718 - ml.src.training.sequence_xgb_trainer - INFO - Training completed
2025-12-21 01:44:48,723 - ml.src.training.sequence_evaluation - INFO - Probability stats: min=0.0020, max=0.3142, mean=0.0234, std=0.0405
2025-12-21 01:44:48,727 - ml.src.training.sequence_evaluation - INFO - Using HYBRID optimization: EV with precision AND recall floors...
2025-12-21 01:44:48,729 - ml.src.training.sequence_evaluation - WARNING - No threshold met BOTH precision >= 0.55 AND recall >= 0.20 with >= 10 trades. Falling back to F1-optimized with precision floor.
2025-12-21 01:44:48,731 - ml.src.training.sequence_evaluation - WARNING - No threshold met precision >= 0.55 with >= 10 trades. Falling back to maximizing precision with stability constraint.
2025-12-21 01:44:48,734 - ml.src.training.sequence_evaluation - INFO - Confusion matrix@thr=0.50:
2025-12-21 01:44:48,735 - ml.src.training.sequence_evaluation - INFO -   [[TN=68, FP=0],
2025-12-21 01:44:48,735 - ml.src.training.sequence_evaluation - INFO -    [FN=12, TP=0]]
2025-12-21 01:44:48,745 - ml.src.pipelines.walk_forward_validation - INFO -   Results: WIN_RATE=0.00%, Precision=0.0000, Recall=0.0000, F1=0.0000
2025-12-21 01:44:48,746 - ml.src.pipelines.walk_forward_validation - INFO - Fold 3:
2025-12-21 01:44:48,746 - ml.src.pipelines.walk_forward_validation - INFO -   Train: [80:380] = 300 samples
2025-12-21 01:44:48,796 - ml.src.pipelines.walk_forward_validation - INFO -   Test:  [380:460] = 80 samples
2025-12-21 01:44:49,027 - ml.src.training.sequence_xgb_trainer - INFO - Class balance (train): pos=54, neg=246, imbalance_ratio=4.56
2025-12-21 01:44:49,028 - ml.src.training.sequence_xgb_trainer - INFO - Applied scale_pos_weight=4.5556 to handle class imbalance
2025-12-21 01:44:49,028 - ml.src.training.sequence_xgb_trainer - INFO - [POINT 1] Cost-Sensitive Learning: using sample weights (mean=1.3600)
2025-12-21 01:44:49,028 - ml.src.training.sequence_xgb_trainer - INFO - Training XGBoost classifier...
2025-12-21 01:45:01,215 - __main__ - INFO - 
================================================================================
2025-12-21 01:45:01,216 - __main__ - INFO - WALK-FORWARD VALIDATION ANALYSIS
2025-12-21 01:45:01,217 - __main__ - INFO - ================================================================================
2025-12-21 01:45:01,219 - __main__ - INFO - Years: 2025
2025-12-21 01:45:01,220 - __main__ - INFO - Train window: 300 samples (~1500 minutes)
2025-12-21 01:45:01,220 - __main__ - INFO - Test window: 80 samples (~400 minutes)
2025-12-21 01:45:01,221 - __main__ - INFO - Step size: 40 samples (~200 minutes)
2025-12-21 01:45:01,221 - __main__ - INFO - ================================================================================

2025-12-21 01:45:01,222 - __main__ - INFO - Loading data...
2025-12-21 01:45:01,225 - ml.src.data_loading.loaders - INFO - Year filter applied: loading only [2025]
2025-12-21 01:45:01,346 - __main__ - INFO - Loaded 18,875 M1 candles
2025-12-21 01:45:01,348 - __main__ - INFO - Aggregating to M5...
2025-12-21 01:45:01,349 - ml.src.features.engineer_m5 - INFO - Aggregating 18875 M1 candles to M5...
2025-12-21 01:45:01,369 - ml.src.features.engineer_m5 - INFO - Aggregated to 3776 M5 candles (5.0x compression)
2025-12-21 01:45:01,369 - __main__ - INFO - Aggregated to 3,776 M5 candles
2025-12-21 01:45:01,370 - __main__ - INFO - Engineering features...
2025-12-21 01:45:01,370 - ml.src.features.engineer_m5 - INFO - Engineering M5 features...
2025-12-21 01:45:01,371 - ml.src.features.engineer_m5 - INFO - Aggregating 3776 M1 candles to M5...
2025-12-21 01:45:01,385 - ml.src.features.engineer_m5 - INFO - Aggregated to 3776 M5 candles (1.0x compression)
2025-12-21 01:45:01,392 - ml.src.features.engineer_m5 - INFO - Computing M5 primary features...
2025-12-21 01:45:02,058 - ml.src.features.engineer_m5 - INFO - Computing M15 context from M5...
2025-12-21 01:45:02,316 - ml.src.features.engineer_m5 - INFO - Computing M60 context from M5...
2025-12-21 01:45:02,410 - ml.src.features.engineer_m5 - INFO - M5 feature engineering complete: 3776 rows × 24 features
2025-12-21 01:45:02,411 - ml.src.features.engineer_m5 - INFO - Timeframe: M5 (5-minute candles)
2025-12-21 01:45:02,412 - ml.src.features.engineer_m5 - INFO - Date range: 2025-12-01 00:00:00 to 2025-12-18 17:35:00
2025-12-21 01:45:02,413 - __main__ - INFO - Engineered 24 features
2025-12-21 01:45:02,413 - __main__ - INFO - Creating targets...
2025-12-21 01:45:02,414 - ml.src.targets.target_maker - INFO - Creating targets (SL/TP simulation) for 3,776 candles...
2025-12-21 01:45:02,414 - ml.src.targets.target_maker - INFO - Parameters: SL=1×ATR, TP=3.0×ATR, min_hold=2min, max_horizon=60min
2025-12-21 01:45:02,417 - ml.src.targets.target_maker - INFO - Calculating M1 ATR(14) for SL/TP targets (fallback)
2025-12-21 01:45:02,425 - ml.src.targets.target_maker - INFO - Target creation complete: 3,716 valid targets
2025-12-21 01:45:02,427 - __main__ - INFO - Created targets: 871 positive, 2,845 negative
2025-12-21 01:45:02,427 - __main__ - INFO - Building sequences...
2025-12-21 01:45:02,439 - ml.src.sequences.sequencer - INFO - M5 alignment filter disabled; keeping all timestamps irrespective of minute alignment
2025-12-21 01:45:02,440 - ml.src.sequences.sequencer - INFO - Applied Trend Filter (dist_sma_200 > 0.00, ADX > 15.00): kept 1711/3667 (46.7%)
2025-12-21 01:45:02,440 - ml.src.sequences.sequencer - INFO - Pullback filter disabled; not constraining RSI_M5
2025-12-21 01:45:02,441 - ml.src.sequences.sequencer - INFO - Session filter 'london_ny': keeping 1,039 / 3,667 windows (28.3%)
2025-12-21 01:45:02,445 - __main__ - INFO - Built 1,039 sequences
2025-12-21 01:45:02,446 - ml.src.pipelines.walk_forward_validation - INFO - 
================================================================================
2025-12-21 01:45:02,446 - ml.src.pipelines.walk_forward_validation - INFO - [POINT 6] WALK-FORWARD CROSS-VALIDATION - Time-Series Validation
2025-12-21 01:45:02,446 - ml.src.pipelines.walk_forward_validation - INFO - ================================================================================
2025-12-21 01:45:02,447 - ml.src.pipelines.walk_forward_validation - INFO - Data size: 1,039 samples (1039 timestamps)
2025-12-21 01:45:02,447 - ml.src.pipelines.walk_forward_validation - INFO - Train window: 300 samples (~1500 minutes)
2025-12-21 01:45:02,449 - ml.src.pipelines.walk_forward_validation - INFO - Test window: 80 samples (~400 minutes)
2025-12-21 01:45:02,450 - ml.src.pipelines.walk_forward_validation - INFO - Step size: 40 samples (~200 minutes)
2025-12-21 01:45:02,451 - ml.src.pipelines.walk_forward_validation - INFO - No lookahead bias: test set is ALWAYS future relative to training set
2025-12-21 01:45:02,452 - ml.src.pipelines.walk_forward_validation - INFO - ================================================================================

2025-12-21 01:45:02,454 - ml.src.pipelines.walk_forward_validation - INFO - Fold 1:
2025-12-21 01:45:02,454 - ml.src.pipelines.walk_forward_validation - INFO -   Train: [0:300] = 300 samples
2025-12-21 01:45:02,455 - ml.src.pipelines.walk_forward_validation - INFO -          2025-12-01 08:15 to 2025-12-05 13:50
2025-12-21 01:45:02,456 - ml.src.pipelines.walk_forward_validation - INFO -   Test:  [300:380] = 80 samples
2025-12-21 01:45:02,456 - ml.src.pipelines.walk_forward_validation - INFO -          2025-12-05 13:55 to 2025-12-09 10:50
2025-12-21 01:45:02,854 - ml.src.training.sequence_xgb_trainer - INFO - Class balance (train): pos=48, neg=252, imbalance_ratio=5.25
2025-12-21 01:45:02,855 - ml.src.training.sequence_xgb_trainer - INFO - Applied scale_pos_weight=5.2500 to handle class imbalance
2025-12-21 01:45:02,856 - ml.src.training.sequence_xgb_trainer - INFO - [POINT 1] Cost-Sensitive Learning: using sample weights (mean=1.3200)
2025-12-21 01:45:02,856 - ml.src.training.sequence_xgb_trainer - INFO - Training XGBoost classifier...
2025-12-21 01:45:06,138 - ml.src.training.sequence_xgb_trainer - INFO - Training completed
2025-12-21 01:45:06,146 - ml.src.training.sequence_evaluation - INFO - Probability stats: min=0.0025, max=0.6989, mean=0.0646, std=0.1379
2025-12-21 01:45:06,165 - ml.src.training.sequence_evaluation - INFO - Using HYBRID optimization: EV with precision AND recall floors...
2025-12-21 01:45:06,169 - ml.src.training.sequence_evaluation - WARNING - No threshold met BOTH precision >= 0.55 AND recall >= 0.20 with >= 10 trades. Falling back to F1-optimized with precision floor.
2025-12-21 01:45:06,173 - ml.src.training.sequence_evaluation - WARNING - No threshold met precision >= 0.55 with >= 10 trades. Falling back to maximizing precision with stability constraint.
2025-12-21 01:45:06,179 - ml.src.training.sequence_evaluation - INFO - Confusion matrix@thr=0.50:
2025-12-21 01:45:06,180 - ml.src.training.sequence_evaluation - INFO -   [[TN=63, FP=4],
2025-12-21 01:45:06,180 - ml.src.training.sequence_evaluation - INFO -    [FN=13, TP=0]]
2025-12-21 01:45:06,199 - ml.src.pipelines.walk_forward_validation - INFO -   Results: WIN_RATE=0.00%, Precision=0.0000, Recall=0.0000, F1=0.0000
2025-12-21 01:45:06,200 - ml.src.pipelines.walk_forward_validation - INFO - Fold 4:
2025-12-21 01:45:06,200 - ml.src.pipelines.walk_forward_validation - INFO -   Train: [120:420] = 300 samples
2025-12-21 01:45:06,208 - ml.src.pipelines.walk_forward_validation - INFO -   Test:  [420:500] = 80 samples
2025-12-21 01:45:06,614 - ml.src.training.sequence_xgb_trainer - INFO - Class balance (train): pos=50, neg=250, imbalance_ratio=5.00
2025-12-21 01:45:06,615 - ml.src.training.sequence_xgb_trainer - INFO - Applied scale_pos_weight=5.0000 to handle class imbalance
2025-12-21 01:45:06,615 - ml.src.training.sequence_xgb_trainer - INFO - [POINT 1] Cost-Sensitive Learning: using sample weights (mean=1.3333)
2025-12-21 01:45:06,616 - ml.src.training.sequence_xgb_trainer - INFO - Training XGBoost classifier...
2025-12-21 01:45:24,353 - ml.src.training.sequence_xgb_trainer - INFO - Training completed
2025-12-21 01:45:24,363 - ml.src.training.sequence_evaluation - INFO - Probability stats: min=0.0040, max=0.9368, mean=0.1730, std=0.2035
2025-12-21 01:45:24,376 - ml.src.training.sequence_evaluation - INFO - Using HYBRID optimization: EV with precision AND recall floors...
2025-12-21 01:45:24,775 - ml.src.training.sequence_evaluation - WARNING - No threshold met BOTH precision >= 0.55 AND recall >= 0.20 with >= 10 trades. Falling back to F1-optimized with precision floor.
2025-12-21 01:45:24,861 - ml.src.training.sequence_evaluation - WARNING - No threshold met precision >= 0.55 with >= 10 trades. Falling back to maximizing precision with stability constraint.
2025-12-21 01:45:25,025 - ml.src.training.sequence_evaluation - INFO - Confusion matrix@thr=0.29:
2025-12-21 01:45:25,026 - ml.src.training.sequence_evaluation - INFO -   [[TN=55, FP=15],
2025-12-21 01:45:25,026 - ml.src.training.sequence_evaluation - INFO -    [FN=8, TP=2]]
2025-12-21 01:45:25,032 - ml.src.pipelines.walk_forward_validation - INFO -   Results: WIN_RATE=11.76%, Precision=0.1176, Recall=0.2000, F1=0.1481
2025-12-21 01:45:25,033 - ml.src.pipelines.walk_forward_validation - INFO - Fold 5:
2025-12-21 01:45:25,034 - ml.src.pipelines.walk_forward_validation - INFO -   Train: [160:460] = 300 samples
2025-12-21 01:45:25,038 - ml.src.pipelines.walk_forward_validation - INFO -   Test:  [460:540] = 80 samples
2025-12-21 01:45:25,235 - ml.src.training.sequence_xgb_trainer - INFO - Class balance (train): pos=52, neg=248, imbalance_ratio=4.77
2025-12-21 01:45:25,235 - ml.src.training.sequence_xgb_trainer - INFO - Applied scale_pos_weight=4.7692 to handle class imbalance
2025-12-21 01:45:25,235 - ml.src.training.sequence_xgb_trainer - INFO - [POINT 1] Cost-Sensitive Learning: using sample weights (mean=1.3467)
2025-12-21 01:45:25,236 - ml.src.training.sequence_xgb_trainer - INFO - Training XGBoost classifier...
2025-12-21 01:45:38,871 - __main__ - INFO - 
================================================================================
2025-12-21 01:45:38,872 - __main__ - INFO - WALK-FORWARD VALIDATION ANALYSIS
2025-12-21 01:45:38,872 - __main__ - INFO - ================================================================================
2025-12-21 01:45:38,873 - __main__ - INFO - Years: 2025
2025-12-21 01:45:38,873 - __main__ - INFO - Train window: 200 samples (~1000 minutes)
2025-12-21 01:45:38,874 - __main__ - INFO - Test window: 50 samples (~250 minutes)
2025-12-21 01:45:38,874 - __main__ - INFO - Step size: 30 samples (~150 minutes)
2025-12-21 01:45:38,874 - __main__ - INFO - ================================================================================

2025-12-21 01:45:38,875 - __main__ - INFO - Loading data...
2025-12-21 01:45:38,879 - ml.src.data_loading.loaders - INFO - Year filter applied: loading only [2025]
2025-12-21 01:45:39,012 - __main__ - INFO - Loaded 18,875 M1 candles
2025-12-21 01:45:39,013 - __main__ - INFO - Aggregating to M5...
2025-12-21 01:45:39,014 - ml.src.features.engineer_m5 - INFO - Aggregating 18875 M1 candles to M5...
2025-12-21 01:45:39,040 - ml.src.features.engineer_m5 - INFO - Aggregated to 3776 M5 candles (5.0x compression)
2025-12-21 01:45:39,043 - __main__ - INFO - Aggregated to 3,776 M5 candles
2025-12-21 01:45:39,044 - __main__ - INFO - Engineering features...
2025-12-21 01:45:39,053 - ml.src.features.engineer_m5 - INFO - Engineering M5 features...
2025-12-21 01:45:39,054 - ml.src.features.engineer_m5 - INFO - Aggregating 3776 M1 candles to M5...
2025-12-21 01:45:39,082 - ml.src.features.engineer_m5 - INFO - Aggregated to 3776 M5 candles (1.0x compression)
2025-12-21 01:45:39,098 - ml.src.features.engineer_m5 - INFO - Computing M5 primary features...
2025-12-21 01:45:39,836 - ml.src.features.engineer_m5 - INFO - Computing M15 context from M5...
2025-12-21 01:45:40,071 - ml.src.features.engineer_m5 - INFO - Computing M60 context from M5...
2025-12-21 01:45:40,183 - ml.src.features.engineer_m5 - INFO - M5 feature engineering complete: 3776 rows × 24 features
2025-12-21 01:45:40,185 - ml.src.features.engineer_m5 - INFO - Timeframe: M5 (5-minute candles)
2025-12-21 01:45:40,185 - ml.src.features.engineer_m5 - INFO - Date range: 2025-12-01 00:00:00 to 2025-12-18 17:35:00
2025-12-21 01:45:40,186 - __main__ - INFO - Engineered 24 features
2025-12-21 01:45:40,187 - __main__ - INFO - Creating targets...
2025-12-21 01:45:40,187 - ml.src.targets.target_maker - INFO - Creating targets (SL/TP simulation) for 3,776 candles...
2025-12-21 01:45:40,188 - ml.src.targets.target_maker - INFO - Parameters: SL=1×ATR, TP=3.0×ATR, min_hold=2min, max_horizon=60min
2025-12-21 01:45:40,189 - ml.src.targets.target_maker - INFO - Calculating M1 ATR(14) for SL/TP targets (fallback)
2025-12-21 01:45:40,198 - ml.src.targets.target_maker - INFO - Target creation complete: 3,716 valid targets
2025-12-21 01:45:40,201 - __main__ - INFO - Created targets: 871 positive, 2,845 negative
2025-12-21 01:45:40,201 - __main__ - INFO - Building sequences...
2025-12-21 01:45:40,210 - ml.src.sequences.sequencer - INFO - M5 alignment filter disabled; keeping all timestamps irrespective of minute alignment
2025-12-21 01:45:40,215 - ml.src.sequences.sequencer - INFO - Applied Trend Filter (dist_sma_200 > 0.00, ADX > 15.00): kept 1711/3667 (46.7%)
2025-12-21 01:45:40,216 - ml.src.sequences.sequencer - INFO - Pullback filter disabled; not constraining RSI_M5
2025-12-21 01:45:40,217 - ml.src.sequences.sequencer - INFO - Session filter 'london_ny': keeping 1,039 / 3,667 windows (28.3%)
2025-12-21 01:45:40,220 - __main__ - INFO - Built 1,039 sequences
2025-12-21 01:45:40,220 - ml.src.pipelines.walk_forward_validation - INFO - 
================================================================================
2025-12-21 01:45:40,221 - ml.src.pipelines.walk_forward_validation - INFO - [POINT 6] WALK-FORWARD CROSS-VALIDATION - Time-Series Validation
2025-12-21 01:45:40,221 - ml.src.pipelines.walk_forward_validation - INFO - ================================================================================
2025-12-21 01:45:40,222 - ml.src.pipelines.walk_forward_validation - INFO - Data size: 1,039 samples (1039 timestamps)
2025-12-21 01:45:40,223 - ml.src.pipelines.walk_forward_validation - INFO - Train window: 200 samples (~1000 minutes)
2025-12-21 01:45:40,223 - ml.src.pipelines.walk_forward_validation - INFO - Test window: 50 samples (~250 minutes)
2025-12-21 01:45:40,224 - ml.src.pipelines.walk_forward_validation - INFO - Step size: 30 samples (~150 minutes)
2025-12-21 01:45:40,224 - ml.src.pipelines.walk_forward_validation - INFO - No lookahead bias: test set is ALWAYS future relative to training set
2025-12-21 01:45:40,225 - ml.src.pipelines.walk_forward_validation - INFO - ================================================================================

2025-12-21 01:45:40,226 - ml.src.pipelines.walk_forward_validation - INFO - Fold 1:
2025-12-21 01:45:40,227 - ml.src.pipelines.walk_forward_validation - INFO -   Train: [0:200] = 200 samples
2025-12-21 01:45:40,228 - ml.src.pipelines.walk_forward_validation - INFO -          2025-12-01 08:15 to 2025-12-04 18:05
2025-12-21 01:45:40,230 - ml.src.pipelines.walk_forward_validation - INFO -   Test:  [200:250] = 50 samples
2025-12-21 01:45:40,231 - ml.src.pipelines.walk_forward_validation - INFO -          2025-12-04 18:10 to 2025-12-05 09:40
2025-12-21 01:45:40,652 - ml.src.training.sequence_xgb_trainer - INFO - Class balance (train): pos=24, neg=176, imbalance_ratio=7.33
2025-12-21 01:45:40,652 - ml.src.training.sequence_xgb_trainer - INFO - Applied scale_pos_weight=7.3333 to handle class imbalance
2025-12-21 01:45:40,653 - ml.src.training.sequence_xgb_trainer - INFO - [POINT 1] Cost-Sensitive Learning: using sample weights (mean=1.2400)
2025-12-21 01:45:40,654 - ml.src.training.sequence_xgb_trainer - INFO - Training XGBoost classifier...
2025-12-21 01:45:42,571 - ml.src.training.sequence_xgb_trainer - INFO - Training completed
2025-12-21 01:45:42,580 - ml.src.training.sequence_evaluation - INFO - Probability stats: min=0.0008, max=0.9567, mean=0.1097, std=0.1673
2025-12-21 01:45:42,589 - ml.src.training.sequence_evaluation - INFO - Using HYBRID optimization: EV with precision AND recall floors...
2025-12-21 01:45:43,062 - ml.src.training.sequence_evaluation - WARNING - No threshold met BOTH precision >= 0.55 AND recall >= 0.20 with >= 10 trades. Falling back to F1-optimized with precision floor.
2025-12-21 01:45:43,155 - ml.src.training.sequence_evaluation - WARNING - No threshold met precision >= 0.55 with >= 10 trades. Falling back to maximizing precision with stability constraint.
2025-12-21 01:45:43,336 - ml.src.training.sequence_evaluation - INFO - Confusion matrix@thr=0.27:
2025-12-21 01:45:43,336 - ml.src.training.sequence_evaluation - INFO -   [[TN=60, FP=9],
2025-12-21 01:45:43,336 - ml.src.training.sequence_evaluation - INFO -    [FN=10, TP=1]]
2025-12-21 01:45:43,344 - ml.src.pipelines.walk_forward_validation - INFO -   Results: WIN_RATE=10.00%, Precision=0.1000, Recall=0.0909, F1=0.0952
2025-12-21 01:45:43,344 - ml.src.pipelines.walk_forward_validation - INFO - Fold 6:
2025-12-21 01:45:43,344 - ml.src.pipelines.walk_forward_validation - INFO -   Train: [200:500] = 300 samples
2025-12-21 01:45:43,351 - ml.src.pipelines.walk_forward_validation - INFO -   Test:  [500:580] = 80 samples
2025-12-21 01:45:43,564 - ml.src.training.sequence_xgb_trainer - INFO - Class balance (train): pos=54, neg=246, imbalance_ratio=4.56
2025-12-21 01:45:43,564 - ml.src.training.sequence_xgb_trainer - INFO - Applied scale_pos_weight=4.5556 to handle class imbalance
2025-12-21 01:45:43,565 - ml.src.training.sequence_xgb_trainer - INFO - [POINT 1] Cost-Sensitive Learning: using sample weights (mean=1.3600)
2025-12-21 01:45:43,565 - ml.src.training.sequence_xgb_trainer - INFO - Training XGBoost classifier...
2025-12-21 01:45:58,426 - ml.src.training.sequence_xgb_trainer - INFO - Training completed
2025-12-21 01:45:58,432 - ml.src.training.sequence_evaluation - INFO - Probability stats: min=0.0007, max=0.3070, mean=0.0318, std=0.0632
2025-12-21 01:45:58,444 - ml.src.training.sequence_evaluation - INFO - Using HYBRID optimization: EV with precision AND recall floors...
2025-12-21 01:45:58,446 - ml.src.training.sequence_evaluation - WARNING - No threshold met BOTH precision >= 0.55 AND recall >= 0.20 with >= 10 trades. Falling back to F1-optimized with precision floor.
2025-12-21 01:45:58,448 - ml.src.training.sequence_evaluation - WARNING - No threshold met precision >= 0.55 with >= 10 trades. Falling back to maximizing precision with stability constraint.
2025-12-21 01:45:58,453 - ml.src.training.sequence_evaluation - INFO - Confusion matrix@thr=0.50:
2025-12-21 01:45:58,453 - ml.src.training.sequence_evaluation - INFO -   [[TN=43, FP=0],
2025-12-21 01:45:58,453 - ml.src.training.sequence_evaluation - INFO -    [FN=37, TP=0]]
2025-12-21 01:45:58,470 - ml.src.pipelines.walk_forward_validation - INFO -   Results: WIN_RATE=0.00%, Precision=0.0000, Recall=0.0000, F1=0.0000
2025-12-21 01:45:58,470 - ml.src.pipelines.walk_forward_validation - INFO - Fold 7:
2025-12-21 01:45:58,471 - ml.src.pipelines.walk_forward_validation - INFO -   Train: [240:540] = 300 samples
2025-12-21 01:45:58,475 - ml.src.pipelines.walk_forward_validation - INFO -   Test:  [540:620] = 80 samples
2025-12-21 01:45:58,696 - ml.src.training.sequence_xgb_trainer - INFO - Class balance (train): pos=62, neg=238, imbalance_ratio=3.84
2025-12-21 01:45:58,697 - ml.src.training.sequence_xgb_trainer - INFO - Applied scale_pos_weight=3.8387 to handle class imbalance
2025-12-21 01:45:58,697 - ml.src.training.sequence_xgb_trainer - INFO - [POINT 1] Cost-Sensitive Learning: using sample weights (mean=1.4133)
2025-12-21 01:45:58,698 - ml.src.training.sequence_xgb_trainer - INFO - Training XGBoost classifier...
2025-12-21 01:46:15,905 - ml.src.training.sequence_xgb_trainer - INFO - Training completed
2025-12-21 01:46:15,912 - ml.src.training.sequence_evaluation - INFO - Probability stats: min=0.0037, max=0.3280, mean=0.0598, std=0.0687
2025-12-21 01:46:15,965 - ml.src.training.sequence_evaluation - INFO - Using HYBRID optimization: EV with precision AND recall floors...
2025-12-21 01:46:16,046 - ml.src.training.sequence_evaluation - WARNING - No threshold met BOTH precision >= 0.55 AND recall >= 0.20 with >= 10 trades. Falling back to F1-optimized with precision floor.
2025-12-21 01:46:16,049 - ml.src.training.sequence_evaluation - WARNING - No threshold met precision >= 0.55 with >= 10 trades. Falling back to maximizing precision with stability constraint.
2025-12-21 01:46:16,052 - ml.src.training.sequence_evaluation - INFO - Confusion matrix@thr=0.50:
2025-12-21 01:46:16,052 - ml.src.training.sequence_evaluation - INFO -   [[TN=45, FP=0],
2025-12-21 01:46:16,052 - ml.src.training.sequence_evaluation - INFO -    [FN=35, TP=0]]
2025-12-21 01:46:16,061 - ml.src.pipelines.walk_forward_validation - INFO -   Results: WIN_RATE=0.00%, Precision=0.0000, Recall=0.0000, F1=0.0000
2025-12-21 01:46:16,062 - ml.src.pipelines.walk_forward_validation - INFO - Fold 8:
2025-12-21 01:46:16,062 - ml.src.pipelines.walk_forward_validation - INFO -   Train: [280:580] = 300 samples
2025-12-21 01:46:16,066 - ml.src.pipelines.walk_forward_validation - INFO -   Test:  [580:660] = 80 samples
2025-12-21 01:46:16,307 - ml.src.training.sequence_xgb_trainer - INFO - Class balance (train): pos=76, neg=224, imbalance_ratio=2.95
2025-12-21 01:46:16,308 - ml.src.training.sequence_xgb_trainer - INFO - Applied scale_pos_weight=2.9474 to handle class imbalance
2025-12-21 01:46:16,309 - ml.src.training.sequence_xgb_trainer - INFO - [POINT 1] Cost-Sensitive Learning: using sample weights (mean=1.5067)
2025-12-21 01:46:16,310 - ml.src.training.sequence_xgb_trainer - INFO - Training XGBoost classifier...
2025-12-21 01:46:23,382 - __main__ - INFO - 
================================================================================
2025-12-21 01:46:23,383 - __main__ - INFO - WALK-FORWARD VALIDATION ANALYSIS
2025-12-21 01:46:23,384 - __main__ - INFO - ================================================================================
2025-12-21 01:46:23,384 - __main__ - INFO - Years: 2025
2025-12-21 01:46:23,384 - __main__ - INFO - Train window: 150 samples (~750 minutes)
2025-12-21 01:46:23,385 - __main__ - INFO - Test window: 40 samples (~200 minutes)
2025-12-21 01:46:23,385 - __main__ - INFO - Step size: 25 samples (~125 minutes)
2025-12-21 01:46:23,385 - __main__ - INFO - ================================================================================

2025-12-21 01:46:23,386 - __main__ - INFO - Loading data...
2025-12-21 01:46:23,387 - ml.src.data_loading.loaders - INFO - Year filter applied: loading only [2025]
2025-12-21 01:46:23,502 - __main__ - INFO - Loaded 18,875 M1 candles
2025-12-21 01:46:23,502 - __main__ - INFO - Aggregating to M5...
2025-12-21 01:46:23,503 - ml.src.features.engineer_m5 - INFO - Aggregating 18875 M1 candles to M5...
2025-12-21 01:46:23,532 - ml.src.features.engineer_m5 - INFO - Aggregated to 3776 M5 candles (5.0x compression)
2025-12-21 01:46:23,533 - __main__ - INFO - Aggregated to 3,776 M5 candles
2025-12-21 01:46:23,533 - __main__ - INFO - Engineering features...
2025-12-21 01:46:23,534 - ml.src.features.engineer_m5 - INFO - Engineering M5 features...
2025-12-21 01:46:23,534 - ml.src.features.engineer_m5 - INFO - Aggregating 3776 M1 candles to M5...
2025-12-21 01:46:23,549 - ml.src.features.engineer_m5 - INFO - Aggregated to 3776 M5 candles (1.0x compression)
2025-12-21 01:46:23,555 - ml.src.features.engineer_m5 - INFO - Computing M5 primary features...
2025-12-21 01:46:24,242 - ml.src.features.engineer_m5 - INFO - Computing M15 context from M5...
2025-12-21 01:46:24,485 - ml.src.features.engineer_m5 - INFO - Computing M60 context from M5...
2025-12-21 01:46:24,588 - ml.src.features.engineer_m5 - INFO - M5 feature engineering complete: 3776 rows × 24 features
2025-12-21 01:46:24,591 - ml.src.features.engineer_m5 - INFO - Timeframe: M5 (5-minute candles)
2025-12-21 01:46:24,592 - ml.src.features.engineer_m5 - INFO - Date range: 2025-12-01 00:00:00 to 2025-12-18 17:35:00
2025-12-21 01:46:24,593 - __main__ - INFO - Engineered 24 features
2025-12-21 01:46:24,593 - __main__ - INFO - Creating targets...
2025-12-21 01:46:24,594 - ml.src.targets.target_maker - INFO - Creating targets (SL/TP simulation) for 3,776 candles...
2025-12-21 01:46:24,594 - ml.src.targets.target_maker - INFO - Parameters: SL=1×ATR, TP=3.0×ATR, min_hold=2min, max_horizon=60min
2025-12-21 01:46:24,596 - ml.src.targets.target_maker - INFO - Calculating M1 ATR(14) for SL/TP targets (fallback)
2025-12-21 01:46:24,606 - ml.src.targets.target_maker - INFO - Target creation complete: 3,716 valid targets
2025-12-21 01:46:24,608 - __main__ - INFO - Created targets: 871 positive, 2,845 negative
2025-12-21 01:46:24,609 - __main__ - INFO - Building sequences...
2025-12-21 01:46:24,620 - ml.src.sequences.sequencer - INFO - M5 alignment filter disabled; keeping all timestamps irrespective of minute alignment
2025-12-21 01:46:24,622 - ml.src.sequences.sequencer - INFO - Applied Trend Filter (dist_sma_200 > 0.00, ADX > 15.00): kept 1711/3667 (46.7%)
2025-12-21 01:46:24,622 - ml.src.sequences.sequencer - INFO - Pullback filter disabled; not constraining RSI_M5
2025-12-21 01:46:24,624 - ml.src.sequences.sequencer - INFO - Session filter 'london_ny': keeping 1,039 / 3,667 windows (28.3%)
2025-12-21 01:46:24,626 - __main__ - INFO - Built 1,039 sequences
2025-12-21 01:46:24,627 - ml.src.pipelines.walk_forward_validation - INFO - 
================================================================================
2025-12-21 01:46:24,627 - ml.src.pipelines.walk_forward_validation - INFO - [POINT 6] WALK-FORWARD CROSS-VALIDATION - Time-Series Validation
2025-12-21 01:46:24,628 - ml.src.pipelines.walk_forward_validation - INFO - ================================================================================
2025-12-21 01:46:24,628 - ml.src.pipelines.walk_forward_validation - INFO - Data size: 1,039 samples (1039 timestamps)
2025-12-21 01:46:24,629 - ml.src.pipelines.walk_forward_validation - INFO - Train window: 150 samples (~750 minutes)
2025-12-21 01:46:24,629 - ml.src.pipelines.walk_forward_validation - INFO - Test window: 40 samples (~200 minutes)
2025-12-21 01:46:24,630 - ml.src.pipelines.walk_forward_validation - INFO - Step size: 25 samples (~125 minutes)
2025-12-21 01:46:24,630 - ml.src.pipelines.walk_forward_validation - INFO - No lookahead bias: test set is ALWAYS future relative to training set
2025-12-21 01:46:24,630 - ml.src.pipelines.walk_forward_validation - INFO - ================================================================================

2025-12-21 01:46:24,631 - ml.src.pipelines.walk_forward_validation - INFO - Fold 1:
2025-12-21 01:46:24,632 - ml.src.pipelines.walk_forward_validation - INFO -   Train: [0:150] = 150 samples
2025-12-21 01:46:24,633 - ml.src.pipelines.walk_forward_validation - INFO -          2025-12-01 08:15 to 2025-12-03 20:05
2025-12-21 01:46:24,634 - ml.src.pipelines.walk_forward_validation - INFO -   Test:  [150:190] = 40 samples
2025-12-21 01:46:24,635 - ml.src.pipelines.walk_forward_validation - INFO -          2025-12-04 10:05 to 2025-12-04 17:15
2025-12-21 01:46:24,958 - ml.src.training.sequence_xgb_trainer - INFO - Class balance (train): pos=9, neg=96, imbalance_ratio=10.67
2025-12-21 01:46:24,958 - ml.src.training.sequence_xgb_trainer - INFO - Applied scale_pos_weight=10.6667 to handle class imbalance
2025-12-21 01:46:24,959 - ml.src.training.sequence_xgb_trainer - INFO - [POINT 1] Cost-Sensitive Learning: using sample weights (mean=1.1714)
2025-12-21 01:46:24,960 - ml.src.training.sequence_xgb_trainer - INFO - Training XGBoost classifier...
2025-12-21 01:46:26,261 - ml.src.training.sequence_xgb_trainer - INFO - Training completed
2025-12-21 01:46:26,268 - ml.src.training.sequence_evaluation - INFO - Probability stats: min=0.2430, max=0.4446, mean=0.3160, std=0.0601
2025-12-21 01:46:26,280 - ml.src.training.sequence_evaluation - INFO - Using HYBRID optimization: EV with precision AND recall floors...
2025-12-21 01:46:26,870 - ml.src.training.sequence_evaluation - WARNING - No threshold met BOTH precision >= 0.55 AND recall >= 0.20 with >= 10 trades. Falling back to F1-optimized with precision floor.
2025-12-21 01:46:27,042 - ml.src.training.sequence_evaluation - WARNING - No threshold met precision >= 0.55 with >= 10 trades. Falling back to maximizing precision with stability constraint.
2025-12-21 01:46:27,389 - ml.src.training.sequence_evaluation - INFO - Confusion matrix@thr=0.35:
2025-12-21 01:46:27,391 - ml.src.training.sequence_evaluation - INFO -   [[TN=28, FP=11],
2025-12-21 01:46:27,391 - ml.src.training.sequence_evaluation - INFO -    [FN=0, TP=1]]
2025-12-21 01:46:27,400 - ml.src.pipelines.walk_forward_validation - INFO -   Results: WIN_RATE=8.33%, Precision=0.0833, Recall=1.0000, F1=0.1538
2025-12-21 01:46:27,401 - ml.src.pipelines.walk_forward_validation - INFO - Fold 2:
2025-12-21 01:46:27,401 - ml.src.pipelines.walk_forward_validation - INFO -   Train: [25:175] = 150 samples
2025-12-21 01:46:27,403 - ml.src.pipelines.walk_forward_validation - INFO -          2025-12-01 10:55 to 2025-12-04 15:15
2025-12-21 01:46:27,403 - ml.src.pipelines.walk_forward_validation - INFO -   Test:  [175:215] = 40 samples
2025-12-21 01:46:27,404 - ml.src.pipelines.walk_forward_validation - INFO -          2025-12-04 15:20 to 2025-12-04 19:20
2025-12-21 01:46:27,790 - ml.src.training.sequence_xgb_trainer - INFO - Class balance (train): pos=19, neg=86, imbalance_ratio=4.53
2025-12-21 01:46:27,791 - ml.src.training.sequence_xgb_trainer - INFO - Applied scale_pos_weight=4.5263 to handle class imbalance
2025-12-21 01:46:27,792 - ml.src.training.sequence_xgb_trainer - INFO - [POINT 1] Cost-Sensitive Learning: using sample weights (mean=1.3619)
2025-12-21 01:46:27,793 - ml.src.training.sequence_xgb_trainer - INFO - Training XGBoost classifier...
2025-12-21 01:46:31,720 - ml.src.training.sequence_xgb_trainer - INFO - Training completed
2025-12-21 01:46:31,727 - ml.src.training.sequence_evaluation - INFO - Probability stats: min=0.0071, max=0.7627, mean=0.1612, std=0.1927
2025-12-21 01:46:31,797 - ml.src.training.sequence_evaluation - INFO - Using HYBRID optimization: EV with precision AND recall floors...
2025-12-21 01:46:32,115 - ml.src.training.sequence_evaluation - WARNING - No threshold met BOTH precision >= 0.55 AND recall >= 0.20 with >= 10 trades. Falling back to F1-optimized with precision floor.
2025-12-21 01:46:32,165 - ml.src.training.sequence_evaluation - WARNING - No threshold met precision >= 0.55 with >= 10 trades. Falling back to maximizing precision with stability constraint.
2025-12-21 01:46:32,285 - ml.src.training.sequence_evaluation - INFO - Confusion matrix@thr=0.20:
2025-12-21 01:46:32,285 - ml.src.training.sequence_evaluation - INFO -   [[TN=29, FP=11],
2025-12-21 01:46:32,286 - ml.src.training.sequence_evaluation - INFO -    [FN=0, TP=0]]
2025-12-21 01:46:32,303 - ml.src.pipelines.walk_forward_validation - INFO -   Results: WIN_RATE=0.00%, Precision=0.0000, Recall=0.0000, F1=0.0000
2025-12-21 01:46:32,303 - ml.src.pipelines.walk_forward_validation - INFO - Fold 3:
2025-12-21 01:46:32,305 - ml.src.pipelines.walk_forward_validation - INFO -   Train: [50:200] = 150 samples
2025-12-21 01:46:32,306 - ml.src.pipelines.walk_forward_validation - INFO -          2025-12-01 13:00 to 2025-12-04 18:05
2025-12-21 01:46:32,307 - ml.src.pipelines.walk_forward_validation - INFO -   Test:  [200:240] = 40 samples
2025-12-21 01:46:32,308 - ml.src.pipelines.walk_forward_validation - INFO -          2025-12-04 18:10 to 2025-12-05 08:50
2025-12-21 01:46:32,650 - ml.src.training.sequence_xgb_trainer - INFO - Class balance (train): pos=16, neg=89, imbalance_ratio=5.56
2025-12-21 01:46:32,651 - ml.src.training.sequence_xgb_trainer - INFO - Applied scale_pos_weight=5.5625 to handle class imbalance
2025-12-21 01:46:32,652 - ml.src.training.sequence_xgb_trainer - INFO - [POINT 1] Cost-Sensitive Learning: using sample weights (mean=1.3048)
2025-12-21 01:46:32,652 - ml.src.training.sequence_xgb_trainer - INFO - Training XGBoost classifier...
2025-12-21 01:46:35,593 - ml.src.training.sequence_xgb_trainer - INFO - Training completed
2025-12-21 01:46:35,602 - ml.src.training.sequence_evaluation - INFO - Probability stats: min=0.0327, max=0.8227, mean=0.2105, std=0.1585
2025-12-21 01:46:35,612 - ml.src.training.sequence_evaluation - INFO - Using HYBRID optimization: EV with precision AND recall floors...
2025-12-21 01:46:36,163 - ml.src.training.sequence_evaluation - INFO - Hybrid-optimized threshold: 0.26 with EV=0.0400 (precision=0.5652, recall=0.5200, win_coeff=1.0, loss_coeff=-1.0)
2025-12-21 01:46:36,167 - ml.src.training.sequence_evaluation - INFO - Confusion matrix@thr=0.26:
2025-12-21 01:46:36,168 - ml.src.training.sequence_evaluation - INFO -   [[TN=45, FP=10],
2025-12-21 01:46:36,168 - ml.src.training.sequence_evaluation - INFO -    [FN=12, TP=13]]
2025-12-21 01:46:36,184 - ml.src.pipelines.walk_forward_validation - INFO -   Results: WIN_RATE=56.52%, Precision=0.5652, Recall=0.5200, F1=0.5417
2025-12-21 01:46:36,185 - ml.src.pipelines.walk_forward_validation - INFO - Fold 9:
2025-12-21 01:46:36,186 - ml.src.pipelines.walk_forward_validation - INFO -   Train: [320:620] = 300 samples
2025-12-21 01:46:36,195 - ml.src.pipelines.walk_forward_validation - INFO -   Test:  [620:700] = 80 samples
2025-12-21 01:46:36,285 - ml.src.training.sequence_xgb_trainer - INFO - Training completed
2025-12-21 01:46:36,287 - ml.src.training.sequence_evaluation - INFO - Probability stats: min=0.0049, max=0.1331, mean=0.0213, std=0.0229
2025-12-21 01:46:36,290 - ml.src.training.sequence_evaluation - INFO - Using HYBRID optimization: EV with precision AND recall floors...
2025-12-21 01:46:36,295 - ml.src.training.sequence_evaluation - WARNING - No threshold met BOTH precision >= 0.55 AND recall >= 0.20 with >= 10 trades. Falling back to F1-optimized with precision floor.
2025-12-21 01:46:36,297 - ml.src.training.sequence_evaluation - WARNING - No threshold met precision >= 0.55 with >= 10 trades. Falling back to maximizing precision with stability constraint.
2025-12-21 01:46:36,364 - ml.src.training.sequence_evaluation - INFO - Confusion matrix@thr=0.50:
2025-12-21 01:46:36,365 - __main__ - ERROR - ERROR: index 1 is out of bounds for axis 1 with size 1
Traceback (most recent call last):
  File "C:\Users\Arek\Documents\Repos\Traiding\Trading-ML\ml\scripts\walk_forward_analysis.py", line 150, in main
    results = walk_forward_validate(
        X=X,
    ...<9 lines>...
        sample_weight_negative=SAMPLE_WEIGHT_NEGATIVE,
    )
  File "C:\Users\Arek\Documents\Repos\Traiding\Trading-ML\ml\src\pipelines\walk_forward_validation.py", line 161, in walk_forward_validate
    metrics = evaluate(
        model,
    ...<5 lines>...
        use_hybrid_optimization=True,
    )
  File "C:\Users\Arek\Documents\Repos\Traiding\Trading-ML\ml\src\training\sequence_evaluation.py", line 413, in evaluate
    logger.info(f"  [[TN={cm[0,0]}, FP={cm[0,1]}],")
                                        ~~^^^^^
IndexError: index 1 is out of bounds for axis 1 with size 1
2025-12-21 01:46:36,532 - ml.src.training.sequence_xgb_trainer - INFO - Class balance (train): pos=65, neg=235, imbalance_ratio=3.62
2025-12-21 01:46:36,533 - ml.src.training.sequence_xgb_trainer - INFO - Applied scale_pos_weight=3.6154 to handle class imbalance
2025-12-21 01:46:36,533 - ml.src.training.sequence_xgb_trainer - INFO - [POINT 1] Cost-Sensitive Learning: using sample weights (mean=1.4333)
2025-12-21 01:46:36,534 - ml.src.training.sequence_xgb_trainer - INFO - Training XGBoost classifier...
2025-12-21 01:46:53,752 - ml.src.training.sequence_xgb_trainer - INFO - Training completed
2025-12-21 01:46:53,759 - ml.src.training.sequence_evaluation - INFO - Probability stats: min=0.0030, max=0.5370, mean=0.0566, std=0.0823
2025-12-21 01:46:53,767 - ml.src.training.sequence_evaluation - INFO - Using HYBRID optimization: EV with precision AND recall floors...
2025-12-21 01:46:53,771 - ml.src.training.sequence_evaluation - WARNING - No threshold met BOTH precision >= 0.55 AND recall >= 0.20 with >= 10 trades. Falling back to F1-optimized with precision floor.
2025-12-21 01:46:53,772 - ml.src.training.sequence_evaluation - WARNING - No threshold met precision >= 0.55 with >= 10 trades. Falling back to maximizing precision with stability constraint.
2025-12-21 01:46:53,775 - ml.src.training.sequence_evaluation - INFO - Confusion matrix@thr=0.50:
2025-12-21 01:46:53,775 - ml.src.training.sequence_evaluation - INFO -   [[TN=48, FP=1],
2025-12-21 01:46:53,776 - ml.src.training.sequence_evaluation - INFO -    [FN=31, TP=0]]
2025-12-21 01:46:53,788 - ml.src.pipelines.walk_forward_validation - INFO -   Results: WIN_RATE=0.00%, Precision=0.0000, Recall=0.0000, F1=0.0000
2025-12-21 01:46:53,788 - ml.src.pipelines.walk_forward_validation - INFO - Fold 10:
2025-12-21 01:46:53,788 - ml.src.pipelines.walk_forward_validation - INFO -   Train: [360:660] = 300 samples
2025-12-21 01:46:53,793 - ml.src.pipelines.walk_forward_validation - INFO -   Test:  [660:740] = 80 samples
2025-12-21 01:46:54,043 - ml.src.training.sequence_xgb_trainer - INFO - Class balance (train): pos=78, neg=222, imbalance_ratio=2.85
2025-12-21 01:46:54,044 - ml.src.training.sequence_xgb_trainer - INFO - Applied scale_pos_weight=2.8462 to handle class imbalance
2025-12-21 01:46:54,044 - ml.src.training.sequence_xgb_trainer - INFO - [POINT 1] Cost-Sensitive Learning: using sample weights (mean=1.5200)
2025-12-21 01:46:54,044 - ml.src.training.sequence_xgb_trainer - INFO - Training XGBoost classifier...
2025-12-21 01:47:12,033 - ml.src.training.sequence_xgb_trainer - INFO - Training completed
2025-12-21 01:47:12,041 - ml.src.training.sequence_evaluation - INFO - Probability stats: min=0.0065, max=0.9568, mean=0.3559, std=0.2692
2025-12-21 01:47:12,047 - ml.src.training.sequence_evaluation - INFO - Using HYBRID optimization: EV with precision AND recall floors...
2025-12-21 01:47:12,733 - __main__ - INFO - 
================================================================================
2025-12-21 01:47:12,733 - __main__ - INFO - WALK-FORWARD VALIDATION ANALYSIS
2025-12-21 01:47:12,733 - __main__ - INFO - ================================================================================
2025-12-21 01:47:12,734 - __main__ - INFO - Years: 2025
2025-12-21 01:47:12,734 - __main__ - INFO - Train window: 150 samples (~750 minutes)
2025-12-21 01:47:12,734 - __main__ - INFO - Test window: 40 samples (~200 minutes)
2025-12-21 01:47:12,735 - __main__ - INFO - Step size: 25 samples (~125 minutes)
2025-12-21 01:47:12,735 - __main__ - INFO - ================================================================================

2025-12-21 01:47:12,736 - __main__ - INFO - Loading data...
2025-12-21 01:47:12,739 - ml.src.data_loading.loaders - INFO - Year filter applied: loading only [2025]
2025-12-21 01:47:12,798 - __main__ - INFO - Loaded 18,875 M1 candles
2025-12-21 01:47:12,799 - __main__ - INFO - Aggregating to M5...
2025-12-21 01:47:12,799 - ml.src.features.engineer_m5 - INFO - Aggregating 18875 M1 candles to M5...
2025-12-21 01:47:12,812 - ml.src.features.engineer_m5 - INFO - Aggregated to 3776 M5 candles (5.0x compression)
2025-12-21 01:47:12,812 - __main__ - INFO - Aggregated to 3,776 M5 candles
2025-12-21 01:47:12,812 - __main__ - INFO - Engineering features...
2025-12-21 01:47:12,813 - ml.src.features.engineer_m5 - INFO - Engineering M5 features...
2025-12-21 01:47:12,813 - ml.src.features.engineer_m5 - INFO - Aggregating 3776 M1 candles to M5...
2025-12-21 01:47:12,825 - ml.src.features.engineer_m5 - INFO - Aggregated to 3776 M5 candles (1.0x compression)
2025-12-21 01:47:12,829 - ml.src.features.engineer_m5 - INFO - Computing M5 primary features...
2025-12-21 01:47:12,841 - ml.src.training.sequence_evaluation - INFO - Hybrid-optimized threshold: 0.57 with EV=0.3333 (precision=0.5556, recall=0.6667, win_coeff=1.0, loss_coeff=-1.0)
2025-12-21 01:47:12,844 - ml.src.training.sequence_evaluation - INFO - Confusion matrix@thr=0.57:
2025-12-21 01:47:12,845 - ml.src.training.sequence_evaluation - INFO -   [[TN=57, FP=8],
2025-12-21 01:47:12,845 - ml.src.training.sequence_evaluation - INFO -    [FN=5, TP=10]]
2025-12-21 01:47:12,853 - ml.src.pipelines.walk_forward_validation - INFO -   Results: WIN_RATE=55.56%, Precision=0.5556, Recall=0.6667, F1=0.6061
2025-12-21 01:47:12,854 - ml.src.pipelines.walk_forward_validation - INFO - Fold 11:
2025-12-21 01:47:12,854 - ml.src.pipelines.walk_forward_validation - INFO -   Train: [400:700] = 300 samples
2025-12-21 01:47:12,859 - ml.src.pipelines.walk_forward_validation - INFO -   Test:  [700:780] = 80 samples
2025-12-21 01:47:13,093 - ml.src.training.sequence_xgb_trainer - INFO - Class balance (train): pos=88, neg=212, imbalance_ratio=2.41
2025-12-21 01:47:13,094 - ml.src.training.sequence_xgb_trainer - INFO - Applied scale_pos_weight=2.4091 to handle class imbalance
2025-12-21 01:47:13,094 - ml.src.training.sequence_xgb_trainer - INFO - [POINT 1] Cost-Sensitive Learning: using sample weights (mean=1.5867)
2025-12-21 01:47:13,094 - ml.src.training.sequence_xgb_trainer - INFO - Training XGBoost classifier...
2025-12-21 01:47:13,283 - ml.src.features.engineer_m5 - INFO - Computing M15 context from M5...
2025-12-21 01:47:13,508 - ml.src.features.engineer_m5 - INFO - Computing M60 context from M5...
2025-12-21 01:47:13,602 - ml.src.features.engineer_m5 - INFO - M5 feature engineering complete: 3776 rows × 24 features
2025-12-21 01:47:13,603 - ml.src.features.engineer_m5 - INFO - Timeframe: M5 (5-minute candles)
2025-12-21 01:47:13,604 - ml.src.features.engineer_m5 - INFO - Date range: 2025-12-01 00:00:00 to 2025-12-18 17:35:00
2025-12-21 01:47:13,605 - __main__ - INFO - Engineered 24 features
2025-12-21 01:47:13,606 - __main__ - INFO - Creating targets...
2025-12-21 01:47:13,607 - ml.src.targets.target_maker - INFO - Creating targets (SL/TP simulation) for 3,776 candles...
2025-12-21 01:47:13,608 - ml.src.targets.target_maker - INFO - Parameters: SL=1×ATR, TP=3.0×ATR, min_hold=2min, max_horizon=60min
2025-12-21 01:47:13,610 - ml.src.targets.target_maker - INFO - Calculating M1 ATR(14) for SL/TP targets (fallback)
2025-12-21 01:47:13,620 - ml.src.targets.target_maker - INFO - Target creation complete: 3,716 valid targets
2025-12-21 01:47:13,623 - __main__ - INFO - Created targets: 871 positive, 2,845 negative
2025-12-21 01:47:13,624 - __main__ - INFO - Building sequences...
2025-12-21 01:47:13,631 - ml.src.sequences.sequencer - INFO - M5 alignment filter disabled; keeping all timestamps irrespective of minute alignment
2025-12-21 01:47:13,633 - ml.src.sequences.sequencer - INFO - Applied Trend Filter (dist_sma_200 > 0.00, ADX > 15.00): kept 1711/3667 (46.7%)
2025-12-21 01:47:13,633 - ml.src.sequences.sequencer - INFO - Pullback filter disabled; not constraining RSI_M5
2025-12-21 01:47:13,634 - ml.src.sequences.sequencer - INFO - Session filter 'london_ny': keeping 1,039 / 3,667 windows (28.3%)
2025-12-21 01:47:13,640 - __main__ - INFO - Built 1,039 sequences
2025-12-21 01:47:13,641 - ml.src.pipelines.walk_forward_validation - INFO - 
================================================================================
2025-12-21 01:47:13,642 - ml.src.pipelines.walk_forward_validation - INFO - [POINT 6] WALK-FORWARD CROSS-VALIDATION - Time-Series Validation
2025-12-21 01:47:13,642 - ml.src.pipelines.walk_forward_validation - INFO - ================================================================================
2025-12-21 01:47:13,643 - ml.src.pipelines.walk_forward_validation - INFO - Data size: 1,039 samples (1039 timestamps)
2025-12-21 01:47:13,644 - ml.src.pipelines.walk_forward_validation - INFO - Train window: 150 samples (~750 minutes)
2025-12-21 01:47:13,644 - ml.src.pipelines.walk_forward_validation - INFO - Test window: 40 samples (~200 minutes)
2025-12-21 01:47:13,644 - ml.src.pipelines.walk_forward_validation - INFO - Step size: 25 samples (~125 minutes)
2025-12-21 01:47:13,645 - ml.src.pipelines.walk_forward_validation - INFO - No lookahead bias: test set is ALWAYS future relative to training set
2025-12-21 01:47:13,646 - ml.src.pipelines.walk_forward_validation - INFO - ================================================================================

2025-12-21 01:47:13,646 - ml.src.pipelines.walk_forward_validation - INFO - Fold 1:
2025-12-21 01:47:13,647 - ml.src.pipelines.walk_forward_validation - INFO -   Train: [0:150] = 150 samples
2025-12-21 01:47:13,648 - ml.src.pipelines.walk_forward_validation - INFO -          2025-12-01 08:15 to 2025-12-03 20:05
2025-12-21 01:47:13,648 - ml.src.pipelines.walk_forward_validation - INFO -   Test:  [150:190] = 40 samples
2025-12-21 01:47:13,649 - ml.src.pipelines.walk_forward_validation - INFO -          2025-12-04 10:05 to 2025-12-04 17:15
2025-12-21 01:47:14,096 - ml.src.training.sequence_xgb_trainer - INFO - Class balance (train): pos=9, neg=96, imbalance_ratio=10.67
2025-12-21 01:47:14,097 - ml.src.training.sequence_xgb_trainer - INFO - Applied scale_pos_weight=10.6667 to handle class imbalance
2025-12-21 01:47:14,098 - ml.src.training.sequence_xgb_trainer - INFO - [POINT 1] Cost-Sensitive Learning: using sample weights (mean=1.1714)
2025-12-21 01:47:14,098 - ml.src.training.sequence_xgb_trainer - INFO - Training XGBoost classifier...
2025-12-21 01:47:15,699 - ml.src.training.sequence_xgb_trainer - INFO - Training completed
2025-12-21 01:47:15,707 - ml.src.training.sequence_evaluation - INFO - Probability stats: min=0.2430, max=0.4446, mean=0.3160, std=0.0601
2025-12-21 01:47:15,717 - ml.src.training.sequence_evaluation - INFO - Using HYBRID optimization: EV with precision AND recall floors...
2025-12-21 01:47:16,249 - ml.src.training.sequence_evaluation - WARNING - No threshold met BOTH precision >= 0.55 AND recall >= 0.20 with >= 10 trades. Falling back to F1-optimized with precision floor.
2025-12-21 01:47:16,397 - ml.src.training.sequence_evaluation - WARNING - No threshold met precision >= 0.55 with >= 10 trades. Falling back to maximizing precision with stability constraint.
2025-12-21 01:47:16,721 - ml.src.training.sequence_evaluation - INFO - Confusion matrix@thr=0.35:
2025-12-21 01:47:16,722 - ml.src.training.sequence_evaluation - INFO -   [[TN=28, FP=11],
2025-12-21 01:47:16,722 - ml.src.training.sequence_evaluation - INFO -    [FN=0, TP=1]]
2025-12-21 01:47:16,733 - ml.src.pipelines.walk_forward_validation - INFO -   Results: WIN_RATE=8.33%, Precision=0.0833, Recall=1.0000, F1=0.1538
2025-12-21 01:47:16,734 - ml.src.pipelines.walk_forward_validation - INFO - Fold 2:
2025-12-21 01:47:16,735 - ml.src.pipelines.walk_forward_validation - INFO -   Train: [25:175] = 150 samples
2025-12-21 01:47:16,735 - ml.src.pipelines.walk_forward_validation - INFO -          2025-12-01 10:55 to 2025-12-04 15:15
2025-12-21 01:47:16,736 - ml.src.pipelines.walk_forward_validation - INFO -   Test:  [175:215] = 40 samples
2025-12-21 01:47:16,738 - ml.src.pipelines.walk_forward_validation - INFO -          2025-12-04 15:20 to 2025-12-04 19:20
2025-12-21 01:47:17,071 - ml.src.training.sequence_xgb_trainer - INFO - Class balance (train): pos=19, neg=86, imbalance_ratio=4.53
2025-12-21 01:47:17,072 - ml.src.training.sequence_xgb_trainer - INFO - Applied scale_pos_weight=4.5263 to handle class imbalance
2025-12-21 01:47:17,073 - ml.src.training.sequence_xgb_trainer - INFO - [POINT 1] Cost-Sensitive Learning: using sample weights (mean=1.3619)
2025-12-21 01:47:17,074 - ml.src.training.sequence_xgb_trainer - INFO - Training XGBoost classifier...
2025-12-21 01:47:23,085 - ml.src.training.sequence_xgb_trainer - INFO - Training completed
2025-12-21 01:47:23,091 - ml.src.training.sequence_evaluation - INFO - Probability stats: min=0.0071, max=0.7627, mean=0.1612, std=0.1927
2025-12-21 01:47:23,101 - ml.src.training.sequence_evaluation - INFO - Using HYBRID optimization: EV with precision AND recall floors...
2025-12-21 01:47:23,492 - ml.src.training.sequence_evaluation - WARNING - No threshold met BOTH precision >= 0.55 AND recall >= 0.20 with >= 10 trades. Falling back to F1-optimized with precision floor.
2025-12-21 01:47:23,563 - ml.src.training.sequence_evaluation - WARNING - No threshold met precision >= 0.55 with >= 10 trades. Falling back to maximizing precision with stability constraint.
2025-12-21 01:47:23,711 - ml.src.training.sequence_evaluation - INFO - Confusion matrix@thr=0.20:
2025-12-21 01:47:23,712 - ml.src.training.sequence_evaluation - INFO -   [[TN=29, FP=11],
2025-12-21 01:47:23,713 - ml.src.training.sequence_evaluation - INFO -    [FN=0, TP=0]]
2025-12-21 01:47:23,728 - ml.src.pipelines.walk_forward_validation - INFO -   Results: WIN_RATE=0.00%, Precision=0.0000, Recall=0.0000, F1=0.0000
2025-12-21 01:47:23,730 - ml.src.pipelines.walk_forward_validation - INFO - Fold 3:
2025-12-21 01:47:23,732 - ml.src.pipelines.walk_forward_validation - INFO -   Train: [50:200] = 150 samples
2025-12-21 01:47:23,734 - ml.src.pipelines.walk_forward_validation - INFO -          2025-12-01 13:00 to 2025-12-04 18:05
2025-12-21 01:47:23,735 - ml.src.pipelines.walk_forward_validation - INFO -   Test:  [200:240] = 40 samples
2025-12-21 01:47:23,735 - ml.src.pipelines.walk_forward_validation - INFO -          2025-12-04 18:10 to 2025-12-05 08:50
2025-12-21 01:47:24,126 - ml.src.training.sequence_xgb_trainer - INFO - Class balance (train): pos=16, neg=89, imbalance_ratio=5.56
2025-12-21 01:47:24,127 - ml.src.training.sequence_xgb_trainer - INFO - Applied scale_pos_weight=5.5625 to handle class imbalance
2025-12-21 01:47:24,127 - ml.src.training.sequence_xgb_trainer - INFO - [POINT 1] Cost-Sensitive Learning: using sample weights (mean=1.3048)
2025-12-21 01:47:24,128 - ml.src.training.sequence_xgb_trainer - INFO - Training XGBoost classifier...
2025-12-21 01:47:29,146 - ml.src.training.sequence_xgb_trainer - INFO - Training completed
2025-12-21 01:47:29,151 - ml.src.training.sequence_evaluation - INFO - Probability stats: min=0.0049, max=0.1331, mean=0.0213, std=0.0229
2025-12-21 01:47:29,161 - ml.src.training.sequence_evaluation - INFO - Using HYBRID optimization: EV with precision AND recall floors...
2025-12-21 01:47:29,166 - ml.src.training.sequence_evaluation - WARNING - No threshold met BOTH precision >= 0.55 AND recall >= 0.20 with >= 10 trades. Falling back to F1-optimized with precision floor.
2025-12-21 01:47:29,175 - ml.src.training.sequence_evaluation - WARNING - No threshold met precision >= 0.55 with >= 10 trades. Falling back to maximizing precision with stability constraint.
2025-12-21 01:47:29,182 - ml.src.training.sequence_evaluation - INFO - Confusion matrix@thr=0.50:
2025-12-21 01:47:29,183 - ml.src.training.sequence_evaluation - INFO -   [[TN=40, FP=0],
2025-12-21 01:47:29,184 - ml.src.training.sequence_evaluation - INFO -    [FN=0, TP=0]]
2025-12-21 01:47:29,202 - ml.src.pipelines.walk_forward_validation - INFO -   Results: WIN_RATE=0.00%, Precision=0.0000, Recall=0.0000, F1=0.0000
2025-12-21 01:47:29,203 - ml.src.pipelines.walk_forward_validation - INFO - Fold 4:
2025-12-21 01:47:29,205 - ml.src.pipelines.walk_forward_validation - INFO -   Train: [75:225] = 150 samples
2025-12-21 01:47:29,208 - ml.src.pipelines.walk_forward_validation - INFO -          2025-12-02 14:20 to 2025-12-04 20:10
2025-12-21 01:47:29,209 - ml.src.pipelines.walk_forward_validation - INFO -   Test:  [225:265] = 40 samples
2025-12-21 01:47:29,209 - ml.src.pipelines.walk_forward_validation - INFO -          2025-12-04 20:15 to 2025-12-05 10:55
2025-12-21 01:47:29,593 - ml.src.training.sequence_xgb_trainer - INFO - Class balance (train): pos=16, neg=89, imbalance_ratio=5.56
2025-12-21 01:47:29,593 - ml.src.training.sequence_xgb_trainer - INFO - Applied scale_pos_weight=5.5625 to handle class imbalance
2025-12-21 01:47:29,594 - ml.src.training.sequence_xgb_trainer - INFO - [POINT 1] Cost-Sensitive Learning: using sample weights (mean=1.3048)
2025-12-21 01:47:29,594 - ml.src.training.sequence_xgb_trainer - INFO - Training XGBoost classifier...
2025-12-21 01:47:35,783 - ml.src.training.sequence_xgb_trainer - INFO - Training completed
2025-12-21 01:47:35,788 - ml.src.training.sequence_evaluation - INFO - Probability stats: min=0.0017, max=0.9760, mean=0.3128, std=0.2826
2025-12-21 01:47:35,796 - ml.src.training.sequence_evaluation - INFO - Using HYBRID optimization: EV with precision AND recall floors...
2025-12-21 01:47:36,476 - ml.src.training.sequence_evaluation - WARNING - No threshold met BOTH precision >= 0.55 AND recall >= 0.20 with >= 10 trades. Falling back to F1-optimized with precision floor.
2025-12-21 01:47:36,722 - ml.src.training.sequence_evaluation - WARNING - No threshold met precision >= 0.55 with >= 10 trades. Falling back to maximizing precision with stability constraint.
2025-12-21 01:47:37,229 - ml.src.training.sequence_evaluation - INFO - Confusion matrix@thr=0.58:
2025-12-21 01:47:37,230 - ml.src.training.sequence_evaluation - INFO -   [[TN=60, FP=12],
2025-12-21 01:47:37,230 - ml.src.training.sequence_evaluation - INFO -    [FN=4, TP=4]]
2025-12-21 01:47:37,236 - ml.src.pipelines.walk_forward_validation - INFO -   Results: WIN_RATE=25.00%, Precision=0.2500, Recall=0.5000, F1=0.3333
2025-12-21 01:47:37,237 - ml.src.pipelines.walk_forward_validation - INFO - Fold 12:
2025-12-21 01:47:37,237 - ml.src.pipelines.walk_forward_validation - INFO -   Train: [440:740] = 300 samples
2025-12-21 01:47:37,240 - ml.src.pipelines.walk_forward_validation - INFO -   Test:  [740:820] = 80 samples
2025-12-21 01:47:37,414 - ml.src.training.sequence_xgb_trainer - INFO - Class balance (train): pos=87, neg=213, imbalance_ratio=2.45
2025-12-21 01:47:37,415 - ml.src.training.sequence_xgb_trainer - INFO - Applied scale_pos_weight=2.4483 to handle class imbalance
2025-12-21 01:47:37,415 - ml.src.training.sequence_xgb_trainer - INFO - [POINT 1] Cost-Sensitive Learning: using sample weights (mean=1.5800)
2025-12-21 01:47:37,415 - ml.src.training.sequence_xgb_trainer - INFO - Training XGBoost classifier...
2025-12-21 01:47:51,397 - ml.src.training.sequence_xgb_trainer - INFO - Training completed
2025-12-21 01:47:51,404 - ml.src.training.sequence_evaluation - INFO - Probability stats: min=0.0010, max=0.9819, mean=0.2643, std=0.3545
2025-12-21 01:47:51,408 - ml.src.training.sequence_evaluation - INFO - Using HYBRID optimization: EV with precision AND recall floors...
2025-12-21 01:47:52,187 - ml.src.training.sequence_evaluation - WARNING - No threshold met BOTH precision >= 0.55 AND recall >= 0.20 with >= 10 trades. Falling back to F1-optimized with precision floor.
2025-12-21 01:47:52,720 - ml.src.training.sequence_evaluation - WARNING - No threshold met precision >= 0.55 with >= 10 trades. Falling back to maximizing precision with stability constraint.
2025-12-21 01:47:53,605 - ml.src.training.sequence_evaluation - INFO - Confusion matrix@thr=0.40:
2025-12-21 01:47:53,606 - ml.src.training.sequence_evaluation - INFO -   [[TN=53, FP=10],
2025-12-21 01:47:53,606 - ml.src.training.sequence_evaluation - INFO -    [FN=9, TP=8]]
2025-12-21 01:47:53,616 - ml.src.pipelines.walk_forward_validation - INFO -   Results: WIN_RATE=44.44%, Precision=0.4444, Recall=0.4706, F1=0.4571
2025-12-21 01:47:53,616 - ml.src.pipelines.walk_forward_validation - INFO - Fold 13:
2025-12-21 01:47:53,617 - ml.src.pipelines.walk_forward_validation - INFO -   Train: [480:780] = 300 samples
2025-12-21 01:47:53,620 - ml.src.pipelines.walk_forward_validation - INFO -   Test:  [780:860] = 80 samples
2025-12-21 01:47:53,903 - ml.src.training.sequence_xgb_trainer - INFO - Class balance (train): pos=84, neg=216, imbalance_ratio=2.57
2025-12-21 01:47:53,904 - ml.src.training.sequence_xgb_trainer - INFO - Applied scale_pos_weight=2.5714 to handle class imbalance
2025-12-21 01:47:53,904 - ml.src.training.sequence_xgb_trainer - INFO - [POINT 1] Cost-Sensitive Learning: using sample weights (mean=1.5600)
2025-12-21 01:47:53,905 - ml.src.training.sequence_xgb_trainer - INFO - Training XGBoost classifier...
2025-12-21 01:48:11,765 - ml.src.training.sequence_xgb_trainer - INFO - Training completed
2025-12-21 01:48:11,773 - ml.src.training.sequence_evaluation - INFO - Probability stats: min=0.0044, max=0.9953, mean=0.4670, std=0.4062
2025-12-21 01:48:11,777 - ml.src.training.sequence_evaluation - INFO - Using HYBRID optimization: EV with precision AND recall floors...
2025-12-21 01:48:12,666 - ml.src.training.sequence_evaluation - WARNING - No threshold met BOTH precision >= 0.55 AND recall >= 0.20 with >= 10 trades. Falling back to F1-optimized with precision floor.
2025-12-21 01:48:13,079 - ml.src.training.sequence_evaluation - WARNING - No threshold met precision >= 0.55 with >= 10 trades. Falling back to maximizing precision with stability constraint.
2025-12-21 01:48:13,835 - ml.src.training.sequence_evaluation - INFO - Confusion matrix@thr=0.92:
2025-12-21 01:48:13,836 - ml.src.training.sequence_evaluation - INFO -   [[TN=50, FP=18],
2025-12-21 01:48:13,836 - ml.src.training.sequence_evaluation - INFO -    [FN=5, TP=7]]
2025-12-21 01:48:13,846 - ml.src.pipelines.walk_forward_validation - INFO -   Results: WIN_RATE=28.00%, Precision=0.2800, Recall=0.5833, F1=0.3784
2025-12-21 01:48:13,847 - ml.src.pipelines.walk_forward_validation - INFO - Fold 14:
2025-12-21 01:48:13,847 - ml.src.pipelines.walk_forward_validation - INFO -   Train: [520:820] = 300 samples
2025-12-21 01:48:13,890 - ml.src.pipelines.walk_forward_validation - INFO -   Test:  [820:900] = 80 samples
2025-12-21 01:48:14,120 - ml.src.training.sequence_xgb_trainer - INFO - Class balance (train): pos=91, neg=209, imbalance_ratio=2.30
2025-12-21 01:48:14,121 - ml.src.training.sequence_xgb_trainer - INFO - Applied scale_pos_weight=2.2967 to handle class imbalance
2025-12-21 01:48:14,121 - ml.src.training.sequence_xgb_trainer - INFO - [POINT 1] Cost-Sensitive Learning: using sample weights (mean=1.6067)
2025-12-21 01:48:14,122 - ml.src.training.sequence_xgb_trainer - INFO - Training XGBoost classifier...
2025-12-21 01:48:18,989 - __main__ - INFO - 
================================================================================
2025-12-21 01:48:18,990 - __main__ - INFO - WALK-FORWARD VALIDATION ANALYSIS
2025-12-21 01:48:18,991 - __main__ - INFO - ================================================================================
2025-12-21 01:48:18,991 - __main__ - INFO - Years: 2025
2025-12-21 01:48:18,992 - __main__ - INFO - Train window: 100 samples (~500 minutes)
2025-12-21 01:48:18,992 - __main__ - INFO - Test window: 30 samples (~150 minutes)
2025-12-21 01:48:18,993 - __main__ - INFO - Step size: 20 samples (~100 minutes)
2025-12-21 01:48:18,993 - __main__ - INFO - ================================================================================

2025-12-21 01:48:18,994 - __main__ - INFO - Loading data...
2025-12-21 01:48:18,997 - ml.src.data_loading.loaders - INFO - Year filter applied: loading only [2025]
2025-12-21 01:48:19,106 - __main__ - INFO - Loaded 18,875 M1 candles
2025-12-21 01:48:19,107 - __main__ - INFO - Aggregating to M5...
2025-12-21 01:48:19,107 - ml.src.features.engineer_m5 - INFO - Aggregating 18875 M1 candles to M5...
2025-12-21 01:48:19,129 - ml.src.features.engineer_m5 - INFO - Aggregated to 3776 M5 candles (5.0x compression)
2025-12-21 01:48:19,129 - __main__ - INFO - Aggregated to 3,776 M5 candles
2025-12-21 01:48:19,130 - __main__ - INFO - Engineering features...
2025-12-21 01:48:19,131 - ml.src.features.engineer_m5 - INFO - Engineering M5 features...
2025-12-21 01:48:19,132 - ml.src.features.engineer_m5 - INFO - Aggregating 3776 M1 candles to M5...
2025-12-21 01:48:19,146 - ml.src.features.engineer_m5 - INFO - Aggregated to 3776 M5 candles (1.0x compression)
2025-12-21 01:48:19,152 - ml.src.features.engineer_m5 - INFO - Computing M5 primary features...
2025-12-21 01:48:19,872 - ml.src.features.engineer_m5 - INFO - Computing M15 context from M5...
2025-12-21 01:48:20,150 - ml.src.features.engineer_m5 - INFO - Computing M60 context from M5...
2025-12-21 01:48:20,258 - ml.src.features.engineer_m5 - INFO - M5 feature engineering complete: 3776 rows × 24 features
2025-12-21 01:48:20,259 - ml.src.features.engineer_m5 - INFO - Timeframe: M5 (5-minute candles)
2025-12-21 01:48:20,259 - ml.src.features.engineer_m5 - INFO - Date range: 2025-12-01 00:00:00 to 2025-12-18 17:35:00
2025-12-21 01:48:20,260 - __main__ - INFO - Engineered 24 features
2025-12-21 01:48:20,261 - __main__ - INFO - Creating targets...
2025-12-21 01:48:20,261 - ml.src.targets.target_maker - INFO - Creating targets (SL/TP simulation) for 3,776 candles...
2025-12-21 01:48:20,262 - ml.src.targets.target_maker - INFO - Parameters: SL=1×ATR, TP=3.0×ATR, min_hold=2min, max_horizon=60min
2025-12-21 01:48:20,263 - ml.src.targets.target_maker - INFO - Calculating M1 ATR(14) for SL/TP targets (fallback)
2025-12-21 01:48:20,272 - ml.src.targets.target_maker - INFO - Target creation complete: 3,716 valid targets
2025-12-21 01:48:20,273 - __main__ - INFO - Created targets: 871 positive, 2,845 negative
2025-12-21 01:48:20,273 - __main__ - INFO - Building sequences...
2025-12-21 01:48:20,280 - ml.src.sequences.sequencer - INFO - M5 alignment filter disabled; keeping all timestamps irrespective of minute alignment
2025-12-21 01:48:20,282 - ml.src.sequences.sequencer - INFO - Applied Trend Filter (dist_sma_200 > 0.00, ADX > 15.00): kept 1711/3667 (46.7%)
2025-12-21 01:48:20,282 - ml.src.sequences.sequencer - INFO - Pullback filter disabled; not constraining RSI_M5
2025-12-21 01:48:20,283 - ml.src.sequences.sequencer - INFO - Session filter 'london_ny': keeping 1,039 / 3,667 windows (28.3%)
2025-12-21 01:48:20,286 - __main__ - INFO - Built 1,039 sequences
2025-12-21 01:48:20,287 - ml.src.pipelines.walk_forward_validation - INFO - 
================================================================================
2025-12-21 01:48:20,288 - ml.src.pipelines.walk_forward_validation - INFO - [POINT 6] WALK-FORWARD CROSS-VALIDATION - Time-Series Validation
2025-12-21 01:48:20,288 - ml.src.pipelines.walk_forward_validation - INFO - ================================================================================
2025-12-21 01:48:20,289 - ml.src.pipelines.walk_forward_validation - INFO - Data size: 1,039 samples (1039 timestamps)
2025-12-21 01:48:20,289 - ml.src.pipelines.walk_forward_validation - INFO - Train window: 100 samples (~500 minutes)
2025-12-21 01:48:20,290 - ml.src.pipelines.walk_forward_validation - INFO - Test window: 30 samples (~150 minutes)
2025-12-21 01:48:20,290 - ml.src.pipelines.walk_forward_validation - INFO - Step size: 20 samples (~100 minutes)
2025-12-21 01:48:20,291 - ml.src.pipelines.walk_forward_validation - INFO - No lookahead bias: test set is ALWAYS future relative to training set
2025-12-21 01:48:20,291 - ml.src.pipelines.walk_forward_validation - INFO - ================================================================================

2025-12-21 01:48:20,292 - ml.src.pipelines.walk_forward_validation - INFO - Fold 1:
2025-12-21 01:48:20,292 - ml.src.pipelines.walk_forward_validation - INFO -   Train: [0:100] = 100 samples
2025-12-21 01:48:20,293 - ml.src.pipelines.walk_forward_validation - INFO -          2025-12-01 08:15 to 2025-12-02 21:45
2025-12-21 01:48:20,293 - ml.src.pipelines.walk_forward_validation - INFO -   Test:  [100:130] = 30 samples
2025-12-21 01:48:20,294 - ml.src.pipelines.walk_forward_validation - INFO -          2025-12-02 21:50 to 2025-12-03 14:10
2025-12-21 01:48:20,648 - ml.src.training.sequence_xgb_trainer - INFO - Class balance (train): pos=8, neg=62, imbalance_ratio=7.75
2025-12-21 01:48:20,649 - ml.src.training.sequence_xgb_trainer - INFO - Applied scale_pos_weight=7.7500 to handle class imbalance
2025-12-21 01:48:20,649 - ml.src.training.sequence_xgb_trainer - INFO - [POINT 1] Cost-Sensitive Learning: using sample weights (mean=1.2286)
2025-12-21 01:48:20,650 - ml.src.training.sequence_xgb_trainer - INFO - Training XGBoost classifier...
2025-12-21 01:48:21,838 - ml.src.training.sequence_xgb_trainer - INFO - Training completed
2025-12-21 01:48:21,846 - ml.src.training.sequence_evaluation - INFO - Probability stats: min=0.0626, max=0.6705, mean=0.2550, std=0.1476
2025-12-21 01:48:21,870 - ml.src.training.sequence_evaluation - INFO - Using HYBRID optimization: EV with precision AND recall floors...
2025-12-21 01:48:22,274 - ml.src.training.sequence_evaluation - INFO - Hybrid-optimized threshold: 0.11 with EV=0.8571 (precision=0.5652, recall=0.9286, win_coeff=1.0, loss_coeff=-1.0)
2025-12-21 01:48:22,280 - ml.src.training.sequence_evaluation - INFO - Confusion matrix@thr=0.11:
2025-12-21 01:48:22,282 - ml.src.training.sequence_evaluation - INFO -   [[TN=6, FP=10],
2025-12-21 01:48:22,284 - ml.src.training.sequence_evaluation - INFO -    [FN=1, TP=13]]
2025-12-21 01:48:22,301 - ml.src.pipelines.walk_forward_validation - INFO -   Results: WIN_RATE=56.52%, Precision=0.5652, Recall=0.9286, F1=0.7027
2025-12-21 01:48:22,302 - ml.src.pipelines.walk_forward_validation - INFO - Fold 2:
2025-12-21 01:48:22,303 - ml.src.pipelines.walk_forward_validation - INFO -   Train: [20:120] = 100 samples
2025-12-21 01:48:22,304 - ml.src.pipelines.walk_forward_validation - INFO -          2025-12-01 10:30 to 2025-12-03 13:20
2025-12-21 01:48:22,305 - ml.src.pipelines.walk_forward_validation - INFO -   Test:  [120:150] = 30 samples
2025-12-21 01:48:22,305 - ml.src.pipelines.walk_forward_validation - INFO -          2025-12-03 13:25 to 2025-12-03 20:05
2025-12-21 01:48:22,686 - ml.src.training.sequence_xgb_trainer - INFO - Class balance (train): pos=5, neg=65, imbalance_ratio=13.00
2025-12-21 01:48:22,690 - ml.src.training.sequence_xgb_trainer - INFO - Applied scale_pos_weight=13.0000 to handle class imbalance
2025-12-21 01:48:22,691 - ml.src.training.sequence_xgb_trainer - INFO - [POINT 1] Cost-Sensitive Learning: using sample weights (mean=1.1429)
2025-12-21 01:48:22,692 - ml.src.training.sequence_xgb_trainer - INFO - Training XGBoost classifier...
2025-12-21 01:48:23,841 - ml.src.training.sequence_xgb_trainer - INFO - Training completed
2025-12-21 01:48:23,846 - ml.src.training.sequence_evaluation - INFO - Probability stats: min=0.2419, max=0.4520, mean=0.2728, std=0.0541
2025-12-21 01:48:23,864 - ml.src.training.sequence_evaluation - INFO - Using HYBRID optimization: EV with precision AND recall floors...
2025-12-21 01:48:24,254 - ml.src.training.sequence_evaluation - WARNING - No threshold met BOTH precision >= 0.55 AND recall >= 0.20 with >= 10 trades. Falling back to F1-optimized with precision floor.
2025-12-21 01:48:24,331 - ml.src.training.sequence_evaluation - WARNING - No threshold met precision >= 0.55 with >= 10 trades. Falling back to maximizing precision with stability constraint.
2025-12-21 01:48:24,474 - ml.src.training.sequence_evaluation - INFO - Confusion matrix@thr=0.25:
2025-12-21 01:48:24,475 - ml.src.training.sequence_evaluation - INFO -   [[TN=16, FP=9],
2025-12-21 01:48:24,475 - ml.src.training.sequence_evaluation - INFO -    [FN=2, TP=3]]
2025-12-21 01:48:24,493 - ml.src.pipelines.walk_forward_validation - INFO -   Results: WIN_RATE=25.00%, Precision=0.2500, Recall=0.6000, F1=0.3529
2025-12-21 01:48:24,494 - ml.src.pipelines.walk_forward_validation - INFO - Fold 3:
2025-12-21 01:48:24,494 - ml.src.pipelines.walk_forward_validation - INFO -   Train: [40:140] = 100 samples
2025-12-21 01:48:24,495 - ml.src.pipelines.walk_forward_validation - INFO -          2025-12-01 12:10 to 2025-12-03 15:10
2025-12-21 01:48:24,496 - ml.src.pipelines.walk_forward_validation - INFO -   Test:  [140:170] = 30 samples
2025-12-21 01:48:24,498 - ml.src.pipelines.walk_forward_validation - INFO -          2025-12-03 15:15 to 2025-12-04 14:45
2025-12-21 01:48:24,863 - ml.src.training.sequence_xgb_trainer - INFO - Class balance (train): pos=6, neg=64, imbalance_ratio=10.67
2025-12-21 01:48:24,864 - ml.src.training.sequence_xgb_trainer - INFO - Applied scale_pos_weight=10.6667 to handle class imbalance
2025-12-21 01:48:24,865 - ml.src.training.sequence_xgb_trainer - INFO - [POINT 1] Cost-Sensitive Learning: using sample weights (mean=1.1714)
2025-12-21 01:48:24,865 - ml.src.training.sequence_xgb_trainer - INFO - Training XGBoost classifier...
2025-12-21 01:48:25,676 - ml.src.training.sequence_xgb_trainer - INFO - Training completed
2025-12-21 01:48:25,682 - ml.src.training.sequence_evaluation - INFO - Probability stats: min=0.3093, max=0.6253, mean=0.4424, std=0.0811
2025-12-21 01:48:25,692 - ml.src.training.sequence_evaluation - INFO - Using HYBRID optimization: EV with precision AND recall floors...
2025-12-21 01:48:26,487 - ml.src.training.sequence_evaluation - WARNING - No threshold met BOTH precision >= 0.55 AND recall >= 0.20 with >= 10 trades. Falling back to F1-optimized with precision floor.
2025-12-21 01:48:26,794 - ml.src.training.sequence_evaluation - WARNING - No threshold met precision >= 0.55 with >= 10 trades. Falling back to maximizing precision with stability constraint.
2025-12-21 01:48:27,432 - ml.src.training.sequence_evaluation - INFO - Confusion matrix@thr=0.20:
2025-12-21 01:48:27,433 - ml.src.training.sequence_evaluation - INFO -   [[TN=0, FP=30],
2025-12-21 01:48:27,434 - ml.src.training.sequence_evaluation - INFO -    [FN=0, TP=0]]
2025-12-21 01:48:27,453 - ml.src.pipelines.walk_forward_validation - INFO -   Results: WIN_RATE=0.00%, Precision=0.0000, Recall=0.0000, F1=0.0000
2025-12-21 01:48:27,454 - ml.src.pipelines.walk_forward_validation - INFO - Fold 4:
2025-12-21 01:48:27,456 - ml.src.pipelines.walk_forward_validation - INFO -   Train: [60:160] = 100 samples
2025-12-21 01:48:27,457 - ml.src.pipelines.walk_forward_validation - INFO -          2025-12-01 13:50 to 2025-12-04 11:40
2025-12-21 01:48:27,458 - ml.src.pipelines.walk_forward_validation - INFO -   Test:  [160:190] = 30 samples
2025-12-21 01:48:27,459 - ml.src.pipelines.walk_forward_validation - INFO -          2025-12-04 14:00 to 2025-12-04 17:15
2025-12-21 01:48:27,896 - ml.src.training.sequence_xgb_trainer - INFO - Class balance (train): pos=15, neg=55, imbalance_ratio=3.67
2025-12-21 01:48:27,897 - ml.src.training.sequence_xgb_trainer - INFO - Applied scale_pos_weight=3.6667 to handle class imbalance
2025-12-21 01:48:27,898 - ml.src.training.sequence_xgb_trainer - INFO - [POINT 1] Cost-Sensitive Learning: using sample weights (mean=1.4286)
2025-12-21 01:48:27,898 - ml.src.training.sequence_xgb_trainer - INFO - Training XGBoost classifier...
2025-12-21 01:48:29,015 - ml.src.training.sequence_xgb_trainer - INFO - Training completed
2025-12-21 01:48:29,025 - ml.src.training.sequence_evaluation - INFO - Probability stats: min=0.0738, max=0.7191, mean=0.2421, std=0.2005
2025-12-21 01:48:29,033 - ml.src.training.sequence_evaluation - INFO - Using HYBRID optimization: EV with precision AND recall floors...
2025-12-21 01:48:29,298 - ml.src.training.sequence_evaluation - WARNING - No threshold met BOTH precision >= 0.55 AND recall >= 0.20 with >= 10 trades. Falling back to F1-optimized with precision floor.
2025-12-21 01:48:29,302 - ml.src.training.sequence_evaluation - WARNING - No threshold met precision >= 0.55 with >= 10 trades. Falling back to maximizing precision with stability constraint.
2025-12-21 01:48:29,309 - ml.src.training.sequence_evaluation - INFO - Confusion matrix@thr=0.50:
2025-12-21 01:48:29,310 - ml.src.training.sequence_evaluation - INFO -   [[TN=26, FP=3],
2025-12-21 01:48:29,311 - ml.src.training.sequence_evaluation - INFO -    [FN=0, TP=1]]
2025-12-21 01:48:29,332 - ml.src.pipelines.walk_forward_validation - INFO -   Results: WIN_RATE=25.00%, Precision=0.2500, Recall=1.0000, F1=0.4000
2025-12-21 01:48:29,333 - ml.src.pipelines.walk_forward_validation - INFO - Fold 5:
2025-12-21 01:48:29,335 - ml.src.pipelines.walk_forward_validation - INFO -   Train: [80:180] = 100 samples
2025-12-21 01:48:29,336 - ml.src.pipelines.walk_forward_validation - INFO -          2025-12-02 14:45 to 2025-12-04 16:25
2025-12-21 01:48:29,337 - ml.src.pipelines.walk_forward_validation - INFO -   Test:  [180:210] = 30 samples
2025-12-21 01:48:29,338 - ml.src.pipelines.walk_forward_validation - INFO -          2025-12-04 16:30 to 2025-12-04 18:55
2025-12-21 01:48:29,741 - ml.src.training.sequence_xgb_trainer - INFO - Class balance (train): pos=15, neg=55, imbalance_ratio=3.67
2025-12-21 01:48:29,742 - ml.src.training.sequence_xgb_trainer - INFO - Applied scale_pos_weight=3.6667 to handle class imbalance
2025-12-21 01:48:29,743 - ml.src.training.sequence_xgb_trainer - INFO - [POINT 1] Cost-Sensitive Learning: using sample weights (mean=1.4286)
2025-12-21 01:48:29,743 - ml.src.training.sequence_xgb_trainer - INFO - Training XGBoost classifier...
2025-12-21 01:48:30,823 - ml.src.training.sequence_xgb_trainer - INFO - Training completed
2025-12-21 01:48:30,829 - ml.src.training.sequence_evaluation - INFO - Probability stats: min=0.0529, max=0.6267, mean=0.1262, std=0.1674
2025-12-21 01:48:30,836 - ml.src.training.sequence_evaluation - INFO - Using HYBRID optimization: EV with precision AND recall floors...
2025-12-21 01:48:30,842 - ml.src.training.sequence_evaluation - WARNING - No threshold met BOTH precision >= 0.55 AND recall >= 0.20 with >= 10 trades. Falling back to F1-optimized with precision floor.
2025-12-21 01:48:30,846 - ml.src.training.sequence_evaluation - WARNING - No threshold met precision >= 0.55 with >= 10 trades. Falling back to maximizing precision with stability constraint.
2025-12-21 01:48:30,852 - ml.src.training.sequence_evaluation - INFO - Confusion matrix@thr=0.50:
2025-12-21 01:48:30,853 - ml.src.training.sequence_evaluation - INFO -   [[TN=27, FP=3],
2025-12-21 01:48:30,855 - ml.src.training.sequence_evaluation - INFO -    [FN=0, TP=0]]
2025-12-21 01:48:30,871 - ml.src.pipelines.walk_forward_validation - INFO -   Results: WIN_RATE=0.00%, Precision=0.0000, Recall=0.0000, F1=0.0000
2025-12-21 01:48:30,875 - ml.src.pipelines.walk_forward_validation - INFO - Fold 6:
2025-12-21 01:48:30,876 - ml.src.pipelines.walk_forward_validation - INFO -   Train: [100:200] = 100 samples
2025-12-21 01:48:30,876 - ml.src.pipelines.walk_forward_validation - INFO -          2025-12-02 21:50 to 2025-12-04 18:05
2025-12-21 01:48:30,877 - ml.src.pipelines.walk_forward_validation - INFO -   Test:  [200:230] = 30 samples
2025-12-21 01:48:30,878 - ml.src.pipelines.walk_forward_validation - INFO -          2025-12-04 18:10 to 2025-12-04 20:35
2025-12-21 01:48:31,318 - ml.src.training.sequence_xgb_trainer - INFO - Class balance (train): pos=14, neg=56, imbalance_ratio=4.00
2025-12-21 01:48:31,319 - ml.src.training.sequence_xgb_trainer - INFO - Applied scale_pos_weight=4.0000 to handle class imbalance
2025-12-21 01:48:31,320 - ml.src.training.sequence_xgb_trainer - INFO - [POINT 1] Cost-Sensitive Learning: using sample weights (mean=1.4000)
2025-12-21 01:48:31,321 - ml.src.training.sequence_xgb_trainer - INFO - Training XGBoost classifier...
2025-12-21 01:48:32,301 - ml.src.training.sequence_xgb_trainer - INFO - Training completed
2025-12-21 01:48:32,306 - ml.src.training.sequence_evaluation - INFO - Probability stats: min=0.0495, max=0.4563, mean=0.1735, std=0.1765
2025-12-21 01:48:32,314 - ml.src.training.sequence_evaluation - INFO - Using HYBRID optimization: EV with precision AND recall floors...
2025-12-21 01:48:32,741 - ml.src.training.sequence_evaluation - WARNING - No threshold met BOTH precision >= 0.55 AND recall >= 0.20 with >= 10 trades. Falling back to F1-optimized with precision floor.
2025-12-21 01:48:32,826 - ml.src.training.sequence_evaluation - WARNING - No threshold met precision >= 0.55 with >= 10 trades. Falling back to maximizing precision with stability constraint.
2025-12-21 01:48:32,986 - ml.src.training.sequence_evaluation - INFO - Confusion matrix@thr=0.20:
2025-12-21 01:48:32,988 - ml.src.training.sequence_evaluation - INFO -   [[TN=20, FP=10],
2025-12-21 01:48:32,988 - ml.src.training.sequence_evaluation - INFO -    [FN=0, TP=0]]
2025-12-21 01:48:33,009 - ml.src.pipelines.walk_forward_validation - INFO -   Results: WIN_RATE=0.00%, Precision=0.0000, Recall=0.0000, F1=0.0000
2025-12-21 01:48:33,010 - ml.src.pipelines.walk_forward_validation - INFO - Fold 7:
2025-12-21 01:48:33,010 - ml.src.pipelines.walk_forward_validation - INFO -   Train: [120:220] = 100 samples
2025-12-21 01:48:33,011 - ml.src.pipelines.walk_forward_validation - INFO -          2025-12-03 13:25 to 2025-12-04 19:45
2025-12-21 01:48:33,011 - ml.src.pipelines.walk_forward_validation - INFO -   Test:  [220:250] = 30 samples
2025-12-21 01:48:33,012 - ml.src.pipelines.walk_forward_validation - INFO -          2025-12-04 19:50 to 2025-12-05 09:40
2025-12-21 01:48:33,414 - ml.src.training.sequence_xgb_trainer - INFO - Class balance (train): pos=6, neg=64, imbalance_ratio=10.67
2025-12-21 01:48:33,415 - ml.src.training.sequence_xgb_trainer - INFO - Applied scale_pos_weight=10.6667 to handle class imbalance
2025-12-21 01:48:33,415 - ml.src.training.sequence_xgb_trainer - INFO - [POINT 1] Cost-Sensitive Learning: using sample weights (mean=1.1714)
2025-12-21 01:48:33,416 - ml.src.training.sequence_xgb_trainer - INFO - Training XGBoost classifier...
2025-12-21 01:48:33,972 - ml.src.training.sequence_xgb_trainer - INFO - Training completed
2025-12-21 01:48:33,981 - ml.src.training.sequence_evaluation - INFO - Probability stats: min=0.0053, max=0.9778, mean=0.3322, std=0.3393
2025-12-21 01:48:33,991 - ml.src.training.sequence_evaluation - INFO - Using HYBRID optimization: EV with precision AND recall floors...
2025-12-21 01:48:34,301 - ml.src.training.sequence_xgb_trainer - INFO - Training completed
2025-12-21 01:48:34,306 - ml.src.training.sequence_evaluation - INFO - Probability stats: min=0.1131, max=0.1640, mean=0.1560, std=0.0120
2025-12-21 01:48:34,315 - ml.src.training.sequence_evaluation - INFO - Using HYBRID optimization: EV with precision AND recall floors...
2025-12-21 01:48:34,452 - ml.src.training.sequence_evaluation - WARNING - No threshold met BOTH precision >= 0.55 AND recall >= 0.20 with >= 10 trades. Falling back to F1-optimized with precision floor.
2025-12-21 01:48:34,455 - ml.src.training.sequence_evaluation - WARNING - No threshold met precision >= 0.55 with >= 10 trades. Falling back to maximizing precision with stability constraint.
2025-12-21 01:48:34,463 - ml.src.training.sequence_evaluation - INFO - Confusion matrix@thr=0.50:
2025-12-21 01:48:34,463 - ml.src.training.sequence_evaluation - INFO -   [[TN=24, FP=0],
2025-12-21 01:48:34,464 - ml.src.training.sequence_evaluation - INFO -    [FN=6, TP=0]]
2025-12-21 01:48:34,484 - ml.src.pipelines.walk_forward_validation - INFO -   Results: WIN_RATE=0.00%, Precision=0.0000, Recall=0.0000, F1=0.0000
2025-12-21 01:48:34,484 - ml.src.pipelines.walk_forward_validation - INFO - Fold 8:
2025-12-21 01:48:34,485 - ml.src.pipelines.walk_forward_validation - INFO -   Train: [140:240] = 100 samples
2025-12-21 01:48:34,486 - ml.src.pipelines.walk_forward_validation - INFO -          2025-12-03 15:15 to 2025-12-05 08:50
2025-12-21 01:48:34,486 - ml.src.pipelines.walk_forward_validation - INFO -   Test:  [240:270] = 30 samples
2025-12-21 01:48:34,487 - ml.src.pipelines.walk_forward_validation - INFO -          2025-12-05 08:55 to 2025-12-05 11:20
2025-12-21 01:48:34,755 - ml.src.training.sequence_xgb_trainer - INFO - Class balance (train): pos=1, neg=69, imbalance_ratio=69.00
2025-12-21 01:48:34,763 - ml.src.training.sequence_xgb_trainer - INFO - Applied scale_pos_weight=69.0000 to handle class imbalance
2025-12-21 01:48:34,765 - ml.src.training.sequence_xgb_trainer - INFO - [POINT 1] Cost-Sensitive Learning: using sample weights (mean=1.0286)
2025-12-21 01:48:34,767 - ml.src.training.sequence_xgb_trainer - INFO - Training XGBoost classifier...
2025-12-21 01:48:35,363 - ml.src.training.sequence_xgb_trainer - INFO - Training completed
2025-12-21 01:48:35,366 - ml.src.training.sequence_evaluation - INFO - Probability stats: min=0.0580, max=0.1319, mean=0.0779, std=0.0128
2025-12-21 01:48:35,380 - ml.src.training.sequence_evaluation - INFO - Using HYBRID optimization: EV with precision AND recall floors...
2025-12-21 01:48:35,382 - ml.src.training.sequence_evaluation - WARNING - No threshold met BOTH precision >= 0.55 AND recall >= 0.20 with >= 10 trades. Falling back to F1-optimized with precision floor.
2025-12-21 01:48:35,385 - ml.src.training.sequence_evaluation - WARNING - No threshold met precision >= 0.55 with >= 10 trades. Falling back to maximizing precision with stability constraint.
2025-12-21 01:48:35,392 - ml.src.training.sequence_evaluation - INFO - Confusion matrix@thr=0.50:
2025-12-21 01:48:35,393 - ml.src.training.sequence_evaluation - INFO -   [[TN=22, FP=0],
2025-12-21 01:48:35,393 - ml.src.training.sequence_evaluation - INFO -    [FN=8, TP=0]]
2025-12-21 01:48:35,411 - ml.src.pipelines.walk_forward_validation - INFO -   Results: WIN_RATE=0.00%, Precision=0.0000, Recall=0.0000, F1=0.0000
2025-12-21 01:48:35,412 - ml.src.pipelines.walk_forward_validation - INFO - Fold 9:
2025-12-21 01:48:35,412 - ml.src.pipelines.walk_forward_validation - INFO -   Train: [160:260] = 100 samples
2025-12-21 01:48:35,413 - ml.src.pipelines.walk_forward_validation - INFO -          2025-12-04 14:00 to 2025-12-05 10:30
2025-12-21 01:48:35,413 - ml.src.pipelines.walk_forward_validation - INFO -   Test:  [260:290] = 30 samples
2025-12-21 01:48:35,414 - ml.src.pipelines.walk_forward_validation - INFO -          2025-12-05 10:35 to 2025-12-05 13:00
2025-12-21 01:48:35,618 - ml.src.training.sequence_evaluation - WARNING - No threshold met BOTH precision >= 0.55 AND recall >= 0.20 with >= 10 trades. Falling back to F1-optimized with precision floor.
2025-12-21 01:48:35,667 - ml.src.training.sequence_xgb_trainer - INFO - Class balance (train): pos=1, neg=69, imbalance_ratio=69.00
2025-12-21 01:48:35,667 - ml.src.training.sequence_xgb_trainer - INFO - Applied scale_pos_weight=69.0000 to handle class imbalance
2025-12-21 01:48:35,668 - ml.src.training.sequence_xgb_trainer - INFO - [POINT 1] Cost-Sensitive Learning: using sample weights (mean=1.0286)
2025-12-21 01:48:35,668 - ml.src.training.sequence_xgb_trainer - INFO - Training XGBoost classifier...
2025-12-21 01:48:36,168 - ml.src.training.sequence_xgb_trainer - INFO - Training completed
2025-12-21 01:48:36,174 - ml.src.training.sequence_evaluation - INFO - Probability stats: min=0.1415, max=0.7628, mean=0.2355, std=0.1463
2025-12-21 01:48:36,192 - ml.src.training.sequence_evaluation - INFO - Using HYBRID optimization: EV with precision AND recall floors...
2025-12-21 01:48:36,309 - ml.src.training.sequence_evaluation - WARNING - No threshold met precision >= 0.55 with >= 10 trades. Falling back to maximizing precision with stability constraint.
2025-12-21 01:48:36,351 - ml.src.training.sequence_evaluation - WARNING - No threshold met BOTH precision >= 0.55 AND recall >= 0.20 with >= 10 trades. Falling back to F1-optimized with precision floor.
2025-12-21 01:48:36,353 - ml.src.training.sequence_evaluation - WARNING - No threshold met precision >= 0.55 with >= 10 trades. Falling back to maximizing precision with stability constraint.
2025-12-21 01:48:36,362 - ml.src.training.sequence_evaluation - INFO - Confusion matrix@thr=0.50:
2025-12-21 01:48:36,362 - ml.src.training.sequence_evaluation - INFO -   [[TN=16, FP=1],
2025-12-21 01:48:36,363 - ml.src.training.sequence_evaluation - INFO -    [FN=12, TP=1]]
2025-12-21 01:48:36,379 - ml.src.pipelines.walk_forward_validation - INFO -   Results: WIN_RATE=50.00%, Precision=0.5000, Recall=0.0769, F1=0.1333
2025-12-21 01:48:36,380 - ml.src.pipelines.walk_forward_validation - INFO - Fold 10:
2025-12-21 01:48:36,381 - ml.src.pipelines.walk_forward_validation - INFO -   Train: [180:280] = 100 samples
2025-12-21 01:48:36,381 - ml.src.pipelines.walk_forward_validation - INFO -          2025-12-04 16:30 to 2025-12-05 12:10
2025-12-21 01:48:36,382 - ml.src.pipelines.walk_forward_validation - INFO -   Test:  [280:310] = 30 samples
2025-12-21 01:48:36,383 - ml.src.pipelines.walk_forward_validation - INFO -          2025-12-05 12:15 to 2025-12-05 14:40
2025-12-21 01:48:36,687 - ml.src.training.sequence_xgb_trainer - INFO - Class balance (train): pos=6, neg=64, imbalance_ratio=10.67
2025-12-21 01:48:36,687 - ml.src.training.sequence_xgb_trainer - INFO - Applied scale_pos_weight=10.6667 to handle class imbalance
2025-12-21 01:48:36,688 - ml.src.training.sequence_xgb_trainer - INFO - [POINT 1] Cost-Sensitive Learning: using sample weights (mean=1.1714)
2025-12-21 01:48:36,688 - ml.src.training.sequence_xgb_trainer - INFO - Training XGBoost classifier...
2025-12-21 01:48:37,365 - ml.src.training.sequence_xgb_trainer - INFO - Training completed
2025-12-21 01:48:37,369 - ml.src.training.sequence_evaluation - INFO - Probability stats: min=0.2537, max=0.2954, mean=0.2779, std=0.0147
2025-12-21 01:48:37,377 - ml.src.training.sequence_evaluation - INFO - Using HYBRID optimization: EV with precision AND recall floors...
2025-12-21 01:48:37,648 - ml.src.training.sequence_evaluation - INFO - Confusion matrix@thr=0.33:
2025-12-21 01:48:37,648 - ml.src.training.sequence_evaluation - INFO -   [[TN=47, FP=23],
2025-12-21 01:48:37,649 - ml.src.training.sequence_evaluation - INFO -    [FN=4, TP=6]]
2025-12-21 01:48:37,657 - ml.src.pipelines.walk_forward_validation - INFO -   Results: WIN_RATE=20.69%, Precision=0.2069, Recall=0.6000, F1=0.3077
2025-12-21 01:48:37,658 - ml.src.pipelines.walk_forward_validation - INFO - Fold 15:
2025-12-21 01:48:37,659 - ml.src.pipelines.walk_forward_validation - INFO -   Train: [560:860] = 300 samples
2025-12-21 01:48:37,664 - ml.src.pipelines.walk_forward_validation - INFO -   Test:  [860:940] = 80 samples
2025-12-21 01:48:37,687 - ml.src.training.sequence_evaluation - WARNING - No threshold met BOTH precision >= 0.55 AND recall >= 0.20 with >= 10 trades. Falling back to F1-optimized with precision floor.
2025-12-21 01:48:37,753 - ml.src.training.sequence_evaluation - WARNING - No threshold met precision >= 0.55 with >= 10 trades. Falling back to maximizing precision with stability constraint.
2025-12-21 01:48:37,866 - ml.src.training.sequence_evaluation - INFO - Confusion matrix@thr=0.27:
2025-12-21 01:48:37,866 - ml.src.training.sequence_evaluation - INFO -   [[TN=7, FP=10],
2025-12-21 01:48:37,867 - ml.src.training.sequence_evaluation - INFO -    [FN=2, TP=11]]
2025-12-21 01:48:37,877 - ml.src.pipelines.walk_forward_validation - INFO -   Results: WIN_RATE=52.38%, Precision=0.5238, Recall=0.8462, F1=0.6471
2025-12-21 01:48:37,878 - ml.src.pipelines.walk_forward_validation - INFO - Fold 11:
2025-12-21 01:48:37,878 - ml.src.pipelines.walk_forward_validation - INFO -   Train: [200:300] = 100 samples
2025-12-21 01:48:37,879 - ml.src.pipelines.walk_forward_validation - INFO -          2025-12-04 18:10 to 2025-12-05 13:50
2025-12-21 01:48:37,879 - ml.src.pipelines.walk_forward_validation - INFO -   Test:  [300:330] = 30 samples
2025-12-21 01:48:37,880 - ml.src.pipelines.walk_forward_validation - INFO -          2025-12-05 13:55 to 2025-12-08 11:30
2025-12-21 01:48:37,932 - ml.src.training.sequence_xgb_trainer - INFO - Class balance (train): pos=70, neg=230, imbalance_ratio=3.29
2025-12-21 01:48:37,932 - ml.src.training.sequence_xgb_trainer - INFO - Applied scale_pos_weight=3.2857 to handle class imbalance
2025-12-21 01:48:37,933 - ml.src.training.sequence_xgb_trainer - INFO - [POINT 1] Cost-Sensitive Learning: using sample weights (mean=1.4667)
2025-12-21 01:48:37,933 - ml.src.training.sequence_xgb_trainer - INFO - Training XGBoost classifier...
2025-12-21 01:48:38,155 - ml.src.training.sequence_xgb_trainer - INFO - Class balance (train): pos=8, neg=62, imbalance_ratio=7.75
2025-12-21 01:48:38,156 - ml.src.training.sequence_xgb_trainer - INFO - Applied scale_pos_weight=7.7500 to handle class imbalance
2025-12-21 01:48:38,156 - ml.src.training.sequence_xgb_trainer - INFO - [POINT 1] Cost-Sensitive Learning: using sample weights (mean=1.2286)
2025-12-21 01:48:38,157 - ml.src.training.sequence_xgb_trainer - INFO - Training XGBoost classifier...
2025-12-21 01:48:38,855 - ml.src.training.sequence_xgb_trainer - INFO - Training completed
2025-12-21 01:48:38,863 - ml.src.training.sequence_evaluation - INFO - Probability stats: min=0.4456, max=0.5455, mean=0.4983, std=0.0304
2025-12-21 01:48:38,886 - ml.src.training.sequence_evaluation - INFO - Using HYBRID optimization: EV with precision AND recall floors...
2025-12-21 01:48:39,725 - ml.src.training.sequence_evaluation - WARNING - No threshold met BOTH precision >= 0.55 AND recall >= 0.20 with >= 10 trades. Falling back to F1-optimized with precision floor.
2025-12-21 01:48:40,064 - ml.src.training.sequence_evaluation - WARNING - No threshold met precision >= 0.55 with >= 10 trades. Falling back to maximizing precision with stability constraint.
2025-12-21 01:48:40,709 - ml.src.training.sequence_evaluation - INFO - Confusion matrix@thr=0.48:
2025-12-21 01:48:40,710 - ml.src.training.sequence_evaluation - INFO -   [[TN=8, FP=14],
2025-12-21 01:48:40,711 - ml.src.training.sequence_evaluation - INFO -    [FN=1, TP=7]]
2025-12-21 01:48:40,732 - ml.src.pipelines.walk_forward_validation - INFO -   Results: WIN_RATE=33.33%, Precision=0.3333, Recall=0.8750, F1=0.4828
2025-12-21 01:48:40,732 - ml.src.pipelines.walk_forward_validation - INFO - Fold 12:
2025-12-21 01:48:40,733 - ml.src.pipelines.walk_forward_validation - INFO -   Train: [220:320] = 100 samples
2025-12-21 01:48:40,734 - ml.src.pipelines.walk_forward_validation - INFO -          2025-12-04 19:50 to 2025-12-05 15:30
2025-12-21 01:48:40,734 - ml.src.pipelines.walk_forward_validation - INFO -   Test:  [320:350] = 30 samples
2025-12-21 01:48:40,735 - ml.src.pipelines.walk_forward_validation - INFO -          2025-12-05 15:35 to 2025-12-08 14:10
2025-12-21 01:48:41,100 - ml.src.training.sequence_xgb_trainer - INFO - Class balance (train): pos=19, neg=51, imbalance_ratio=2.68
2025-12-21 01:48:41,100 - ml.src.training.sequence_xgb_trainer - INFO - Applied scale_pos_weight=2.6842 to handle class imbalance
2025-12-21 01:48:41,101 - ml.src.training.sequence_xgb_trainer - INFO - [POINT 1] Cost-Sensitive Learning: using sample weights (mean=1.5429)
2025-12-21 01:48:41,102 - ml.src.training.sequence_xgb_trainer - INFO - Training XGBoost classifier...
2025-12-21 01:48:42,266 - ml.src.training.sequence_xgb_trainer - INFO - Training completed
2025-12-21 01:48:42,271 - ml.src.training.sequence_evaluation - INFO - Probability stats: min=0.2003, max=0.6845, mean=0.3812, std=0.1234
2025-12-21 01:48:42,278 - ml.src.training.sequence_evaluation - INFO - Using HYBRID optimization: EV with precision AND recall floors...
2025-12-21 01:48:43,024 - ml.src.training.sequence_evaluation - WARNING - No threshold met BOTH precision >= 0.55 AND recall >= 0.20 with >= 10 trades. Falling back to F1-optimized with precision floor.
2025-12-21 01:48:43,273 - ml.src.training.sequence_evaluation - WARNING - No threshold met precision >= 0.55 with >= 10 trades. Falling back to maximizing precision with stability constraint.
2025-12-21 01:48:43,835 - ml.src.training.sequence_evaluation - INFO - Confusion matrix@thr=0.20:
2025-12-21 01:48:43,837 - ml.src.training.sequence_evaluation - INFO -   [[TN=0, FP=30],
2025-12-21 01:48:43,838 - ml.src.training.sequence_evaluation - INFO -    [FN=0, TP=0]]
2025-12-21 01:48:43,867 - ml.src.pipelines.walk_forward_validation - INFO -   Results: WIN_RATE=0.00%, Precision=0.0000, Recall=0.0000, F1=0.0000
2025-12-21 01:48:43,869 - ml.src.pipelines.walk_forward_validation - INFO - Fold 13:
2025-12-21 01:48:43,870 - ml.src.pipelines.walk_forward_validation - INFO -   Train: [240:340] = 100 samples
2025-12-21 01:48:43,871 - ml.src.pipelines.walk_forward_validation - INFO -          2025-12-05 08:55 to 2025-12-08 12:20
2025-12-21 01:48:43,872 - ml.src.pipelines.walk_forward_validation - INFO -   Test:  [340:370] = 30 samples
2025-12-21 01:48:43,880 - ml.src.pipelines.walk_forward_validation - INFO -          2025-12-08 12:25 to 2025-12-09 10:00
2025-12-21 01:48:44,296 - ml.src.training.sequence_xgb_trainer - INFO - Class balance (train): pos=28, neg=42, imbalance_ratio=1.50
2025-12-21 01:48:44,297 - ml.src.training.sequence_xgb_trainer - INFO - Applied scale_pos_weight=1.5000 to handle class imbalance
2025-12-21 01:48:44,297 - ml.src.training.sequence_xgb_trainer - INFO - [POINT 1] Cost-Sensitive Learning: using sample weights (mean=1.8000)
2025-12-21 01:48:44,298 - ml.src.training.sequence_xgb_trainer - INFO - Training XGBoost classifier...
2025-12-21 01:48:45,412 - ml.src.training.sequence_xgb_trainer - INFO - Training completed
2025-12-21 01:48:45,418 - ml.src.training.sequence_evaluation - INFO - Probability stats: min=0.2910, max=0.8016, mean=0.5806, std=0.1214
2025-12-21 01:48:45,450 - ml.src.training.sequence_evaluation - INFO - Using HYBRID optimization: EV with precision AND recall floors...
2025-12-21 01:48:46,695 - ml.src.training.sequence_evaluation - WARNING - No threshold met BOTH precision >= 0.55 AND recall >= 0.20 with >= 10 trades. Falling back to F1-optimized with precision floor.
2025-12-21 01:48:47,152 - ml.src.training.sequence_evaluation - WARNING - No threshold met precision >= 0.55 with >= 10 trades. Falling back to maximizing precision with stability constraint.
2025-12-21 01:48:48,026 - ml.src.training.sequence_evaluation - INFO - Confusion matrix@thr=0.48:
2025-12-21 01:48:48,028 - ml.src.training.sequence_evaluation - INFO -   [[TN=4, FP=20],
2025-12-21 01:48:48,029 - ml.src.training.sequence_evaluation - INFO -    [FN=0, TP=6]]
2025-12-21 01:48:48,037 - ml.src.pipelines.walk_forward_validation - INFO -   Results: WIN_RATE=23.08%, Precision=0.2308, Recall=1.0000, F1=0.3750
2025-12-21 01:48:48,038 - ml.src.pipelines.walk_forward_validation - INFO - Fold 14:
2025-12-21 01:48:48,039 - ml.src.pipelines.walk_forward_validation - INFO -   Train: [260:360] = 100 samples
2025-12-21 01:48:48,039 - ml.src.pipelines.walk_forward_validation - INFO -          2025-12-05 10:35 to 2025-12-09 09:10
2025-12-21 01:48:48,040 - ml.src.pipelines.walk_forward_validation - INFO -   Test:  [360:390] = 30 samples
2025-12-21 01:48:48,040 - ml.src.pipelines.walk_forward_validation - INFO -          2025-12-09 09:15 to 2025-12-09 12:35
2025-12-21 01:48:48,428 - ml.src.training.sequence_xgb_trainer - INFO - Class balance (train): pos=26, neg=44, imbalance_ratio=1.69
2025-12-21 01:48:48,428 - ml.src.training.sequence_xgb_trainer - INFO - Applied scale_pos_weight=1.6923 to handle class imbalance
2025-12-21 01:48:48,429 - ml.src.training.sequence_xgb_trainer - INFO - [POINT 1] Cost-Sensitive Learning: using sample weights (mean=1.7429)
2025-12-21 01:48:48,430 - ml.src.training.sequence_xgb_trainer - INFO - Training XGBoost classifier...
2025-12-21 01:48:49,648 - ml.src.training.sequence_xgb_trainer - INFO - Training completed
2025-12-21 01:48:49,655 - ml.src.training.sequence_evaluation - INFO - Probability stats: min=0.2339, max=0.8597, mean=0.5558, std=0.2189
2025-12-21 01:48:49,676 - ml.src.training.sequence_evaluation - INFO - Using HYBRID optimization: EV with precision AND recall floors...
2025-12-21 01:48:51,361 - ml.src.training.sequence_evaluation - WARNING - No threshold met BOTH precision >= 0.55 AND recall >= 0.20 with >= 10 trades. Falling back to F1-optimized with precision floor.
2025-12-21 01:48:52,008 - ml.src.training.sequence_evaluation - WARNING - No threshold met precision >= 0.55 with >= 10 trades. Falling back to maximizing precision with stability constraint.
2025-12-21 01:48:53,269 - ml.src.training.sequence_evaluation - INFO - Confusion matrix@thr=0.41:
2025-12-21 01:48:53,270 - ml.src.training.sequence_evaluation - INFO -   [[TN=10, FP=18],
2025-12-21 01:48:53,271 - ml.src.training.sequence_evaluation - INFO -    [FN=0, TP=2]]
2025-12-21 01:48:53,289 - ml.src.pipelines.walk_forward_validation - INFO -   Results: WIN_RATE=10.00%, Precision=0.1000, Recall=1.0000, F1=0.1818
2025-12-21 01:48:53,290 - ml.src.pipelines.walk_forward_validation - INFO - Fold 15:
2025-12-21 01:48:53,290 - ml.src.pipelines.walk_forward_validation - INFO -   Train: [280:380] = 100 samples
2025-12-21 01:48:53,291 - ml.src.pipelines.walk_forward_validation - INFO -          2025-12-05 12:15 to 2025-12-09 10:50
2025-12-21 01:48:53,291 - ml.src.pipelines.walk_forward_validation - INFO -   Test:  [380:410] = 30 samples
2025-12-21 01:48:53,292 - ml.src.pipelines.walk_forward_validation - INFO -          2025-12-09 10:55 to 2025-12-09 15:00
2025-12-21 01:48:53,667 - ml.src.training.sequence_xgb_trainer - INFO - Class balance (train): pos=17, neg=53, imbalance_ratio=3.12
2025-12-21 01:48:53,667 - ml.src.training.sequence_xgb_trainer - INFO - Applied scale_pos_weight=3.1176 to handle class imbalance
2025-12-21 01:48:53,668 - ml.src.training.sequence_xgb_trainer - INFO - [POINT 1] Cost-Sensitive Learning: using sample weights (mean=1.4857)
2025-12-21 01:48:53,669 - ml.src.training.sequence_xgb_trainer - INFO - Training XGBoost classifier...
2025-12-21 01:48:54,820 - ml.src.training.sequence_xgb_trainer - INFO - Training completed
2025-12-21 01:48:54,826 - ml.src.training.sequence_evaluation - INFO - Probability stats: min=0.1867, max=0.7759, mean=0.5555, std=0.1637
2025-12-21 01:48:54,839 - ml.src.training.sequence_evaluation - INFO - Using HYBRID optimization: EV with precision AND recall floors...
2025-12-21 01:48:55,953 - ml.src.training.sequence_evaluation - WARNING - No threshold met BOTH precision >= 0.55 AND recall >= 0.20 with >= 10 trades. Falling back to F1-optimized with precision floor.
2025-12-21 01:48:56,417 - ml.src.training.sequence_evaluation - WARNING - No threshold met precision >= 0.55 with >= 10 trades. Falling back to maximizing precision with stability constraint.
2025-12-21 01:48:56,704 - ml.src.training.sequence_xgb_trainer - INFO - Training completed
2025-12-21 01:48:56,709 - ml.src.training.sequence_evaluation - INFO - Probability stats: min=0.0073, max=0.7390, mean=0.1885, std=0.1961
2025-12-21 01:48:56,717 - ml.src.training.sequence_evaluation - INFO - Using HYBRID optimization: EV with precision AND recall floors...
2025-12-21 01:48:57,157 - ml.src.training.sequence_evaluation - INFO - Confusion matrix@thr=0.61:
2025-12-21 01:48:57,158 - ml.src.training.sequence_evaluation - INFO -   [[TN=17, FP=11],
2025-12-21 01:48:57,159 - ml.src.training.sequence_evaluation - INFO -    [FN=0, TP=2]]
2025-12-21 01:48:57,167 - ml.src.pipelines.walk_forward_validation - INFO -   Results: WIN_RATE=15.38%, Precision=0.1538, Recall=1.0000, F1=0.2667
2025-12-21 01:48:57,168 - ml.src.pipelines.walk_forward_validation - INFO - Fold 16:
2025-12-21 01:48:57,168 - ml.src.pipelines.walk_forward_validation - INFO -   Train: [300:400] = 100 samples
2025-12-21 01:48:57,169 - ml.src.pipelines.walk_forward_validation - INFO -          2025-12-05 13:55 to 2025-12-09 13:25
2025-12-21 01:48:57,169 - ml.src.pipelines.walk_forward_validation - INFO -   Test:  [400:430] = 30 samples
2025-12-21 01:48:57,170 - ml.src.pipelines.walk_forward_validation - INFO -          2025-12-09 13:35 to 2025-12-09 16:55
2025-12-21 01:48:57,213 - ml.src.training.sequence_evaluation - WARNING - No threshold met BOTH precision >= 0.55 AND recall >= 0.20 with >= 10 trades. Falling back to F1-optimized with precision floor.
2025-12-21 01:48:57,381 - ml.src.training.sequence_evaluation - WARNING - No threshold met precision >= 0.55 with >= 10 trades. Falling back to maximizing precision with stability constraint.
2025-12-21 01:48:57,394 - ml.src.training.sequence_xgb_trainer - INFO - Class balance (train): pos=14, neg=56, imbalance_ratio=4.00
2025-12-21 01:48:57,395 - ml.src.training.sequence_xgb_trainer - INFO - Applied scale_pos_weight=4.0000 to handle class imbalance
2025-12-21 01:48:57,395 - ml.src.training.sequence_xgb_trainer - INFO - [POINT 1] Cost-Sensitive Learning: using sample weights (mean=1.4000)
2025-12-21 01:48:57,395 - ml.src.training.sequence_xgb_trainer - INFO - Training XGBoost classifier...
2025-12-21 01:48:57,953 - ml.src.training.sequence_evaluation - INFO - Confusion matrix@thr=0.20:
2025-12-21 01:48:57,954 - ml.src.training.sequence_evaluation - INFO -   [[TN=44, FP=18],
2025-12-21 01:48:57,955 - ml.src.training.sequence_evaluation - INFO -    [FN=8, TP=10]]
2025-12-21 01:48:57,975 - ml.src.pipelines.walk_forward_validation - INFO -   Results: WIN_RATE=35.71%, Precision=0.3571, Recall=0.5556, F1=0.4348
2025-12-21 01:48:57,975 - ml.src.pipelines.walk_forward_validation - INFO - Fold 16:
2025-12-21 01:48:57,976 - ml.src.pipelines.walk_forward_validation - INFO -   Train: [600:900] = 300 samples
2025-12-21 01:48:57,983 - ml.src.pipelines.walk_forward_validation - INFO -   Test:  [900:980] = 80 samples
2025-12-21 01:48:58,186 - ml.src.training.sequence_xgb_trainer - INFO - Training completed
2025-12-21 01:48:58,191 - ml.src.training.sequence_evaluation - INFO - Probability stats: min=0.1034, max=0.7609, mean=0.3957, std=0.2186
2025-12-21 01:48:58,199 - ml.src.training.sequence_evaluation - INFO - Using HYBRID optimization: EV with precision AND recall floors...
2025-12-21 01:48:58,373 - ml.src.training.sequence_xgb_trainer - INFO - Class balance (train): pos=67, neg=233, imbalance_ratio=3.48
2025-12-21 01:48:58,374 - ml.src.training.sequence_xgb_trainer - INFO - Applied scale_pos_weight=3.4776 to handle class imbalance
2025-12-21 01:48:58,374 - ml.src.training.sequence_xgb_trainer - INFO - [POINT 1] Cost-Sensitive Learning: using sample weights (mean=1.4467)
2025-12-21 01:48:58,375 - ml.src.training.sequence_xgb_trainer - INFO - Training XGBoost classifier...
2025-12-21 01:48:58,965 - ml.src.training.sequence_evaluation - WARNING - No threshold met BOTH precision >= 0.55 AND recall >= 0.20 with >= 10 trades. Falling back to F1-optimized with precision floor.
2025-12-21 01:48:59,323 - ml.src.training.sequence_evaluation - WARNING - No threshold met precision >= 0.55 with >= 10 trades. Falling back to maximizing precision with stability constraint.
2025-12-21 01:49:00,083 - ml.src.training.sequence_evaluation - INFO - Confusion matrix@thr=0.52:
2025-12-21 01:49:00,088 - ml.src.training.sequence_evaluation - INFO -   [[TN=18, FP=8],
2025-12-21 01:49:00,089 - ml.src.training.sequence_evaluation - INFO -    [FN=2, TP=2]]
2025-12-21 01:49:00,109 - ml.src.pipelines.walk_forward_validation - INFO -   Results: WIN_RATE=20.00%, Precision=0.2000, Recall=0.5000, F1=0.2857
2025-12-21 01:49:00,111 - ml.src.pipelines.walk_forward_validation - INFO - Fold 17:
2025-12-21 01:49:00,113 - ml.src.pipelines.walk_forward_validation - INFO -   Train: [320:420] = 100 samples
2025-12-21 01:49:00,116 - ml.src.pipelines.walk_forward_validation - INFO -          2025-12-05 15:35 to 2025-12-09 15:55
2025-12-21 01:49:00,118 - ml.src.pipelines.walk_forward_validation - INFO -   Test:  [420:450] = 30 samples
2025-12-21 01:49:00,119 - ml.src.pipelines.walk_forward_validation - INFO -          2025-12-09 16:10 to 2025-12-09 18:35
2025-12-21 01:49:00,518 - ml.src.training.sequence_xgb_trainer - INFO - Class balance (train): pos=8, neg=62, imbalance_ratio=7.75
2025-12-21 01:49:00,520 - ml.src.training.sequence_xgb_trainer - INFO - Applied scale_pos_weight=7.7500 to handle class imbalance
2025-12-21 01:49:00,520 - ml.src.training.sequence_xgb_trainer - INFO - [POINT 1] Cost-Sensitive Learning: using sample weights (mean=1.2286)
2025-12-21 01:49:00,521 - ml.src.training.sequence_xgb_trainer - INFO - Training XGBoost classifier...
2025-12-21 01:49:01,484 - ml.src.training.sequence_xgb_trainer - INFO - Training completed
2025-12-21 01:49:01,489 - ml.src.training.sequence_evaluation - INFO - Probability stats: min=0.0723, max=0.5241, mean=0.2428, std=0.1556
2025-12-21 01:49:01,496 - ml.src.training.sequence_evaluation - INFO - Using HYBRID optimization: EV with precision AND recall floors...
2025-12-21 01:49:01,904 - ml.src.training.sequence_evaluation - WARNING - No threshold met BOTH precision >= 0.55 AND recall >= 0.20 with >= 10 trades. Falling back to F1-optimized with precision floor.
2025-12-21 01:49:01,984 - ml.src.training.sequence_evaluation - WARNING - No threshold met precision >= 0.55 with >= 10 trades. Falling back to maximizing precision with stability constraint.
2025-12-21 01:49:02,172 - ml.src.training.sequence_evaluation - INFO - Confusion matrix@thr=0.29:
2025-12-21 01:49:02,172 - ml.src.training.sequence_evaluation - INFO -   [[TN=18, FP=7],
2025-12-21 01:49:02,173 - ml.src.training.sequence_evaluation - INFO -    [FN=2, TP=3]]
2025-12-21 01:49:02,184 - ml.src.pipelines.walk_forward_validation - INFO -   Results: WIN_RATE=30.00%, Precision=0.3000, Recall=0.6000, F1=0.4000
2025-12-21 01:49:02,186 - ml.src.pipelines.walk_forward_validation - INFO - Fold 18:
2025-12-21 01:49:02,187 - ml.src.pipelines.walk_forward_validation - INFO -   Train: [340:440] = 100 samples
2025-12-21 01:49:02,188 - ml.src.pipelines.walk_forward_validation - INFO -          2025-12-08 12:25 to 2025-12-09 17:45
2025-12-21 01:49:02,189 - ml.src.pipelines.walk_forward_validation - INFO -   Test:  [440:470] = 30 samples
2025-12-21 01:49:02,190 - ml.src.pipelines.walk_forward_validation - INFO -          2025-12-09 17:50 to 2025-12-09 20:15
2025-12-21 01:49:02,542 - ml.src.training.sequence_xgb_trainer - INFO - Class balance (train): pos=8, neg=62, imbalance_ratio=7.75
2025-12-21 01:49:02,542 - ml.src.training.sequence_xgb_trainer - INFO - Applied scale_pos_weight=7.7500 to handle class imbalance
2025-12-21 01:49:02,543 - ml.src.training.sequence_xgb_trainer - INFO - [POINT 1] Cost-Sensitive Learning: using sample weights (mean=1.2286)
2025-12-21 01:49:02,543 - ml.src.training.sequence_xgb_trainer - INFO - Training XGBoost classifier...
2025-12-21 01:49:02,981 - ml.src.training.sequence_xgb_trainer - INFO - Training completed
2025-12-21 01:49:02,986 - ml.src.training.sequence_evaluation - INFO - Probability stats: min=0.6915, max=0.6915, mean=0.6915, std=0.0000
2025-12-21 01:49:03,049 - ml.src.training.sequence_evaluation - INFO - Using HYBRID optimization: EV with precision AND recall floors...
2025-12-21 01:49:16,781 - ml.src.training.sequence_xgb_trainer - INFO - Training completed
2025-12-21 01:49:16,788 - ml.src.training.sequence_evaluation - INFO - Probability stats: min=0.0016, max=0.9431, mean=0.2433, std=0.2659
2025-12-21 01:49:16,796 - ml.src.training.sequence_evaluation - INFO - Using HYBRID optimization: EV with precision AND recall floors...
2025-12-21 01:49:17,300 - ml.src.training.sequence_evaluation - INFO - Hybrid-optimized threshold: 0.32 with EV=0.3000 (precision=0.5652, recall=0.6500, win_coeff=1.0, loss_coeff=-1.0)
2025-12-21 01:49:17,302 - ml.src.training.sequence_evaluation - INFO - Confusion matrix@thr=0.32:
2025-12-21 01:49:17,302 - ml.src.training.sequence_evaluation - INFO -   [[TN=50, FP=10],
2025-12-21 01:49:17,303 - ml.src.training.sequence_evaluation - INFO -    [FN=7, TP=13]]
2025-12-21 01:49:17,309 - ml.src.pipelines.walk_forward_validation - INFO -   Results: WIN_RATE=56.52%, Precision=0.5652, Recall=0.6500, F1=0.6047
2025-12-21 01:49:17,310 - ml.src.pipelines.walk_forward_validation - INFO - Fold 17:
2025-12-21 01:49:17,310 - ml.src.pipelines.walk_forward_validation - INFO -   Train: [640:940] = 300 samples
2025-12-21 01:49:17,313 - ml.src.pipelines.walk_forward_validation - INFO -   Test:  [940:1,020] = 80 samples
2025-12-21 01:49:17,485 - ml.src.training.sequence_xgb_trainer - INFO - Class balance (train): pos=64, neg=236, imbalance_ratio=3.69
2025-12-21 01:49:17,486 - ml.src.training.sequence_xgb_trainer - INFO - Applied scale_pos_weight=3.6875 to handle class imbalance
2025-12-21 01:49:17,486 - ml.src.training.sequence_xgb_trainer - INFO - [POINT 1] Cost-Sensitive Learning: using sample weights (mean=1.4267)
2025-12-21 01:49:17,487 - ml.src.training.sequence_xgb_trainer - INFO - Training XGBoost classifier...
2025-12-21 01:49:33,417 - ml.src.training.sequence_xgb_trainer - INFO - Training completed
2025-12-21 01:49:33,426 - ml.src.training.sequence_evaluation - INFO - Probability stats: min=0.0027, max=0.9380, mean=0.2671, std=0.2766
2025-12-21 01:49:33,435 - ml.src.training.sequence_evaluation - INFO - Using HYBRID optimization: EV with precision AND recall floors...
2025-12-21 01:49:34,276 - ml.src.training.sequence_evaluation - WARNING - No threshold met BOTH precision >= 0.55 AND recall >= 0.20 with >= 10 trades. Falling back to F1-optimized with precision floor.
2025-12-21 01:49:34,563 - ml.src.training.sequence_evaluation - WARNING - No threshold met precision >= 0.55 with >= 10 trades. Falling back to maximizing precision with stability constraint.
2025-12-21 01:49:35,520 - ml.src.training.sequence_evaluation - INFO - Confusion matrix@thr=0.51:
2025-12-21 01:49:35,520 - ml.src.training.sequence_evaluation - INFO -   [[TN=52, FP=13],
2025-12-21 01:49:35,521 - ml.src.training.sequence_evaluation - INFO -    [FN=9, TP=6]]
2025-12-21 01:49:35,532 - ml.src.pipelines.walk_forward_validation - INFO -   Results: WIN_RATE=31.58%, Precision=0.3158, Recall=0.4000, F1=0.3529
2025-12-21 01:49:35,532 - ml.src.pipelines.walk_forward_validation - INFO - 
================================================================================
2025-12-21 01:49:35,533 - ml.src.pipelines.walk_forward_validation - INFO - WALK-FORWARD VALIDATION RESULTS
2025-12-21 01:49:35,533 - ml.src.pipelines.walk_forward_validation - INFO - ================================================================================
2025-12-21 01:49:35,534 - ml.src.pipelines.walk_forward_validation - INFO - 
Aggregated Results (17 folds):

2025-12-21 01:49:35,535 - ml.src.pipelines.walk_forward_validation - INFO -   WIN RATE:   22.11% ± 20.99% (range: 0.00% - 56.52%)
2025-12-21 01:49:35,535 - ml.src.pipelines.walk_forward_validation - INFO -   Precision:  0.2211 ± 0.2099 (range: 0.0000 - 0.5652)
2025-12-21 01:49:35,535 - ml.src.pipelines.walk_forward_validation - INFO -   Recall:     0.3081 ± 0.2671 (range: 0.0000 - 0.6667)
2025-12-21 01:49:35,536 - ml.src.pipelines.walk_forward_validation - INFO -   F1 Score:   0.2506 ± 0.2251
2025-12-21 01:49:35,536 - ml.src.pipelines.walk_forward_validation - INFO -   ROC-AUC:    0.6242 ± 0.1370
2025-12-21 01:49:35,536 - ml.src.pipelines.walk_forward_validation - INFO - 
================================================================================
2025-12-21 01:49:35,537 - __main__ - INFO - 
================================================================================
2025-12-21 01:49:35,538 - __main__ - INFO - COMPARISON: Single Split vs Walk-Forward CV
2025-12-21 01:49:35,538 - __main__ - INFO - ================================================================================
2025-12-21 01:49:35,539 - __main__ - INFO - Baseline (single 70/15/15 split):     WIN_RATE = 85.71%
2025-12-21 01:49:35,542 - __main__ - INFO - Walk-Forward CV (17 folds): WIN_RATE = 22.11% ± 20.99%
2025-12-21 01:49:35,546 - __main__ - WARNING -      This suggests model may be overfitting or trading lookahead patterns.
2025-12-21 01:49:35,546 - __main__ - WARNING -      Baseline 85.71% may NOT be reliable for live trading.
2025-12-21 01:49:35,547 - __main__ - INFO - ================================================================================
2025-12-21 10:33:54,261 - __main__ - INFO - 
================================================================================
2025-12-21 10:33:54,262 - __main__ - INFO - WALK-FORWARD VALIDATION ANALYSIS
2025-12-21 10:33:54,262 - __main__ - INFO - ================================================================================
2025-12-21 10:33:54,263 - __main__ - INFO - Years: 2025
2025-12-21 10:33:54,263 - __main__ - INFO - Train window: 500 samples (~2500 minutes)
2025-12-21 10:33:54,264 - __main__ - INFO - Test window: 100 samples (~500 minutes)
2025-12-21 10:33:54,264 - __main__ - INFO - Step size: 50 samples (~250 minutes)
2025-12-21 10:33:54,264 - __main__ - INFO - ================================================================================

2025-12-21 10:33:54,265 - __main__ - INFO - Loading data...
2025-12-21 10:33:54,267 - ml.src.data_loading.loaders - INFO - Year filter applied: loading only [2025]
2025-12-21 10:33:54,400 - __main__ - INFO - Loaded 18,875 M1 candles
2025-12-21 10:33:54,401 - __main__ - INFO - Aggregating to M5...
2025-12-21 10:33:54,401 - ml.src.features.engineer_m5 - INFO - Aggregating 18875 M1 candles to M5...
2025-12-21 10:33:54,433 - ml.src.features.engineer_m5 - INFO - Aggregated to 3776 M5 candles (5.0x compression)
2025-12-21 10:33:54,433 - __main__ - INFO - Aggregated to 3,776 M5 candles
2025-12-21 10:33:54,434 - __main__ - INFO - Engineering features...
2025-12-21 10:33:54,434 - ml.src.features.engineer_m5 - INFO - Engineering M5 features...
2025-12-21 10:33:54,434 - ml.src.features.engineer_m5 - INFO - Aggregating 3776 M1 candles to M5...
2025-12-21 10:33:54,442 - ml.src.features.engineer_m5 - INFO - Aggregated to 3776 M5 candles (1.0x compression)
2025-12-21 10:33:54,445 - ml.src.features.engineer_m5 - INFO - Computing M5 primary features...
2025-12-21 10:33:54,729 - ml.src.features.engineer_m5 - INFO - Computing M15 context from M5...
2025-12-21 10:33:54,832 - ml.src.features.engineer_m5 - INFO - Computing M60 context from M5...
2025-12-21 10:33:54,875 - ml.src.features.engineer_m5 - INFO - M5 feature engineering complete: 3776 rows × 24 features
2025-12-21 10:33:54,876 - ml.src.features.engineer_m5 - INFO - Timeframe: M5 (5-minute candles)
2025-12-21 10:33:54,876 - ml.src.features.engineer_m5 - INFO - Date range: 2025-12-01 00:00:00 to 2025-12-18 17:35:00
2025-12-21 10:33:54,877 - __main__ - INFO - Engineered 24 features
2025-12-21 10:33:54,877 - __main__ - INFO - Creating targets...
2025-12-21 10:33:54,877 - ml.src.targets.target_maker - INFO - Creating targets (SL/TP simulation) for 3,776 candles...
2025-12-21 10:33:54,877 - ml.src.targets.target_maker - INFO - Parameters: SL=1×ATR, TP=3.0×ATR, min_hold=2min, max_horizon=60min
2025-12-21 10:33:54,878 - ml.src.targets.target_maker - INFO - Calculating M1 ATR(14) for SL/TP targets (fallback)
2025-12-21 10:33:54,885 - ml.src.targets.target_maker - INFO - Target creation complete: 3,716 valid targets
2025-12-21 10:33:54,886 - __main__ - INFO - Created targets: 871 positive, 2,845 negative
2025-12-21 10:33:54,887 - __main__ - INFO - Building sequences...
2025-12-21 10:33:54,900 - ml.src.sequences.sequencer - INFO - M5 alignment filter disabled; keeping all timestamps irrespective of minute alignment
2025-12-21 10:33:54,901 - ml.src.sequences.sequencer - INFO - Applied Trend Filter (dist_sma_200 > 0.00, ADX > 15.00): kept 1711/3667 (46.7%)
2025-12-21 10:33:54,901 - ml.src.sequences.sequencer - INFO - Pullback filter disabled; not constraining RSI_M5
2025-12-21 10:33:54,901 - ml.src.sequences.sequencer - INFO - Session filter 'london_ny': keeping 1,039 / 3,667 windows (28.3%)
2025-12-21 10:33:54,903 - __main__ - INFO - Built 1,039 sequences
2025-12-21 10:33:54,904 - ml.src.pipelines.walk_forward_validation - INFO - 
================================================================================
2025-12-21 10:33:54,904 - ml.src.pipelines.walk_forward_validation - INFO - [POINT 6] WALK-FORWARD CROSS-VALIDATION - Time-Series Validation
2025-12-21 10:33:54,904 - ml.src.pipelines.walk_forward_validation - INFO - ================================================================================
2025-12-21 10:33:54,904 - ml.src.pipelines.walk_forward_validation - INFO - Data size: 1,039 samples (1039 timestamps)
2025-12-21 10:33:54,905 - ml.src.pipelines.walk_forward_validation - INFO - Train window: 500 samples (~2500 minutes)
2025-12-21 10:33:54,905 - ml.src.pipelines.walk_forward_validation - INFO - Test window: 100 samples (~500 minutes)
2025-12-21 10:33:54,905 - ml.src.pipelines.walk_forward_validation - INFO - Step size: 50 samples (~250 minutes)
2025-12-21 10:33:54,905 - ml.src.pipelines.walk_forward_validation - INFO - No lookahead bias: test set is ALWAYS future relative to training set
2025-12-21 10:33:54,906 - ml.src.pipelines.walk_forward_validation - INFO - ================================================================================

2025-12-21 10:33:54,906 - ml.src.pipelines.walk_forward_validation - INFO - Fold 1:
2025-12-21 10:33:54,906 - ml.src.pipelines.walk_forward_validation - INFO -   Train: [0:500] = 500 samples
2025-12-21 10:33:54,907 - ml.src.pipelines.walk_forward_validation - INFO -          2025-12-01 08:15 to 2025-12-10 19:30
2025-12-21 10:33:54,907 - ml.src.pipelines.walk_forward_validation - INFO -   Test:  [500:600] = 100 samples
2025-12-21 10:33:54,907 - ml.src.pipelines.walk_forward_validation - INFO -          2025-12-10 19:35 to 2025-12-11 18:50
2025-12-21 10:33:55,165 - ml.src.training.sequence_xgb_trainer - INFO - Class balance (train): pos=56, neg=294, imbalance_ratio=5.25
2025-12-21 10:33:55,166 - ml.src.training.sequence_xgb_trainer - INFO - Applied scale_pos_weight=5.2500 to handle class imbalance
2025-12-21 10:33:55,166 - ml.src.training.sequence_xgb_trainer - INFO - [POINT 1] Cost-Sensitive Learning: using sample weights (mean=1.3200)
2025-12-21 10:33:55,167 - ml.src.training.sequence_xgb_trainer - INFO - Training XGBoost classifier...
2025-12-21 10:34:00,984 - ml.src.training.sequence_xgb_trainer - INFO - Training completed
2025-12-21 10:34:00,994 - ml.src.training.sequence_evaluation - INFO - Probability stats: min=0.0833, max=0.3957, mean=0.1632, std=0.0671
2025-12-21 10:34:01,010 - ml.src.training.sequence_evaluation - INFO - Using HYBRID optimization: EV with precision AND recall floors...
2025-12-21 10:34:01,462 - ml.src.training.sequence_evaluation - WARNING - No threshold met BOTH precision >= 0.55 AND recall >= 0.20 with >= 10 trades. Falling back to F1-optimized with precision floor.
2025-12-21 10:34:01,582 - ml.src.training.sequence_evaluation - INFO - Confusion matrix@thr=0.27:
2025-12-21 10:34:01,583 - ml.src.training.sequence_evaluation - INFO -   [[TN=59, FP=4],
2025-12-21 10:34:01,583 - ml.src.training.sequence_evaluation - INFO -    [FN=31, TP=6]]
2025-12-21 10:34:01,601 - ml.src.pipelines.walk_forward_validation - INFO -   Results: WIN_RATE=60.00%, Precision=0.6000, Recall=0.1622, F1=0.2553
2025-12-21 10:34:01,602 - ml.src.pipelines.walk_forward_validation - INFO - Fold 2:
2025-12-21 10:34:01,603 - ml.src.pipelines.walk_forward_validation - INFO -   Train: [50:550] = 500 samples
2025-12-21 10:34:01,605 - ml.src.pipelines.walk_forward_validation - INFO -          2025-12-01 13:00 to 2025-12-11 14:40
2025-12-21 10:34:01,606 - ml.src.pipelines.walk_forward_validation - INFO -   Test:  [550:650] = 100 samples
2025-12-21 10:34:01,608 - ml.src.pipelines.walk_forward_validation - INFO -          2025-12-11 14:45 to 2025-12-12 09:00
2025-12-21 10:34:01,909 - ml.src.training.sequence_xgb_trainer - INFO - Class balance (train): pos=57, neg=293, imbalance_ratio=5.14
2025-12-21 10:34:01,909 - ml.src.training.sequence_xgb_trainer - INFO - Applied scale_pos_weight=5.1404 to handle class imbalance
2025-12-21 10:34:01,910 - ml.src.training.sequence_xgb_trainer - INFO - [POINT 1] Cost-Sensitive Learning: using sample weights (mean=1.3257)
2025-12-21 10:34:01,910 - ml.src.training.sequence_xgb_trainer - INFO - Training XGBoost classifier...
2025-12-21 10:34:11,639 - __main__ - INFO - 
================================================================================
2025-12-21 10:34:11,639 - __main__ - INFO - WALK-FORWARD VALIDATION ANALYSIS
2025-12-21 10:34:11,640 - __main__ - INFO - ================================================================================
2025-12-21 10:34:11,640 - __main__ - INFO - Years: 2025
2025-12-21 10:34:11,640 - __main__ - INFO - Train window: 300 samples (~1500 minutes)
2025-12-21 10:34:11,641 - __main__ - INFO - Test window: 50 samples (~250 minutes)
2025-12-21 10:34:11,641 - __main__ - INFO - Step size: 50 samples (~250 minutes)
2025-12-21 10:34:11,641 - __main__ - INFO - ================================================================================

2025-12-21 10:34:11,641 - __main__ - INFO - Loading data...
2025-12-21 10:34:11,643 - ml.src.data_loading.loaders - INFO - Year filter applied: loading only [2025]
2025-12-21 10:34:11,687 - __main__ - INFO - Loaded 18,875 M1 candles
2025-12-21 10:34:11,688 - __main__ - INFO - Aggregating to M5...
2025-12-21 10:34:11,688 - ml.src.features.engineer_m5 - INFO - Aggregating 18875 M1 candles to M5...
2025-12-21 10:34:11,698 - ml.src.features.engineer_m5 - INFO - Aggregated to 3776 M5 candles (5.0x compression)
2025-12-21 10:34:11,698 - __main__ - INFO - Aggregated to 3,776 M5 candles
2025-12-21 10:34:11,698 - __main__ - INFO - Engineering features...
2025-12-21 10:34:11,699 - ml.src.features.engineer_m5 - INFO - Engineering M5 features...
2025-12-21 10:34:11,699 - ml.src.features.engineer_m5 - INFO - Aggregating 3776 M1 candles to M5...
2025-12-21 10:34:11,706 - ml.src.features.engineer_m5 - INFO - Aggregated to 3776 M5 candles (1.0x compression)
2025-12-21 10:34:11,709 - ml.src.features.engineer_m5 - INFO - Computing M5 primary features...
2025-12-21 10:34:12,092 - ml.src.features.engineer_m5 - INFO - Computing M15 context from M5...
2025-12-21 10:34:12,192 - ml.src.features.engineer_m5 - INFO - Computing M60 context from M5...
2025-12-21 10:34:12,246 - ml.src.features.engineer_m5 - INFO - M5 feature engineering complete: 3776 rows × 24 features
2025-12-21 10:34:12,247 - ml.src.features.engineer_m5 - INFO - Timeframe: M5 (5-minute candles)
2025-12-21 10:34:12,247 - ml.src.features.engineer_m5 - INFO - Date range: 2025-12-01 00:00:00 to 2025-12-18 17:35:00
2025-12-21 10:34:12,248 - __main__ - INFO - Engineered 24 features
2025-12-21 10:34:12,249 - __main__ - INFO - Creating targets...
2025-12-21 10:34:12,249 - ml.src.targets.target_maker - INFO - Creating targets (SL/TP simulation) for 3,776 candles...
2025-12-21 10:34:12,249 - ml.src.targets.target_maker - INFO - Parameters: SL=1×ATR, TP=3.0×ATR, min_hold=2min, max_horizon=60min
2025-12-21 10:34:12,250 - ml.src.targets.target_maker - INFO - Calculating M1 ATR(14) for SL/TP targets (fallback)
2025-12-21 10:34:12,254 - ml.src.targets.target_maker - INFO - Target creation complete: 3,716 valid targets
2025-12-21 10:34:12,255 - __main__ - INFO - Created targets: 871 positive, 2,845 negative
2025-12-21 10:34:12,255 - __main__ - INFO - Building sequences...
2025-12-21 10:34:12,258 - ml.src.sequences.sequencer - INFO - M5 alignment filter disabled; keeping all timestamps irrespective of minute alignment
2025-12-21 10:34:12,259 - ml.src.sequences.sequencer - INFO - Applied Trend Filter (dist_sma_200 > 0.00, ADX > 15.00): kept 1711/3667 (46.7%)
2025-12-21 10:34:12,260 - ml.src.sequences.sequencer - INFO - Pullback filter disabled; not constraining RSI_M5
2025-12-21 10:34:12,261 - ml.src.sequences.sequencer - INFO - Session filter 'london_ny': keeping 1,039 / 3,667 windows (28.3%)
2025-12-21 10:34:12,263 - __main__ - INFO - Built 1,039 sequences
2025-12-21 10:34:12,264 - ml.src.pipelines.walk_forward_validation - INFO - 
================================================================================
2025-12-21 10:34:12,264 - ml.src.pipelines.walk_forward_validation - INFO - [POINT 6] WALK-FORWARD CROSS-VALIDATION - Time-Series Validation
2025-12-21 10:34:12,264 - ml.src.pipelines.walk_forward_validation - INFO - ================================================================================
2025-12-21 10:34:12,265 - ml.src.pipelines.walk_forward_validation - INFO - Data size: 1,039 samples (1039 timestamps)
2025-12-21 10:34:12,265 - ml.src.pipelines.walk_forward_validation - INFO - Train window: 300 samples (~1500 minutes)
2025-12-21 10:34:12,265 - ml.src.pipelines.walk_forward_validation - INFO - Test window: 50 samples (~250 minutes)
2025-12-21 10:34:12,265 - ml.src.pipelines.walk_forward_validation - INFO - Step size: 50 samples (~250 minutes)
2025-12-21 10:34:12,266 - ml.src.pipelines.walk_forward_validation - INFO - No lookahead bias: test set is ALWAYS future relative to training set
2025-12-21 10:34:12,266 - ml.src.pipelines.walk_forward_validation - INFO - ================================================================================

2025-12-21 10:34:12,266 - ml.src.pipelines.walk_forward_validation - INFO - Fold 1:
2025-12-21 10:34:12,267 - ml.src.pipelines.walk_forward_validation - INFO -   Train: [0:300] = 300 samples
2025-12-21 10:34:12,267 - ml.src.pipelines.walk_forward_validation - INFO -          2025-12-01 08:15 to 2025-12-05 13:50
2025-12-21 10:34:12,267 - ml.src.pipelines.walk_forward_validation - INFO -   Test:  [300:350] = 50 samples
2025-12-21 10:34:12,268 - ml.src.pipelines.walk_forward_validation - INFO -          2025-12-05 13:55 to 2025-12-08 14:10
2025-12-21 10:34:12,436 - ml.src.training.sequence_xgb_trainer - INFO - Class balance (train): pos=24, neg=186, imbalance_ratio=7.75
2025-12-21 10:34:12,436 - ml.src.training.sequence_xgb_trainer - INFO - Applied scale_pos_weight=7.7500 to handle class imbalance
2025-12-21 10:34:12,437 - ml.src.training.sequence_xgb_trainer - INFO - [POINT 1] Cost-Sensitive Learning: using sample weights (mean=1.2286)
2025-12-21 10:34:12,438 - ml.src.training.sequence_xgb_trainer - INFO - Training XGBoost classifier...
2025-12-21 10:34:15,298 - ml.src.training.sequence_xgb_trainer - INFO - Training completed
2025-12-21 10:34:15,303 - ml.src.training.sequence_evaluation - INFO - Probability stats: min=0.1422, max=0.5071, mean=0.2484, std=0.0949
2025-12-21 10:34:15,310 - ml.src.training.sequence_evaluation - WARNING - [WARNING] Model has very low discriminative power (ROC-AUC=0.5089). Results may be random.
2025-12-21 10:34:15,314 - ml.src.training.sequence_evaluation - INFO - Using HYBRID optimization: EV with precision AND recall floors...
2025-12-21 10:34:15,584 - ml.src.training.sequence_evaluation - WARNING - No threshold met BOTH precision >= 0.55 AND recall >= 0.20 with >= 10 trades. Falling back to F1-optimized with precision floor.
2025-12-21 10:34:15,642 - ml.src.training.sequence_evaluation - WARNING - No threshold met precision >= 0.55 with >= 10 trades. Falling back to maximizing precision with stability constraint.
2025-12-21 10:34:15,752 - ml.src.training.sequence_evaluation - INFO - Confusion matrix@thr=0.29:
2025-12-21 10:34:15,753 - ml.src.training.sequence_evaluation - INFO -   [[TN=31, FP=11],
2025-12-21 10:34:15,753 - ml.src.training.sequence_evaluation - INFO -    [FN=5, TP=3]]
2025-12-21 10:34:15,759 - ml.src.pipelines.walk_forward_validation - INFO -   Results: WIN_RATE=21.43%, Precision=0.2143, Recall=0.3750, F1=0.2727
2025-12-21 10:34:15,759 - ml.src.pipelines.walk_forward_validation - INFO - Fold 2:
2025-12-21 10:34:15,760 - ml.src.pipelines.walk_forward_validation - INFO -   Train: [50:350] = 300 samples
2025-12-21 10:34:15,760 - ml.src.pipelines.walk_forward_validation - INFO -          2025-12-01 13:00 to 2025-12-08 14:10
2025-12-21 10:34:15,760 - ml.src.pipelines.walk_forward_validation - INFO -   Test:  [350:400] = 50 samples
2025-12-21 10:34:15,761 - ml.src.pipelines.walk_forward_validation - INFO -          2025-12-08 14:15 to 2025-12-09 13:25
2025-12-21 10:34:15,925 - ml.src.training.sequence_xgb_trainer - INFO - Class balance (train): pos=23, neg=187, imbalance_ratio=8.13
2025-12-21 10:34:15,926 - ml.src.training.sequence_xgb_trainer - INFO - Applied scale_pos_weight=8.1304 to handle class imbalance
2025-12-21 10:34:15,926 - ml.src.training.sequence_xgb_trainer - INFO - [POINT 1] Cost-Sensitive Learning: using sample weights (mean=1.2190)
2025-12-21 10:34:15,926 - ml.src.training.sequence_xgb_trainer - INFO - Training XGBoost classifier...
2025-12-21 10:34:18,563 - ml.src.training.sequence_xgb_trainer - INFO - Training completed
2025-12-21 10:34:18,569 - ml.src.training.sequence_evaluation - INFO - Probability stats: min=0.0432, max=0.4331, mean=0.1101, std=0.0817
2025-12-21 10:34:18,576 - ml.src.training.sequence_evaluation - INFO - Using HYBRID optimization: EV with precision AND recall floors...
2025-12-21 10:34:18,659 - ml.src.training.sequence_evaluation - WARNING - No threshold met BOTH precision >= 0.55 AND recall >= 0.20 with >= 10 trades. Falling back to F1-optimized with precision floor.
2025-12-21 10:34:18,663 - ml.src.training.sequence_evaluation - WARNING - No threshold met precision >= 0.55 with >= 10 trades. Falling back to maximizing precision with stability constraint.
2025-12-21 10:34:18,668 - ml.src.training.sequence_evaluation - INFO - Confusion matrix@thr=0.50:
2025-12-21 10:34:18,669 - ml.src.training.sequence_evaluation - INFO -   [[TN=42, FP=0],
2025-12-21 10:34:18,669 - ml.src.training.sequence_evaluation - INFO -    [FN=8, TP=0]]
2025-12-21 10:34:18,678 - ml.src.pipelines.walk_forward_validation - INFO -   Results: WIN_RATE=0.00%, Precision=0.0000, Recall=0.0000, F1=0.0000
2025-12-21 10:34:18,678 - ml.src.pipelines.walk_forward_validation - INFO - Fold 3:
2025-12-21 10:34:18,678 - ml.src.pipelines.walk_forward_validation - INFO -   Train: [100:400] = 300 samples
2025-12-21 10:34:18,679 - ml.src.pipelines.walk_forward_validation - INFO -          2025-12-02 21:50 to 2025-12-09 13:25
2025-12-21 10:34:18,679 - ml.src.pipelines.walk_forward_validation - INFO -   Test:  [400:450] = 50 samples
2025-12-21 10:34:18,681 - ml.src.pipelines.walk_forward_validation - INFO -          2025-12-09 13:35 to 2025-12-09 18:35
2025-12-21 10:34:18,881 - ml.src.training.sequence_xgb_trainer - INFO - Class balance (train): pos=43, neg=167, imbalance_ratio=3.88
2025-12-21 10:34:18,882 - ml.src.training.sequence_xgb_trainer - INFO - Applied scale_pos_weight=3.8837 to handle class imbalance
2025-12-21 10:34:18,882 - ml.src.training.sequence_xgb_trainer - INFO - [POINT 1] Cost-Sensitive Learning: using sample weights (mean=1.4095)
2025-12-21 10:34:18,883 - ml.src.training.sequence_xgb_trainer - INFO - Training XGBoost classifier...
2025-12-21 10:34:22,391 - ml.src.training.sequence_xgb_trainer - INFO - Training completed
2025-12-21 10:34:22,394 - ml.src.training.sequence_evaluation - INFO - Probability stats: min=0.0489, max=0.2912, mean=0.1423, std=0.0688
2025-12-21 10:34:22,399 - ml.src.training.sequence_evaluation - WARNING - [WARNING] Model has very low discriminative power (ROC-AUC=0.4634). Results may be random.
2025-12-21 10:34:22,403 - ml.src.training.sequence_evaluation - INFO - Using HYBRID optimization: EV with precision AND recall floors...
2025-12-21 10:34:22,569 - ml.src.training.sequence_evaluation - WARNING - No threshold met BOTH precision >= 0.55 AND recall >= 0.20 with >= 10 trades. Falling back to F1-optimized with precision floor.
2025-12-21 10:34:22,583 - ml.src.training.sequence_evaluation - WARNING - No threshold met precision >= 0.55 with >= 10 trades. Falling back to maximizing precision with stability constraint.
2025-12-21 10:34:22,607 - ml.src.training.sequence_evaluation - INFO - Confusion matrix@thr=0.20:
2025-12-21 10:34:22,608 - ml.src.training.sequence_evaluation - INFO -   [[TN=29, FP=12],
2025-12-21 10:34:22,608 - ml.src.training.sequence_evaluation - INFO -    [FN=9, TP=0]]
2025-12-21 10:34:22,616 - ml.src.pipelines.walk_forward_validation - INFO -   Results: WIN_RATE=0.00%, Precision=0.0000, Recall=0.0000, F1=0.0000
2025-12-21 10:34:22,617 - ml.src.pipelines.walk_forward_validation - INFO - Fold 4:
2025-12-21 10:34:22,617 - ml.src.pipelines.walk_forward_validation - INFO -   Train: [150:450] = 300 samples
2025-12-21 10:34:22,618 - ml.src.pipelines.walk_forward_validation - INFO -          2025-12-04 10:05 to 2025-12-09 18:35
2025-12-21 10:34:22,618 - ml.src.pipelines.walk_forward_validation - INFO -   Test:  [450:500] = 50 samples
2025-12-21 10:34:22,618 - ml.src.pipelines.walk_forward_validation - INFO -          2025-12-09 18:40 to 2025-12-10 19:30
2025-12-21 10:34:22,811 - ml.src.training.sequence_xgb_trainer - INFO - Class balance (train): pos=39, neg=171, imbalance_ratio=4.38
2025-12-21 10:34:22,812 - ml.src.training.sequence_xgb_trainer - INFO - Applied scale_pos_weight=4.3846 to handle class imbalance
2025-12-21 10:34:22,812 - ml.src.training.sequence_xgb_trainer - INFO - [POINT 1] Cost-Sensitive Learning: using sample weights (mean=1.3714)
2025-12-21 10:34:22,812 - ml.src.training.sequence_xgb_trainer - INFO - Training XGBoost classifier...
2025-12-21 10:34:42,869 - __main__ - INFO - 
================================================================================
2025-12-21 10:34:42,870 - __main__ - INFO - WALK-FORWARD VALIDATION ANALYSIS
2025-12-21 10:34:42,871 - __main__ - INFO - ================================================================================
2025-12-21 10:34:42,872 - __main__ - INFO - Years: 2025
2025-12-21 10:34:42,872 - __main__ - INFO - Train window: 200 samples (~1000 minutes)
2025-12-21 10:34:42,872 - __main__ - INFO - Test window: 30 samples (~150 minutes)
2025-12-21 10:34:42,873 - __main__ - INFO - Step size: 50 samples (~250 minutes)
2025-12-21 10:34:42,873 - __main__ - INFO - ================================================================================

2025-12-21 10:34:42,876 - __main__ - INFO - Loading data...
2025-12-21 10:34:42,879 - ml.src.data_loading.loaders - INFO - Year filter applied: loading only [2025]
2025-12-21 10:34:42,966 - __main__ - INFO - Loaded 18,875 M1 candles
2025-12-21 10:34:42,968 - __main__ - INFO - Aggregating to M5...
2025-12-21 10:34:42,970 - ml.src.features.engineer_m5 - INFO - Aggregating 18875 M1 candles to M5...
2025-12-21 10:34:42,988 - ml.src.features.engineer_m5 - INFO - Aggregated to 3776 M5 candles (5.0x compression)
2025-12-21 10:34:42,989 - __main__ - INFO - Aggregated to 3,776 M5 candles
2025-12-21 10:34:42,991 - __main__ - INFO - Engineering features...
2025-12-21 10:34:42,993 - ml.src.features.engineer_m5 - INFO - Engineering M5 features...
2025-12-21 10:34:42,993 - ml.src.features.engineer_m5 - INFO - Aggregating 3776 M1 candles to M5...
2025-12-21 10:34:43,005 - ml.src.features.engineer_m5 - INFO - Aggregated to 3776 M5 candles (1.0x compression)
2025-12-21 10:34:43,009 - ml.src.features.engineer_m5 - INFO - Computing M5 primary features...
2025-12-21 10:34:43,301 - ml.src.features.engineer_m5 - INFO - Computing M15 context from M5...
2025-12-21 10:34:43,427 - ml.src.features.engineer_m5 - INFO - Computing M60 context from M5...
2025-12-21 10:34:43,474 - ml.src.features.engineer_m5 - INFO - M5 feature engineering complete: 3776 rows × 24 features
2025-12-21 10:34:43,474 - ml.src.features.engineer_m5 - INFO - Timeframe: M5 (5-minute candles)
2025-12-21 10:34:43,475 - ml.src.features.engineer_m5 - INFO - Date range: 2025-12-01 00:00:00 to 2025-12-18 17:35:00
2025-12-21 10:34:43,475 - __main__ - INFO - Engineered 24 features
2025-12-21 10:34:43,475 - __main__ - INFO - Creating targets...
2025-12-21 10:34:43,476 - ml.src.targets.target_maker - INFO - Creating targets (SL/TP simulation) for 3,776 candles...
2025-12-21 10:34:43,476 - ml.src.targets.target_maker - INFO - Parameters: SL=1×ATR, TP=3.0×ATR, min_hold=2min, max_horizon=60min
2025-12-21 10:34:43,477 - ml.src.targets.target_maker - INFO - Calculating M1 ATR(14) for SL/TP targets (fallback)
2025-12-21 10:34:43,483 - ml.src.targets.target_maker - INFO - Target creation complete: 3,716 valid targets
2025-12-21 10:34:43,484 - __main__ - INFO - Created targets: 871 positive, 2,845 negative
2025-12-21 10:34:43,484 - __main__ - INFO - Building sequences...
2025-12-21 10:34:43,489 - ml.src.sequences.sequencer - INFO - M5 alignment filter disabled; keeping all timestamps irrespective of minute alignment
2025-12-21 10:34:43,490 - ml.src.sequences.sequencer - INFO - Applied Trend Filter (dist_sma_200 > 0.00, ADX > 15.00): kept 1711/3667 (46.7%)
2025-12-21 10:34:43,490 - ml.src.sequences.sequencer - INFO - Pullback filter disabled; not constraining RSI_M5
2025-12-21 10:34:43,491 - ml.src.sequences.sequencer - INFO - Session filter 'london_ny': keeping 1,039 / 3,667 windows (28.3%)
2025-12-21 10:34:43,492 - __main__ - INFO - Built 1,039 sequences
2025-12-21 10:34:43,493 - ml.src.pipelines.walk_forward_validation - INFO - 
================================================================================
2025-12-21 10:34:43,493 - ml.src.pipelines.walk_forward_validation - INFO - [POINT 6] WALK-FORWARD CROSS-VALIDATION - Time-Series Validation
2025-12-21 10:34:43,493 - ml.src.pipelines.walk_forward_validation - INFO - ================================================================================
2025-12-21 10:34:43,494 - ml.src.pipelines.walk_forward_validation - INFO - Data size: 1,039 samples (1039 timestamps)
2025-12-21 10:34:43,494 - ml.src.pipelines.walk_forward_validation - INFO - Train window: 200 samples (~1000 minutes)
2025-12-21 10:34:43,494 - ml.src.pipelines.walk_forward_validation - INFO - Test window: 30 samples (~150 minutes)
2025-12-21 10:34:43,495 - ml.src.pipelines.walk_forward_validation - INFO - Step size: 50 samples (~250 minutes)
2025-12-21 10:34:43,495 - ml.src.pipelines.walk_forward_validation - INFO - No lookahead bias: test set is ALWAYS future relative to training set
2025-12-21 10:34:43,495 - ml.src.pipelines.walk_forward_validation - INFO - ================================================================================

2025-12-21 10:34:43,495 - ml.src.pipelines.walk_forward_validation - INFO - Fold 1:
2025-12-21 10:34:43,496 - ml.src.pipelines.walk_forward_validation - INFO -   Train: [0:200] = 200 samples
2025-12-21 10:34:43,496 - ml.src.pipelines.walk_forward_validation - INFO -          2025-12-01 08:15 to 2025-12-04 18:05
2025-12-21 10:34:43,497 - ml.src.pipelines.walk_forward_validation - INFO -   Test:  [200:230] = 30 samples
2025-12-21 10:34:43,499 - ml.src.pipelines.walk_forward_validation - INFO -          2025-12-04 18:10 to 2025-12-04 20:35
2025-12-21 10:34:43,670 - ml.src.training.sequence_xgb_trainer - INFO - Class balance (train): pos=23, neg=117, imbalance_ratio=5.09
2025-12-21 10:34:43,670 - ml.src.training.sequence_xgb_trainer - INFO - Applied scale_pos_weight=5.0870 to handle class imbalance
2025-12-21 10:34:43,670 - ml.src.training.sequence_xgb_trainer - INFO - [POINT 1] Cost-Sensitive Learning: using sample weights (mean=1.3286)
2025-12-21 10:34:43,671 - ml.src.training.sequence_xgb_trainer - INFO - Training XGBoost classifier...
2025-12-21 10:34:44,608 - ml.src.training.sequence_xgb_trainer - INFO - Training completed
2025-12-21 10:34:44,612 - ml.src.training.sequence_evaluation - INFO - Probability stats: min=0.2226, max=0.4719, mean=0.2909, std=0.0644
2025-12-21 10:34:44,676 - ml.src.training.sequence_evaluation - INFO - Using HYBRID optimization: EV with precision AND recall floors...
2025-12-21 10:34:44,872 - ml.src.training.sequence_evaluation - WARNING - No threshold met BOTH precision >= 0.55 AND recall >= 0.20 with >= 10 trades. Falling back to F1-optimized with precision floor.
2025-12-21 10:34:44,922 - ml.src.training.sequence_evaluation - WARNING - No threshold met precision >= 0.55 with >= 10 trades. Falling back to maximizing precision with stability constraint.
2025-12-21 10:34:45,022 - ml.src.training.sequence_evaluation - INFO - Confusion matrix@thr=0.20:
2025-12-21 10:34:45,023 - ml.src.training.sequence_evaluation - INFO -   [[TN=0, FP=30],
2025-12-21 10:34:45,023 - ml.src.training.sequence_evaluation - INFO -    [FN=0, TP=0]]
2025-12-21 10:34:45,029 - ml.src.pipelines.walk_forward_validation - INFO -   Results: WIN_RATE=0.00%, Precision=0.0000, Recall=0.0000, F1=0.0000
2025-12-21 10:34:45,030 - ml.src.pipelines.walk_forward_validation - INFO - Fold 2:
2025-12-21 10:34:45,030 - ml.src.pipelines.walk_forward_validation - INFO -   Train: [50:250] = 200 samples
2025-12-21 10:34:45,032 - ml.src.pipelines.walk_forward_validation - INFO -          2025-12-01 13:00 to 2025-12-05 09:40
2025-12-21 10:34:45,033 - ml.src.pipelines.walk_forward_validation - INFO -   Test:  [250:280] = 30 samples
2025-12-21 10:34:45,034 - ml.src.pipelines.walk_forward_validation - INFO -          2025-12-05 09:45 to 2025-12-05 12:10
2025-12-21 10:34:45,188 - ml.src.training.sequence_xgb_trainer - INFO - Class balance (train): pos=17, neg=123, imbalance_ratio=7.24
2025-12-21 10:34:45,189 - ml.src.training.sequence_xgb_trainer - INFO - Applied scale_pos_weight=7.2353 to handle class imbalance
2025-12-21 10:34:45,189 - ml.src.training.sequence_xgb_trainer - INFO - [POINT 1] Cost-Sensitive Learning: using sample weights (mean=1.2429)
2025-12-21 10:34:45,190 - ml.src.training.sequence_xgb_trainer - INFO - Training XGBoost classifier...
2025-12-21 10:34:45,935 - ml.src.training.sequence_xgb_trainer - INFO - Training completed
2025-12-21 10:34:45,939 - ml.src.training.sequence_evaluation - INFO - Probability stats: min=0.1950, max=0.4878, mean=0.3188, std=0.1027
2025-12-21 10:34:45,943 - ml.src.training.sequence_evaluation - INFO - Using HYBRID optimization: EV with precision AND recall floors...
2025-12-21 10:34:46,269 - ml.src.training.sequence_evaluation - INFO - Hybrid-optimized threshold: 0.34 with EV=0.7778 (precision=0.5714, recall=0.8889, win_coeff=1.0, loss_coeff=-1.0)
2025-12-21 10:34:46,270 - ml.src.training.sequence_evaluation - INFO - Confusion matrix@thr=0.34:
2025-12-21 10:34:46,270 - ml.src.training.sequence_evaluation - INFO -   [[TN=15, FP=6],
2025-12-21 10:34:46,271 - ml.src.training.sequence_evaluation - INFO -    [FN=1, TP=8]]
2025-12-21 10:34:46,277 - ml.src.pipelines.walk_forward_validation - INFO -   Results: WIN_RATE=57.14%, Precision=0.5714, Recall=0.8889, F1=0.6957
2025-12-21 10:34:46,277 - ml.src.pipelines.walk_forward_validation - INFO - Fold 3:
2025-12-21 10:34:46,277 - ml.src.pipelines.walk_forward_validation - INFO -   Train: [100:300] = 200 samples
2025-12-21 10:34:46,278 - ml.src.pipelines.walk_forward_validation - INFO -          2025-12-02 21:50 to 2025-12-05 13:50
2025-12-21 10:34:46,278 - ml.src.pipelines.walk_forward_validation - INFO -   Test:  [300:330] = 30 samples
2025-12-21 10:34:46,279 - ml.src.pipelines.walk_forward_validation - INFO -          2025-12-05 13:55 to 2025-12-08 11:30
2025-12-21 10:34:46,432 - ml.src.training.sequence_xgb_trainer - INFO - Class balance (train): pos=15, neg=125, imbalance_ratio=8.33
2025-12-21 10:34:46,433 - ml.src.training.sequence_xgb_trainer - INFO - Applied scale_pos_weight=8.3333 to handle class imbalance
2025-12-21 10:34:46,433 - ml.src.training.sequence_xgb_trainer - INFO - [POINT 1] Cost-Sensitive Learning: using sample weights (mean=1.2143)
2025-12-21 10:34:46,434 - ml.src.training.sequence_xgb_trainer - INFO - Training XGBoost classifier...
2025-12-21 10:34:47,016 - ml.src.training.sequence_xgb_trainer - INFO - Training completed
2025-12-21 10:34:47,019 - ml.src.training.sequence_evaluation - INFO - Probability stats: min=0.3709, max=0.5248, mean=0.3996, std=0.0350
2025-12-21 10:34:47,024 - ml.src.training.sequence_evaluation - INFO - Using HYBRID optimization: EV with precision AND recall floors...
2025-12-21 10:34:47,344 - ml.src.training.sequence_evaluation - WARNING - No threshold met BOTH precision >= 0.55 AND recall >= 0.20 with >= 10 trades. Falling back to F1-optimized with precision floor.
2025-12-21 10:34:47,457 - ml.src.training.sequence_evaluation - WARNING - No threshold met precision >= 0.55 with >= 10 trades. Falling back to maximizing precision with stability constraint.
2025-12-21 10:34:47,905 - ml.src.training.sequence_evaluation - INFO - Confusion matrix@thr=0.38:
2025-12-21 10:34:47,905 - ml.src.training.sequence_evaluation - INFO -   [[TN=10, FP=12],
2025-12-21 10:34:47,906 - ml.src.training.sequence_evaluation - INFO -    [FN=1, TP=7]]
2025-12-21 10:34:47,917 - ml.src.pipelines.walk_forward_validation - INFO -   Results: WIN_RATE=36.84%, Precision=0.3684, Recall=0.8750, F1=0.5185
2025-12-21 10:34:47,917 - ml.src.pipelines.walk_forward_validation - INFO - Fold 4:
2025-12-21 10:34:47,918 - ml.src.pipelines.walk_forward_validation - INFO -   Train: [150:350] = 200 samples
2025-12-21 10:34:47,918 - ml.src.pipelines.walk_forward_validation - INFO -          2025-12-04 10:05 to 2025-12-08 14:10
2025-12-21 10:34:47,919 - ml.src.pipelines.walk_forward_validation - INFO -   Test:  [350:380] = 30 samples
2025-12-21 10:34:47,920 - ml.src.pipelines.walk_forward_validation - INFO -          2025-12-08 14:15 to 2025-12-09 10:50
2025-12-21 10:34:48,119 - ml.src.training.sequence_xgb_trainer - INFO - Class balance (train): pos=20, neg=120, imbalance_ratio=6.00
2025-12-21 10:34:48,119 - ml.src.training.sequence_xgb_trainer - INFO - Applied scale_pos_weight=6.0000 to handle class imbalance
2025-12-21 10:34:48,120 - ml.src.training.sequence_xgb_trainer - INFO - [POINT 1] Cost-Sensitive Learning: using sample weights (mean=1.2857)
2025-12-21 10:34:48,120 - ml.src.training.sequence_xgb_trainer - INFO - Training XGBoost classifier...
2025-12-21 10:34:48,893 - ml.src.training.sequence_xgb_trainer - INFO - Training completed
2025-12-21 10:34:48,897 - ml.src.training.sequence_evaluation - INFO - Probability stats: min=0.1751, max=0.5620, mean=0.2378, std=0.0840
2025-12-21 10:34:48,905 - ml.src.training.sequence_evaluation - INFO - Using HYBRID optimization: EV with precision AND recall floors...
2025-12-21 10:34:49,091 - ml.src.training.sequence_evaluation - WARNING - No threshold met BOTH precision >= 0.55 AND recall >= 0.20 with >= 10 trades. Falling back to F1-optimized with precision floor.
2025-12-21 10:34:49,114 - ml.src.training.sequence_evaluation - WARNING - No threshold met precision >= 0.55 with >= 10 trades. Falling back to maximizing precision with stability constraint.
2025-12-21 10:34:49,162 - ml.src.training.sequence_evaluation - INFO - Confusion matrix@thr=0.24:
2025-12-21 10:34:49,163 - ml.src.training.sequence_evaluation - INFO -   [[TN=18, FP=6],
2025-12-21 10:34:49,163 - ml.src.training.sequence_evaluation - INFO -    [FN=0, TP=6]]
2025-12-21 10:34:49,172 - ml.src.pipelines.walk_forward_validation - INFO -   Results: WIN_RATE=50.00%, Precision=0.5000, Recall=1.0000, F1=0.6667
2025-12-21 10:34:49,173 - ml.src.pipelines.walk_forward_validation - INFO - Fold 5:
2025-12-21 10:34:49,173 - ml.src.pipelines.walk_forward_validation - INFO -   Train: [200:400] = 200 samples
2025-12-21 10:34:49,173 - ml.src.pipelines.walk_forward_validation - INFO -          2025-12-04 18:10 to 2025-12-09 13:25
2025-12-21 10:34:49,174 - ml.src.pipelines.walk_forward_validation - INFO -   Test:  [400:430] = 30 samples
2025-12-21 10:34:49,174 - ml.src.pipelines.walk_forward_validation - INFO -          2025-12-09 13:35 to 2025-12-09 16:55
2025-12-21 10:34:49,335 - ml.src.training.sequence_xgb_trainer - INFO - Class balance (train): pos=32, neg=108, imbalance_ratio=3.38
2025-12-21 10:34:49,336 - ml.src.training.sequence_xgb_trainer - INFO - Applied scale_pos_weight=3.3750 to handle class imbalance
2025-12-21 10:34:49,336 - ml.src.training.sequence_xgb_trainer - INFO - [POINT 1] Cost-Sensitive Learning: using sample weights (mean=1.4571)
2025-12-21 10:34:49,337 - ml.src.training.sequence_xgb_trainer - INFO - Training XGBoost classifier...
2025-12-21 10:34:50,442 - ml.src.training.sequence_xgb_trainer - INFO - Training completed
2025-12-21 10:34:50,445 - ml.src.training.sequence_evaluation - INFO - Probability stats: min=0.1905, max=0.3547, mean=0.2380, std=0.0403
2025-12-21 10:34:50,451 - ml.src.training.sequence_evaluation - INFO - Using HYBRID optimization: EV with precision AND recall floors...
2025-12-21 10:34:50,642 - ml.src.training.sequence_evaluation - WARNING - No threshold met BOTH precision >= 0.55 AND recall >= 0.20 with >= 10 trades. Falling back to F1-optimized with precision floor.
2025-12-21 10:34:50,672 - ml.src.training.sequence_evaluation - WARNING - No threshold met precision >= 0.55 with >= 10 trades. Falling back to maximizing precision with stability constraint.
2025-12-21 10:34:50,730 - ml.src.training.sequence_evaluation - INFO - Confusion matrix@thr=0.24:
2025-12-21 10:34:50,730 - ml.src.training.sequence_evaluation - INFO -   [[TN=16, FP=10],
2025-12-21 10:34:50,732 - ml.src.training.sequence_evaluation - INFO -    [FN=1, TP=3]]
2025-12-21 10:34:50,740 - ml.src.pipelines.walk_forward_validation - INFO -   Results: WIN_RATE=23.08%, Precision=0.2308, Recall=0.7500, F1=0.3529
2025-12-21 10:34:50,741 - ml.src.pipelines.walk_forward_validation - INFO - Fold 6:
2025-12-21 10:34:50,741 - ml.src.pipelines.walk_forward_validation - INFO -   Train: [250:450] = 200 samples
2025-12-21 10:34:50,742 - ml.src.pipelines.walk_forward_validation - INFO -          2025-12-05 09:45 to 2025-12-09 18:35
2025-12-21 10:34:50,742 - ml.src.pipelines.walk_forward_validation - INFO -   Test:  [450:480] = 30 samples
2025-12-21 10:34:50,743 - ml.src.pipelines.walk_forward_validation - INFO -          2025-12-09 18:40 to 2025-12-09 21:05
2025-12-21 10:34:50,914 - ml.src.training.sequence_xgb_trainer - INFO - Class balance (train): pos=34, neg=106, imbalance_ratio=3.12
2025-12-21 10:34:50,916 - ml.src.training.sequence_xgb_trainer - INFO - Applied scale_pos_weight=3.1176 to handle class imbalance
2025-12-21 10:34:50,917 - ml.src.training.sequence_xgb_trainer - INFO - [POINT 1] Cost-Sensitive Learning: using sample weights (mean=1.4857)
2025-12-21 10:34:50,917 - ml.src.training.sequence_xgb_trainer - INFO - Training XGBoost classifier...
2025-12-21 10:34:52,059 - ml.src.training.sequence_xgb_trainer - INFO - Training completed
2025-12-21 10:34:52,064 - ml.src.training.sequence_evaluation - INFO - Probability stats: min=0.2842, max=0.7259, mean=0.5177, std=0.1299
2025-12-21 10:34:52,071 - ml.src.training.sequence_evaluation - WARNING - [WARNING] Model has very low discriminative power (ROC-AUC=0.1358). Results may be random.
2025-12-21 10:34:52,073 - ml.src.training.sequence_evaluation - INFO - Using HYBRID optimization: EV with precision AND recall floors...
2025-12-21 10:34:52,608 - ml.src.training.sequence_evaluation - WARNING - No threshold met BOTH precision >= 0.55 AND recall >= 0.20 with >= 10 trades. Falling back to F1-optimized with precision floor.
2025-12-21 10:34:52,815 - ml.src.training.sequence_evaluation - WARNING - No threshold met precision >= 0.55 with >= 10 trades. Falling back to maximizing precision with stability constraint.
2025-12-21 10:34:53,148 - ml.src.training.sequence_evaluation - INFO - Confusion matrix@thr=0.30:
2025-12-21 10:34:53,149 - ml.src.training.sequence_evaluation - INFO -   [[TN=2, FP=25],
2025-12-21 10:34:53,150 - ml.src.training.sequence_evaluation - INFO -    [FN=0, TP=3]]
2025-12-21 10:34:53,156 - ml.src.pipelines.walk_forward_validation - INFO -   Results: WIN_RATE=10.71%, Precision=0.1071, Recall=1.0000, F1=0.1935
2025-12-21 10:34:53,156 - ml.src.pipelines.walk_forward_validation - INFO - Fold 7:
2025-12-21 10:34:53,157 - ml.src.pipelines.walk_forward_validation - INFO -   Train: [300:500] = 200 samples
2025-12-21 10:34:53,157 - ml.src.pipelines.walk_forward_validation - INFO -          2025-12-05 13:55 to 2025-12-10 19:30
2025-12-21 10:34:53,158 - ml.src.pipelines.walk_forward_validation - INFO -   Test:  [500:530] = 30 samples
2025-12-21 10:34:53,158 - ml.src.pipelines.walk_forward_validation - INFO -          2025-12-10 19:35 to 2025-12-11 08:50
2025-12-21 10:34:53,307 - ml.src.training.sequence_xgb_trainer - INFO - Class balance (train): pos=20, neg=120, imbalance_ratio=6.00
2025-12-21 10:34:53,307 - ml.src.training.sequence_xgb_trainer - INFO - Applied scale_pos_weight=6.0000 to handle class imbalance
2025-12-21 10:34:53,307 - ml.src.training.sequence_xgb_trainer - INFO - [POINT 1] Cost-Sensitive Learning: using sample weights (mean=1.2857)
2025-12-21 10:34:53,308 - ml.src.training.sequence_xgb_trainer - INFO - Training XGBoost classifier...
2025-12-21 10:34:54,557 - ml.src.training.sequence_xgb_trainer - INFO - Training completed
2025-12-21 10:34:54,560 - ml.src.training.sequence_evaluation - INFO - Probability stats: min=0.2507, max=0.8126, mean=0.4360, std=0.1866
2025-12-21 10:34:54,566 - ml.src.training.sequence_evaluation - INFO - Using HYBRID optimization: EV with precision AND recall floors...
2025-12-21 10:34:55,075 - ml.src.training.sequence_evaluation - WARNING - No threshold met BOTH precision >= 0.55 AND recall >= 0.20 with >= 10 trades. Falling back to F1-optimized with precision floor.
2025-12-21 10:34:55,243 - ml.src.training.sequence_evaluation - WARNING - No threshold met precision >= 0.55 with >= 10 trades. Falling back to maximizing precision with stability constraint.
2025-12-21 10:34:55,549 - ml.src.training.sequence_evaluation - INFO - Confusion matrix@thr=0.53:
2025-12-21 10:34:55,549 - ml.src.training.sequence_evaluation - INFO -   [[TN=18, FP=5],
2025-12-21 10:34:55,549 - ml.src.training.sequence_evaluation - INFO -    [FN=1, TP=6]]
2025-12-21 10:34:55,559 - ml.src.pipelines.walk_forward_validation - INFO -   Results: WIN_RATE=54.55%, Precision=0.5455, Recall=0.8571, F1=0.6667
2025-12-21 10:34:55,559 - ml.src.pipelines.walk_forward_validation - INFO - Fold 8:
2025-12-21 10:34:55,559 - ml.src.pipelines.walk_forward_validation - INFO -   Train: [350:550] = 200 samples
2025-12-21 10:34:55,560 - ml.src.pipelines.walk_forward_validation - INFO -          2025-12-08 14:15 to 2025-12-11 14:40
2025-12-21 10:34:55,560 - ml.src.pipelines.walk_forward_validation - INFO -   Test:  [550:580] = 30 samples
2025-12-21 10:34:55,561 - ml.src.pipelines.walk_forward_validation - INFO -          2025-12-11 14:45 to 2025-12-11 17:10
2025-12-21 10:34:55,707 - ml.src.training.sequence_xgb_trainer - INFO - Class balance (train): pos=21, neg=119, imbalance_ratio=5.67
2025-12-21 10:34:55,708 - ml.src.training.sequence_xgb_trainer - INFO - Applied scale_pos_weight=5.6667 to handle class imbalance
2025-12-21 10:34:55,708 - ml.src.training.sequence_xgb_trainer - INFO - [POINT 1] Cost-Sensitive Learning: using sample weights (mean=1.3000)
2025-12-21 10:34:55,708 - ml.src.training.sequence_xgb_trainer - INFO - Training XGBoost classifier...
2025-12-21 10:34:56,543 - ml.src.training.sequence_xgb_trainer - INFO - Training completed
2025-12-21 10:34:56,546 - ml.src.training.sequence_evaluation - INFO - Probability stats: min=0.1699, max=0.2276, mean=0.1886, std=0.0169
2025-12-21 10:34:56,555 - ml.src.training.sequence_evaluation - INFO - Using HYBRID optimization: EV with precision AND recall floors...
2025-12-21 10:34:56,661 - ml.src.training.sequence_evaluation - INFO - Hybrid-optimized threshold: 0.10 with EV=1.0000 (precision=0.7333, recall=1.0000, win_coeff=1.0, loss_coeff=-1.0)
2025-12-21 10:34:56,663 - ml.src.training.sequence_evaluation - INFO - Confusion matrix@thr=0.10:
2025-12-21 10:34:56,663 - ml.src.training.sequence_evaluation - INFO -   [[TN=0, FP=8],
2025-12-21 10:34:56,664 - ml.src.training.sequence_evaluation - INFO -    [FN=0, TP=22]]
2025-12-21 10:34:56,671 - ml.src.pipelines.walk_forward_validation - INFO -   Results: WIN_RATE=73.33%, Precision=0.7333, Recall=1.0000, F1=0.8462
2025-12-21 10:34:56,671 - ml.src.pipelines.walk_forward_validation - INFO - Fold 9:
2025-12-21 10:34:56,672 - ml.src.pipelines.walk_forward_validation - INFO -   Train: [400:600] = 200 samples
2025-12-21 10:34:56,672 - ml.src.pipelines.walk_forward_validation - INFO -          2025-12-09 13:35 to 2025-12-11 18:50
2025-12-21 10:34:56,672 - ml.src.pipelines.walk_forward_validation - INFO -   Test:  [600:630] = 30 samples
2025-12-21 10:34:56,673 - ml.src.pipelines.walk_forward_validation - INFO -          2025-12-11 18:55 to 2025-12-11 21:20
2025-12-21 10:34:56,877 - ml.src.training.sequence_xgb_trainer - INFO - Class balance (train): pos=22, neg=118, imbalance_ratio=5.36
2025-12-21 10:34:56,878 - ml.src.training.sequence_xgb_trainer - INFO - Applied scale_pos_weight=5.3636 to handle class imbalance
2025-12-21 10:34:56,878 - ml.src.training.sequence_xgb_trainer - INFO - [POINT 1] Cost-Sensitive Learning: using sample weights (mean=1.3143)
2025-12-21 10:34:56,879 - ml.src.training.sequence_xgb_trainer - INFO - Training XGBoost classifier...
2025-12-21 10:34:57,900 - ml.src.training.sequence_xgb_trainer - INFO - Training completed
2025-12-21 10:34:57,904 - ml.src.training.sequence_evaluation - INFO - Probability stats: min=0.4973, max=0.5854, mean=0.5378, std=0.0263
2025-12-21 10:34:57,908 - ml.src.training.sequence_evaluation - INFO - Using HYBRID optimization: EV with precision AND recall floors...
2025-12-21 10:34:58,374 - ml.src.training.sequence_evaluation - WARNING - No threshold met BOTH precision >= 0.55 AND recall >= 0.20 with >= 10 trades. Falling back to F1-optimized with precision floor.
2025-12-21 10:34:58,527 - ml.src.training.sequence_evaluation - WARNING - No threshold met precision >= 0.55 with >= 10 trades. Falling back to maximizing precision with stability constraint.
2025-12-21 10:34:58,816 - ml.src.training.sequence_evaluation - INFO - Confusion matrix@thr=0.55:
2025-12-21 10:34:58,816 - ml.src.training.sequence_evaluation - INFO -   [[TN=15, FP=7],
2025-12-21 10:34:58,816 - ml.src.training.sequence_evaluation - INFO -    [FN=2, TP=6]]
2025-12-21 10:34:58,822 - ml.src.pipelines.walk_forward_validation - INFO -   Results: WIN_RATE=46.15%, Precision=0.4615, Recall=0.7500, F1=0.5714
2025-12-21 10:34:58,823 - ml.src.pipelines.walk_forward_validation - INFO - Fold 10:
2025-12-21 10:34:58,823 - ml.src.pipelines.walk_forward_validation - INFO -   Train: [450:650] = 200 samples
2025-12-21 10:34:58,824 - ml.src.pipelines.walk_forward_validation - INFO -          2025-12-09 18:40 to 2025-12-12 09:00
2025-12-21 10:34:58,824 - ml.src.pipelines.walk_forward_validation - INFO -   Test:  [650:680] = 30 samples
2025-12-21 10:34:58,824 - ml.src.pipelines.walk_forward_validation - INFO -          2025-12-12 09:05 to 2025-12-12 11:30
2025-12-21 10:34:58,973 - ml.src.training.sequence_xgb_trainer - INFO - Class balance (train): pos=42, neg=98, imbalance_ratio=2.33
2025-12-21 10:34:58,974 - ml.src.training.sequence_xgb_trainer - INFO - Applied scale_pos_weight=2.3333 to handle class imbalance
2025-12-21 10:34:58,974 - ml.src.training.sequence_xgb_trainer - INFO - [POINT 1] Cost-Sensitive Learning: using sample weights (mean=1.6000)
2025-12-21 10:34:58,974 - ml.src.training.sequence_xgb_trainer - INFO - Training XGBoost classifier...
2025-12-21 10:35:28,288 - __main__ - INFO - 
================================================================================
2025-12-21 10:35:28,289 - __main__ - INFO - WALK-FORWARD VALIDATION ANALYSIS
2025-12-21 10:35:28,289 - __main__ - INFO - ================================================================================
2025-12-21 10:35:28,289 - __main__ - INFO - Years: 2025
2025-12-21 10:35:28,289 - __main__ - INFO - Train window: 150 samples (~750 minutes)
2025-12-21 10:35:28,290 - __main__ - INFO - Test window: 25 samples (~125 minutes)
2025-12-21 10:35:28,290 - __main__ - INFO - Step size: 50 samples (~250 minutes)
2025-12-21 10:35:28,290 - __main__ - INFO - ================================================================================

2025-12-21 10:35:28,291 - __main__ - INFO - Loading data...
2025-12-21 10:35:28,292 - ml.src.data_loading.loaders - INFO - Year filter applied: loading only [2025]
2025-12-21 10:35:28,338 - __main__ - INFO - Loaded 18,875 M1 candles
2025-12-21 10:35:28,339 - __main__ - INFO - Aggregating to M5...
2025-12-21 10:35:28,339 - ml.src.features.engineer_m5 - INFO - Aggregating 18875 M1 candles to M5...
2025-12-21 10:35:28,346 - ml.src.features.engineer_m5 - INFO - Aggregated to 3776 M5 candles (5.0x compression)
2025-12-21 10:35:28,346 - __main__ - INFO - Aggregated to 3,776 M5 candles
2025-12-21 10:35:28,346 - __main__ - INFO - Engineering features...
2025-12-21 10:35:28,347 - ml.src.features.engineer_m5 - INFO - Engineering M5 features...
2025-12-21 10:35:28,347 - ml.src.features.engineer_m5 - INFO - Aggregating 3776 M1 candles to M5...
2025-12-21 10:35:28,354 - ml.src.features.engineer_m5 - INFO - Aggregated to 3776 M5 candles (1.0x compression)
2025-12-21 10:35:28,357 - ml.src.features.engineer_m5 - INFO - Computing M5 primary features...
2025-12-21 10:35:28,599 - ml.src.features.engineer_m5 - INFO - Computing M15 context from M5...
2025-12-21 10:35:28,689 - ml.src.features.engineer_m5 - INFO - Computing M60 context from M5...
2025-12-21 10:35:28,724 - ml.src.features.engineer_m5 - INFO - M5 feature engineering complete: 3776 rows × 24 features
2025-12-21 10:35:28,725 - ml.src.features.engineer_m5 - INFO - Timeframe: M5 (5-minute candles)
2025-12-21 10:35:28,725 - ml.src.features.engineer_m5 - INFO - Date range: 2025-12-01 00:00:00 to 2025-12-18 17:35:00
2025-12-21 10:35:28,725 - __main__ - INFO - Engineered 24 features
2025-12-21 10:35:28,726 - __main__ - INFO - Creating targets...
2025-12-21 10:35:28,726 - ml.src.targets.target_maker - INFO - Creating targets (SL/TP simulation) for 3,776 candles...
2025-12-21 10:35:28,726 - ml.src.targets.target_maker - INFO - Parameters: SL=1×ATR, TP=3.0×ATR, min_hold=2min, max_horizon=60min
2025-12-21 10:35:28,727 - ml.src.targets.target_maker - INFO - Calculating M1 ATR(14) for SL/TP targets (fallback)
2025-12-21 10:35:28,730 - ml.src.targets.target_maker - INFO - Target creation complete: 3,716 valid targets
2025-12-21 10:35:28,730 - __main__ - INFO - Created targets: 871 positive, 2,845 negative
2025-12-21 10:35:28,731 - __main__ - INFO - Building sequences...
2025-12-21 10:35:28,736 - ml.src.sequences.sequencer - INFO - M5 alignment filter disabled; keeping all timestamps irrespective of minute alignment
2025-12-21 10:35:28,737 - ml.src.sequences.sequencer - INFO - Applied Trend Filter (dist_sma_200 > 0.00, ADX > 15.00): kept 1711/3667 (46.7%)
2025-12-21 10:35:28,738 - ml.src.sequences.sequencer - INFO - Pullback filter disabled; not constraining RSI_M5
2025-12-21 10:35:28,739 - ml.src.sequences.sequencer - INFO - Session filter 'london_ny': keeping 1,039 / 3,667 windows (28.3%)
2025-12-21 10:35:28,740 - __main__ - INFO - Built 1,039 sequences
2025-12-21 10:35:28,741 - ml.src.pipelines.walk_forward_validation - INFO - 
================================================================================
2025-12-21 10:35:28,741 - ml.src.pipelines.walk_forward_validation - INFO - [POINT 6] WALK-FORWARD CROSS-VALIDATION - Time-Series Validation
2025-12-21 10:35:28,741 - ml.src.pipelines.walk_forward_validation - INFO - ================================================================================
2025-12-21 10:35:28,742 - ml.src.pipelines.walk_forward_validation - INFO - Data size: 1,039 samples (1039 timestamps)
2025-12-21 10:35:28,742 - ml.src.pipelines.walk_forward_validation - INFO - Train window: 150 samples (~750 minutes)
2025-12-21 10:35:28,742 - ml.src.pipelines.walk_forward_validation - INFO - Test window: 25 samples (~125 minutes)
2025-12-21 10:35:28,742 - ml.src.pipelines.walk_forward_validation - INFO - Step size: 50 samples (~250 minutes)
2025-12-21 10:35:28,743 - ml.src.pipelines.walk_forward_validation - INFO - No lookahead bias: test set is ALWAYS future relative to training set
2025-12-21 10:35:28,743 - ml.src.pipelines.walk_forward_validation - INFO - ================================================================================

2025-12-21 10:35:28,743 - ml.src.pipelines.walk_forward_validation - INFO - Fold 1:
2025-12-21 10:35:28,743 - ml.src.pipelines.walk_forward_validation - INFO -   Train: [0:150] = 150 samples
2025-12-21 10:35:28,744 - ml.src.pipelines.walk_forward_validation - INFO -          2025-12-01 08:15 to 2025-12-03 20:05
2025-12-21 10:35:28,744 - ml.src.pipelines.walk_forward_validation - INFO -   Test:  [150:175] = 25 samples
2025-12-21 10:35:28,744 - ml.src.pipelines.walk_forward_validation - INFO -          2025-12-04 10:05 to 2025-12-04 15:15
2025-12-21 10:35:28,876 - ml.src.training.sequence_xgb_trainer - INFO - Class balance (train): pos=9, neg=96, imbalance_ratio=10.67
2025-12-21 10:35:28,876 - ml.src.training.sequence_xgb_trainer - INFO - Applied scale_pos_weight=10.6667 to handle class imbalance
2025-12-21 10:35:28,877 - ml.src.training.sequence_xgb_trainer - INFO - [POINT 1] Cost-Sensitive Learning: using sample weights (mean=1.1714)
2025-12-21 10:35:28,877 - ml.src.training.sequence_xgb_trainer - INFO - Training XGBoost classifier...
2025-12-21 10:35:28,929 - __main__ - ERROR - ERROR: Must have at least 1 validation dataset for early stopping.
Traceback (most recent call last):
  File "C:\Users\Arek\Documents\Repos\Traiding\Trading-ML\ml\scripts\walk_forward_analysis.py", line 150, in main
    results = walk_forward_validate(
        X=X,
    ...<9 lines>...
        sample_weight_negative=SAMPLE_WEIGHT_NEGATIVE,
    )
  File "C:\Users\Arek\Documents\Repos\Traiding\Trading-ML\ml\src\pipelines\walk_forward_validation.py", line 153, in walk_forward_validate
    model = train_xgb(
        X_train_fold, y_train_fold,
    ...<3 lines>...
        n_estimators=20  # Minimal for quick CV testing
    )
  File "C:\Users\Arek\Documents\Repos\Traiding\Trading-ML\ml\src\training\sequence_xgb_trainer.py", line 80, in train_xgb
    base.fit(
    ~~~~~~~~^
        X_train,
        ^^^^^^^^
    ...<2 lines>...
        verbose=False,
        ^^^^^^^^^^^^^^
    )
    ^
  File "C:\Users\Arek\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\LocalCache\local-packages\Python313\site-packages\xgboost\core.py", line 774, in inner_f
    return func(**kwargs)
  File "C:\Users\Arek\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\LocalCache\local-packages\Python313\site-packages\xgboost\sklearn.py", line 1806, in fit
    self._Booster = train(
                    ~~~~~^
        params,
        ^^^^^^^
    ...<9 lines>...
        callbacks=self.callbacks,
        ^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "C:\Users\Arek\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\LocalCache\local-packages\Python313\site-packages\xgboost\core.py", line 774, in inner_f
    return func(**kwargs)
  File "C:\Users\Arek\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\LocalCache\local-packages\Python313\site-packages\xgboost\training.py", line 200, in train
    if cb_container.after_iteration(bst, i, dtrain, evals):
       ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Arek\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\LocalCache\local-packages\Python313\site-packages\xgboost\callback.py", line 269, in after_iteration
    ret = any(c.after_iteration(model, epoch, self.history) for c in self.callbacks)
  File "C:\Users\Arek\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\LocalCache\local-packages\Python313\site-packages\xgboost\callback.py", line 269, in <genexpr>
    ret = any(c.after_iteration(model, epoch, self.history) for c in self.callbacks)
              ~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Arek\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\LocalCache\local-packages\Python313\site-packages\xgboost\callback.py", line 461, in after_iteration
    raise ValueError(msg)
ValueError: Must have at least 1 validation dataset for early stopping.
2025-12-21 10:35:43,807 - __main__ - INFO - 
================================================================================
2025-12-21 10:35:43,807 - __main__ - INFO - WALK-FORWARD VALIDATION ANALYSIS
2025-12-21 10:35:43,807 - __main__ - INFO - ================================================================================
2025-12-21 10:35:43,807 - __main__ - INFO - Years: 2025
2025-12-21 10:35:43,807 - __main__ - INFO - Train window: 150 samples (~750 minutes)
2025-12-21 10:35:43,807 - __main__ - INFO - Test window: 25 samples (~125 minutes)
2025-12-21 10:35:43,807 - __main__ - INFO - Step size: 50 samples (~250 minutes)
2025-12-21 10:35:43,808 - __main__ - INFO - ================================================================================

2025-12-21 10:35:43,808 - __main__ - INFO - Loading data...
2025-12-21 10:35:43,809 - ml.src.data_loading.loaders - INFO - Year filter applied: loading only [2025]
2025-12-21 10:35:43,855 - __main__ - INFO - Loaded 18,875 M1 candles
2025-12-21 10:35:43,856 - __main__ - INFO - Aggregating to M5...
2025-12-21 10:35:43,856 - ml.src.features.engineer_m5 - INFO - Aggregating 18875 M1 candles to M5...
2025-12-21 10:35:43,864 - ml.src.features.engineer_m5 - INFO - Aggregated to 3776 M5 candles (5.0x compression)
2025-12-21 10:35:43,865 - __main__ - INFO - Aggregated to 3,776 M5 candles
2025-12-21 10:35:43,865 - __main__ - INFO - Engineering features...
2025-12-21 10:35:43,865 - ml.src.features.engineer_m5 - INFO - Engineering M5 features...
2025-12-21 10:35:43,865 - ml.src.features.engineer_m5 - INFO - Aggregating 3776 M1 candles to M5...
2025-12-21 10:35:43,872 - ml.src.features.engineer_m5 - INFO - Aggregated to 3776 M5 candles (1.0x compression)
2025-12-21 10:35:43,874 - ml.src.features.engineer_m5 - INFO - Computing M5 primary features...
2025-12-21 10:35:44,152 - ml.src.features.engineer_m5 - INFO - Computing M15 context from M5...
2025-12-21 10:35:44,261 - ml.src.features.engineer_m5 - INFO - Computing M60 context from M5...
2025-12-21 10:35:44,302 - ml.src.features.engineer_m5 - INFO - M5 feature engineering complete: 3776 rows × 24 features
2025-12-21 10:35:44,302 - ml.src.features.engineer_m5 - INFO - Timeframe: M5 (5-minute candles)
2025-12-21 10:35:44,303 - ml.src.features.engineer_m5 - INFO - Date range: 2025-12-01 00:00:00 to 2025-12-18 17:35:00
2025-12-21 10:35:44,303 - __main__ - INFO - Engineered 24 features
2025-12-21 10:35:44,303 - __main__ - INFO - Creating targets...
2025-12-21 10:35:44,303 - ml.src.targets.target_maker - INFO - Creating targets (SL/TP simulation) for 3,776 candles...
2025-12-21 10:35:44,303 - ml.src.targets.target_maker - INFO - Parameters: SL=1×ATR, TP=3.0×ATR, min_hold=2min, max_horizon=60min
2025-12-21 10:35:44,304 - ml.src.targets.target_maker - INFO - Calculating M1 ATR(14) for SL/TP targets (fallback)
2025-12-21 10:35:44,307 - ml.src.targets.target_maker - INFO - Target creation complete: 3,716 valid targets
2025-12-21 10:35:44,308 - __main__ - INFO - Created targets: 871 positive, 2,845 negative
2025-12-21 10:35:44,308 - __main__ - INFO - Building sequences...
2025-12-21 10:35:44,312 - ml.src.sequences.sequencer - INFO - M5 alignment filter disabled; keeping all timestamps irrespective of minute alignment
2025-12-21 10:35:44,313 - ml.src.sequences.sequencer - INFO - Applied Trend Filter (dist_sma_200 > 0.00, ADX > 15.00): kept 1711/3667 (46.7%)
2025-12-21 10:35:44,314 - ml.src.sequences.sequencer - INFO - Pullback filter disabled; not constraining RSI_M5
2025-12-21 10:35:44,314 - ml.src.sequences.sequencer - INFO - Session filter 'london_ny': keeping 1,039 / 3,667 windows (28.3%)
2025-12-21 10:35:44,317 - __main__ - INFO - Built 1,039 sequences
2025-12-21 10:35:44,318 - ml.src.pipelines.walk_forward_validation - INFO - 
================================================================================
2025-12-21 10:35:44,318 - ml.src.pipelines.walk_forward_validation - INFO - [POINT 6] WALK-FORWARD CROSS-VALIDATION - Time-Series Validation
2025-12-21 10:35:44,318 - ml.src.pipelines.walk_forward_validation - INFO - ================================================================================
2025-12-21 10:35:44,318 - ml.src.pipelines.walk_forward_validation - INFO - Data size: 1,039 samples (1039 timestamps)
2025-12-21 10:35:44,318 - ml.src.pipelines.walk_forward_validation - INFO - Train window: 150 samples (~750 minutes)
2025-12-21 10:35:44,318 - ml.src.pipelines.walk_forward_validation - INFO - Test window: 25 samples (~125 minutes)
2025-12-21 10:35:44,318 - ml.src.pipelines.walk_forward_validation - INFO - Step size: 50 samples (~250 minutes)
2025-12-21 10:35:44,318 - ml.src.pipelines.walk_forward_validation - INFO - No lookahead bias: test set is ALWAYS future relative to training set
2025-12-21 10:35:44,319 - ml.src.pipelines.walk_forward_validation - INFO - ================================================================================

2025-12-21 10:35:44,319 - ml.src.pipelines.walk_forward_validation - INFO - Fold 1:
2025-12-21 10:35:44,319 - ml.src.pipelines.walk_forward_validation - INFO -   Train: [0:150] = 150 samples
2025-12-21 10:35:44,319 - ml.src.pipelines.walk_forward_validation - INFO -          2025-12-01 08:15 to 2025-12-03 20:05
2025-12-21 10:35:44,319 - ml.src.pipelines.walk_forward_validation - INFO -   Test:  [150:175] = 25 samples
2025-12-21 10:35:44,320 - ml.src.pipelines.walk_forward_validation - INFO -          2025-12-04 10:05 to 2025-12-04 15:15
2025-12-21 10:35:44,616 - ml.src.training.sequence_xgb_trainer - INFO - Class balance (train): pos=9, neg=96, imbalance_ratio=10.67
2025-12-21 10:35:44,616 - ml.src.training.sequence_xgb_trainer - INFO - Applied scale_pos_weight=10.6667 to handle class imbalance
2025-12-21 10:35:44,617 - ml.src.training.sequence_xgb_trainer - INFO - [POINT 1] Cost-Sensitive Learning: using sample weights (mean=1.1714)
2025-12-21 10:35:44,617 - ml.src.training.sequence_xgb_trainer - INFO - Training XGBoost classifier...
2025-12-21 10:35:44,883 - ml.src.training.sequence_xgb_trainer - INFO - Training completed
2025-12-21 10:35:44,888 - ml.src.training.sequence_evaluation - INFO - Probability stats: min=0.4195, max=0.6094, mean=0.5302, std=0.0575
2025-12-21 10:35:44,897 - ml.src.training.sequence_evaluation - INFO - Using HYBRID optimization: EV with precision AND recall floors...
2025-12-21 10:35:45,368 - ml.src.training.sequence_evaluation - WARNING - No threshold met BOTH precision >= 0.55 AND recall >= 0.20 with >= 10 trades. Falling back to F1-optimized with precision floor.
2025-12-21 10:35:45,531 - ml.src.training.sequence_evaluation - WARNING - No threshold met precision >= 0.55 with >= 10 trades. Falling back to maximizing precision with stability constraint.
2025-12-21 10:35:45,855 - ml.src.training.sequence_evaluation - INFO - Confusion matrix@thr=0.55:
2025-12-21 10:35:45,855 - ml.src.training.sequence_evaluation - INFO -   [[TN=14, FP=10],
2025-12-21 10:35:45,855 - ml.src.training.sequence_evaluation - INFO -    [FN=0, TP=1]]
2025-12-21 10:35:45,861 - ml.src.pipelines.walk_forward_validation - INFO -   Results: WIN_RATE=9.09%, Precision=0.0909, Recall=1.0000, F1=0.1667
2025-12-21 10:35:45,861 - ml.src.pipelines.walk_forward_validation - INFO - Fold 2:
2025-12-21 10:35:45,861 - ml.src.pipelines.walk_forward_validation - INFO -   Train: [50:200] = 150 samples
2025-12-21 10:35:45,862 - ml.src.pipelines.walk_forward_validation - INFO -          2025-12-01 13:00 to 2025-12-04 18:05
2025-12-21 10:35:45,862 - ml.src.pipelines.walk_forward_validation - INFO -   Test:  [200:225] = 25 samples
2025-12-21 10:35:45,862 - ml.src.pipelines.walk_forward_validation - INFO -          2025-12-04 18:10 to 2025-12-04 20:10
2025-12-21 10:35:46,030 - ml.src.training.sequence_xgb_trainer - INFO - Class balance (train): pos=16, neg=89, imbalance_ratio=5.56
2025-12-21 10:35:46,030 - ml.src.training.sequence_xgb_trainer - INFO - Applied scale_pos_weight=5.5625 to handle class imbalance
2025-12-21 10:35:46,031 - ml.src.training.sequence_xgb_trainer - INFO - [POINT 1] Cost-Sensitive Learning: using sample weights (mean=1.3048)
2025-12-21 10:35:46,031 - ml.src.training.sequence_xgb_trainer - INFO - Training XGBoost classifier...
2025-12-21 10:35:46,256 - ml.src.training.sequence_xgb_trainer - INFO - Training completed
2025-12-21 10:35:46,258 - ml.src.training.sequence_evaluation - INFO - Probability stats: min=0.4368, max=0.5895, mean=0.4712, std=0.0303
2025-12-21 10:35:46,262 - ml.src.training.sequence_evaluation - INFO - Using HYBRID optimization: EV with precision AND recall floors...
2025-12-21 10:35:46,654 - ml.src.training.sequence_evaluation - WARNING - No threshold met BOTH precision >= 0.55 AND recall >= 0.20 with >= 10 trades. Falling back to F1-optimized with precision floor.
2025-12-21 10:35:46,795 - ml.src.training.sequence_evaluation - WARNING - No threshold met precision >= 0.55 with >= 10 trades. Falling back to maximizing precision with stability constraint.
2025-12-21 10:35:47,048 - ml.src.training.sequence_evaluation - INFO - Confusion matrix@thr=0.20:
2025-12-21 10:35:47,049 - ml.src.training.sequence_evaluation - INFO -   [[TN=0, FP=25],
2025-12-21 10:35:47,049 - ml.src.training.sequence_evaluation - INFO -    [FN=0, TP=0]]
2025-12-21 10:35:47,057 - ml.src.pipelines.walk_forward_validation - INFO -   Results: WIN_RATE=0.00%, Precision=0.0000, Recall=0.0000, F1=0.0000
2025-12-21 10:35:47,058 - ml.src.pipelines.walk_forward_validation - INFO - Fold 3:
2025-12-21 10:35:47,058 - ml.src.pipelines.walk_forward_validation - INFO -   Train: [100:250] = 150 samples
2025-12-21 10:35:47,058 - ml.src.pipelines.walk_forward_validation - INFO -          2025-12-02 21:50 to 2025-12-05 09:40
2025-12-21 10:35:47,058 - ml.src.pipelines.walk_forward_validation - INFO -   Test:  [250:275] = 25 samples
2025-12-21 10:35:47,058 - ml.src.pipelines.walk_forward_validation - INFO -          2025-12-05 09:45 to 2025-12-05 11:45
2025-12-21 10:35:47,222 - ml.src.training.sequence_xgb_trainer - INFO - Class balance (train): pos=15, neg=90, imbalance_ratio=6.00
2025-12-21 10:35:47,223 - ml.src.training.sequence_xgb_trainer - INFO - Applied scale_pos_weight=6.0000 to handle class imbalance
2025-12-21 10:35:47,223 - ml.src.training.sequence_xgb_trainer - INFO - [POINT 1] Cost-Sensitive Learning: using sample weights (mean=1.2857)
2025-12-21 10:35:47,223 - ml.src.training.sequence_xgb_trainer - INFO - Training XGBoost classifier...
2025-12-21 10:35:47,430 - ml.src.training.sequence_xgb_trainer - INFO - Training completed
2025-12-21 10:35:47,436 - ml.src.training.sequence_evaluation - INFO - Probability stats: min=0.4091, max=0.4922, mean=0.4491, std=0.0348
2025-12-21 10:35:47,442 - ml.src.training.sequence_evaluation - INFO - Using HYBRID optimization: EV with precision AND recall floors...
2025-12-21 10:35:48,244 - ml.src.training.sequence_evaluation - WARNING - No threshold met BOTH precision >= 0.55 AND recall >= 0.20 with >= 10 trades. Falling back to F1-optimized with precision floor.
2025-12-21 10:35:48,417 - ml.src.training.sequence_evaluation - WARNING - No threshold met precision >= 0.55 with >= 10 trades. Falling back to maximizing precision with stability constraint.
2025-12-21 10:35:48,742 - ml.src.training.sequence_evaluation - INFO - Confusion matrix@thr=0.41:
2025-12-21 10:35:48,742 - ml.src.training.sequence_evaluation - INFO -   [[TN=10, FP=8],
2025-12-21 10:35:48,742 - ml.src.training.sequence_evaluation - INFO -    [FN=0, TP=7]]
2025-12-21 10:35:48,761 - ml.src.pipelines.walk_forward_validation - INFO -   Results: WIN_RATE=46.67%, Precision=0.4667, Recall=1.0000, F1=0.6364
2025-12-21 10:35:48,761 - ml.src.pipelines.walk_forward_validation - INFO - Fold 4:
2025-12-21 10:35:48,761 - ml.src.pipelines.walk_forward_validation - INFO -   Train: [150:300] = 150 samples
2025-12-21 10:35:48,762 - ml.src.pipelines.walk_forward_validation - INFO -          2025-12-04 10:05 to 2025-12-05 13:50
2025-12-21 10:35:48,762 - ml.src.pipelines.walk_forward_validation - INFO -   Test:  [300:325] = 25 samples
2025-12-21 10:35:48,762 - ml.src.pipelines.walk_forward_validation - INFO -          2025-12-05 13:55 to 2025-12-05 15:55
2025-12-21 10:35:49,074 - ml.src.training.sequence_xgb_trainer - INFO - Class balance (train): pos=7, neg=98, imbalance_ratio=14.00
2025-12-21 10:35:49,074 - ml.src.training.sequence_xgb_trainer - INFO - Applied scale_pos_weight=14.0000 to handle class imbalance
2025-12-21 10:35:49,074 - ml.src.training.sequence_xgb_trainer - INFO - [POINT 1] Cost-Sensitive Learning: using sample weights (mean=1.1333)
2025-12-21 10:35:49,074 - ml.src.training.sequence_xgb_trainer - INFO - Training XGBoost classifier...
2025-12-21 10:35:49,285 - ml.src.training.sequence_xgb_trainer - INFO - Training completed
2025-12-21 10:35:49,288 - ml.src.training.sequence_evaluation - INFO - Probability stats: min=0.4102, max=0.5004, mean=0.4600, std=0.0347
2025-12-21 10:35:49,292 - ml.src.training.sequence_evaluation - WARNING - [WARNING] Model has very low discriminative power (ROC-AUC=0.2647). Results may be random.
2025-12-21 10:35:49,294 - ml.src.training.sequence_evaluation - INFO - Using HYBRID optimization: EV with precision AND recall floors...
2025-12-21 10:35:49,774 - ml.src.training.sequence_evaluation - WARNING - No threshold met BOTH precision >= 0.55 AND recall >= 0.20 with >= 10 trades. Falling back to F1-optimized with precision floor.
2025-12-21 10:35:49,922 - ml.src.training.sequence_evaluation - WARNING - No threshold met precision >= 0.55 with >= 10 trades. Falling back to maximizing precision with stability constraint.
2025-12-21 10:35:50,218 - ml.src.training.sequence_evaluation - INFO - Confusion matrix@thr=0.20:
2025-12-21 10:35:50,218 - ml.src.training.sequence_evaluation - INFO -   [[TN=0, FP=17],
2025-12-21 10:35:50,218 - ml.src.training.sequence_evaluation - INFO -    [FN=0, TP=8]]
2025-12-21 10:35:50,225 - ml.src.pipelines.walk_forward_validation - INFO -   Results: WIN_RATE=32.00%, Precision=0.3200, Recall=1.0000, F1=0.4848
2025-12-21 10:35:50,225 - ml.src.pipelines.walk_forward_validation - INFO - Fold 5:
2025-12-21 10:35:50,225 - ml.src.pipelines.walk_forward_validation - INFO -   Train: [200:350] = 150 samples
2025-12-21 10:35:50,225 - ml.src.pipelines.walk_forward_validation - INFO -          2025-12-04 18:10 to 2025-12-08 14:10
2025-12-21 10:35:50,225 - ml.src.pipelines.walk_forward_validation - INFO -   Test:  [350:375] = 25 samples
2025-12-21 10:35:50,226 - ml.src.pipelines.walk_forward_validation - INFO -          2025-12-08 14:15 to 2025-12-09 10:25
2025-12-21 10:35:50,406 - ml.src.training.sequence_xgb_trainer - INFO - Class balance (train): pos=24, neg=81, imbalance_ratio=3.38
2025-12-21 10:35:50,406 - ml.src.training.sequence_xgb_trainer - INFO - Applied scale_pos_weight=3.3750 to handle class imbalance
2025-12-21 10:35:50,406 - ml.src.training.sequence_xgb_trainer - INFO - [POINT 1] Cost-Sensitive Learning: using sample weights (mean=1.4571)
2025-12-21 10:35:50,407 - ml.src.training.sequence_xgb_trainer - INFO - Training XGBoost classifier...
2025-12-21 10:35:50,653 - ml.src.training.sequence_xgb_trainer - INFO - Training completed
2025-12-21 10:35:50,655 - ml.src.training.sequence_evaluation - INFO - Probability stats: min=0.4856, max=0.7583, mean=0.6377, std=0.0716
2025-12-21 10:35:50,660 - ml.src.training.sequence_evaluation - WARNING - [WARNING] Model has very low discriminative power (ROC-AUC=0.2763). Results may be random.
2025-12-21 10:35:50,662 - ml.src.training.sequence_evaluation - INFO - Using HYBRID optimization: EV with precision AND recall floors...
2025-12-21 10:35:51,220 - ml.src.training.sequence_evaluation - WARNING - No threshold met BOTH precision >= 0.55 AND recall >= 0.20 with >= 10 trades. Falling back to F1-optimized with precision floor.
2025-12-21 10:35:51,430 - ml.src.training.sequence_evaluation - WARNING - No threshold met precision >= 0.55 with >= 10 trades. Falling back to maximizing precision with stability constraint.
2025-12-21 10:35:51,825 - ml.src.training.sequence_evaluation - INFO - Confusion matrix@thr=0.51:
2025-12-21 10:35:51,825 - ml.src.training.sequence_evaluation - INFO -   [[TN=3, FP=16],
2025-12-21 10:35:51,825 - ml.src.training.sequence_evaluation - INFO -    [FN=0, TP=6]]
2025-12-21 10:35:51,832 - ml.src.pipelines.walk_forward_validation - INFO -   Results: WIN_RATE=27.27%, Precision=0.2727, Recall=1.0000, F1=0.4286
2025-12-21 10:35:51,832 - ml.src.pipelines.walk_forward_validation - INFO - Fold 6:
2025-12-21 10:35:51,833 - ml.src.pipelines.walk_forward_validation - INFO -   Train: [250:400] = 150 samples
2025-12-21 10:35:51,833 - ml.src.pipelines.walk_forward_validation - INFO -          2025-12-05 09:45 to 2025-12-09 13:25
2025-12-21 10:35:51,833 - ml.src.pipelines.walk_forward_validation - INFO -   Test:  [400:425] = 25 samples
2025-12-21 10:35:51,834 - ml.src.pipelines.walk_forward_validation - INFO -          2025-12-09 13:35 to 2025-12-09 16:30
2025-12-21 10:35:51,997 - ml.src.training.sequence_xgb_trainer - INFO - Class balance (train): pos=28, neg=77, imbalance_ratio=2.75
2025-12-21 10:35:51,997 - ml.src.training.sequence_xgb_trainer - INFO - Applied scale_pos_weight=2.7500 to handle class imbalance
2025-12-21 10:35:51,997 - ml.src.training.sequence_xgb_trainer - INFO - [POINT 1] Cost-Sensitive Learning: using sample weights (mean=1.5333)
2025-12-21 10:35:51,997 - ml.src.training.sequence_xgb_trainer - INFO - Training XGBoost classifier...
2025-12-21 10:35:52,312 - ml.src.training.sequence_xgb_trainer - INFO - Training completed
2025-12-21 10:35:52,314 - ml.src.training.sequence_evaluation - INFO - Probability stats: min=0.4932, max=0.7105, mean=0.5815, std=0.0577
2025-12-21 10:35:52,320 - ml.src.training.sequence_evaluation - INFO - Using HYBRID optimization: EV with precision AND recall floors...
2025-12-21 10:35:52,813 - ml.src.training.sequence_evaluation - WARNING - No threshold met BOTH precision >= 0.55 AND recall >= 0.20 with >= 10 trades. Falling back to F1-optimized with precision floor.
2025-12-21 10:35:53,006 - ml.src.training.sequence_evaluation - WARNING - No threshold met precision >= 0.55 with >= 10 trades. Falling back to maximizing precision with stability constraint.
2025-12-21 10:35:53,361 - ml.src.training.sequence_evaluation - INFO - Confusion matrix@thr=0.60:
2025-12-21 10:35:53,361 - ml.src.training.sequence_evaluation - INFO -   [[TN=15, FP=6],
2025-12-21 10:35:53,361 - ml.src.training.sequence_evaluation - INFO -    [FN=0, TP=4]]
2025-12-21 10:35:53,371 - ml.src.pipelines.walk_forward_validation - INFO -   Results: WIN_RATE=40.00%, Precision=0.4000, Recall=1.0000, F1=0.5714
2025-12-21 10:35:53,371 - ml.src.pipelines.walk_forward_validation - INFO - Fold 7:
2025-12-21 10:35:53,371 - ml.src.pipelines.walk_forward_validation - INFO -   Train: [300:450] = 150 samples
2025-12-21 10:35:53,372 - ml.src.pipelines.walk_forward_validation - INFO -          2025-12-05 13:55 to 2025-12-09 18:35
2025-12-21 10:35:53,372 - ml.src.pipelines.walk_forward_validation - INFO -   Test:  [450:475] = 25 samples
2025-12-21 10:35:53,372 - ml.src.pipelines.walk_forward_validation - INFO -          2025-12-09 18:40 to 2025-12-09 20:40
2025-12-21 10:35:53,552 - ml.src.training.sequence_xgb_trainer - INFO - Class balance (train): pos=16, neg=89, imbalance_ratio=5.56
2025-12-21 10:35:53,553 - ml.src.training.sequence_xgb_trainer - INFO - Applied scale_pos_weight=5.5625 to handle class imbalance
2025-12-21 10:35:53,553 - ml.src.training.sequence_xgb_trainer - INFO - [POINT 1] Cost-Sensitive Learning: using sample weights (mean=1.3048)
2025-12-21 10:35:53,553 - ml.src.training.sequence_xgb_trainer - INFO - Training XGBoost classifier...
2025-12-21 10:35:53,767 - ml.src.training.sequence_xgb_trainer - INFO - Training completed
2025-12-21 10:35:53,772 - ml.src.training.sequence_evaluation - INFO - Probability stats: min=0.4358, max=0.4762, mean=0.4505, std=0.0111
2025-12-21 10:35:53,776 - ml.src.training.sequence_evaluation - WARNING - [WARNING] Model has very low discriminative power (ROC-AUC=0.3788). Results may be random.
2025-12-21 10:35:53,777 - ml.src.training.sequence_evaluation - INFO - Using HYBRID optimization: EV with precision AND recall floors...
2025-12-21 10:35:54,159 - ml.src.training.sequence_evaluation - WARNING - No threshold met BOTH precision >= 0.55 AND recall >= 0.20 with >= 10 trades. Falling back to F1-optimized with precision floor.
2025-12-21 10:35:54,280 - ml.src.training.sequence_evaluation - WARNING - No threshold met precision >= 0.55 with >= 10 trades. Falling back to maximizing precision with stability constraint.
2025-12-21 10:35:54,529 - ml.src.training.sequence_evaluation - INFO - Confusion matrix@thr=0.44:
2025-12-21 10:35:54,529 - ml.src.training.sequence_evaluation - INFO -   [[TN=4, FP=18],
2025-12-21 10:35:54,529 - ml.src.training.sequence_evaluation - INFO -    [FN=0, TP=3]]
2025-12-21 10:35:54,538 - ml.src.pipelines.walk_forward_validation - INFO -   Results: WIN_RATE=14.29%, Precision=0.1429, Recall=1.0000, F1=0.2500
2025-12-21 10:35:54,538 - ml.src.pipelines.walk_forward_validation - INFO - Fold 8:
2025-12-21 10:35:54,538 - ml.src.pipelines.walk_forward_validation - INFO -   Train: [350:500] = 150 samples
2025-12-21 10:35:54,538 - ml.src.pipelines.walk_forward_validation - INFO -          2025-12-08 14:15 to 2025-12-10 19:30
2025-12-21 10:35:54,538 - ml.src.pipelines.walk_forward_validation - INFO -   Test:  [500:525] = 25 samples
2025-12-21 10:35:54,538 - ml.src.pipelines.walk_forward_validation - INFO -          2025-12-10 19:35 to 2025-12-10 21:45
2025-12-21 10:35:54,696 - ml.src.training.sequence_xgb_trainer - INFO - Class balance (train): pos=19, neg=86, imbalance_ratio=4.53
2025-12-21 10:35:54,697 - ml.src.training.sequence_xgb_trainer - INFO - Applied scale_pos_weight=4.5263 to handle class imbalance
2025-12-21 10:35:54,697 - ml.src.training.sequence_xgb_trainer - INFO - [POINT 1] Cost-Sensitive Learning: using sample weights (mean=1.3619)
2025-12-21 10:35:54,697 - ml.src.training.sequence_xgb_trainer - INFO - Training XGBoost classifier...
2025-12-21 10:35:54,948 - ml.src.training.sequence_xgb_trainer - INFO - Training completed
2025-12-21 10:35:54,954 - ml.src.training.sequence_evaluation - INFO - Probability stats: min=0.4473, max=0.7431, mean=0.5773, std=0.1006
2025-12-21 10:35:54,959 - ml.src.training.sequence_evaluation - WARNING - [WARNING] Model has very low discriminative power (ROC-AUC=0.1706). Results may be random.
2025-12-21 10:35:54,961 - ml.src.training.sequence_evaluation - INFO - Using HYBRID optimization: EV with precision AND recall floors...
2025-12-21 10:35:55,526 - ml.src.training.sequence_evaluation - WARNING - No threshold met BOTH precision >= 0.55 AND recall >= 0.20 with >= 10 trades. Falling back to F1-optimized with precision floor.
2025-12-21 10:35:55,730 - ml.src.training.sequence_evaluation - WARNING - No threshold met precision >= 0.55 with >= 10 trades. Falling back to maximizing precision with stability constraint.
2025-12-21 10:35:56,097 - ml.src.training.sequence_evaluation - INFO - Confusion matrix@thr=0.20:
2025-12-21 10:35:56,097 - ml.src.training.sequence_evaluation - INFO -   [[TN=0, FP=18],
2025-12-21 10:35:56,097 - ml.src.training.sequence_evaluation - INFO -    [FN=0, TP=7]]
2025-12-21 10:35:56,106 - ml.src.pipelines.walk_forward_validation - INFO -   Results: WIN_RATE=28.00%, Precision=0.2800, Recall=1.0000, F1=0.4375
2025-12-21 10:35:56,106 - ml.src.pipelines.walk_forward_validation - INFO - Fold 9:
2025-12-21 10:35:56,106 - ml.src.pipelines.walk_forward_validation - INFO -   Train: [400:550] = 150 samples
2025-12-21 10:35:56,106 - ml.src.pipelines.walk_forward_validation - INFO -          2025-12-09 13:35 to 2025-12-11 14:40
2025-12-21 10:35:56,106 - ml.src.pipelines.walk_forward_validation - INFO -   Test:  [550:575] = 25 samples
2025-12-21 10:35:56,107 - ml.src.pipelines.walk_forward_validation - INFO -          2025-12-11 14:45 to 2025-12-11 16:45
2025-12-21 10:35:56,278 - ml.src.training.sequence_xgb_trainer - INFO - Class balance (train): pos=15, neg=90, imbalance_ratio=6.00
2025-12-21 10:35:56,278 - ml.src.training.sequence_xgb_trainer - INFO - Applied scale_pos_weight=6.0000 to handle class imbalance
2025-12-21 10:35:56,278 - ml.src.training.sequence_xgb_trainer - INFO - [POINT 1] Cost-Sensitive Learning: using sample weights (mean=1.2857)
2025-12-21 10:35:56,278 - ml.src.training.sequence_xgb_trainer - INFO - Training XGBoost classifier...
2025-12-21 10:35:56,574 - ml.src.training.sequence_xgb_trainer - INFO - Training completed
2025-12-21 10:35:56,578 - ml.src.training.sequence_evaluation - INFO - Probability stats: min=0.4141, max=0.5244, mean=0.4556, std=0.0334
2025-12-21 10:35:56,586 - ml.src.training.sequence_evaluation - INFO - Using HYBRID optimization: EV with precision AND recall floors...
2025-12-21 10:35:56,996 - ml.src.training.sequence_evaluation - INFO - Hybrid-optimized threshold: 0.10 with EV=1.0000 (precision=0.8800, recall=1.0000, win_coeff=1.0, loss_coeff=-1.0)
2025-12-21 10:35:56,997 - ml.src.training.sequence_evaluation - INFO - Confusion matrix@thr=0.10:
2025-12-21 10:35:56,997 - ml.src.training.sequence_evaluation - INFO -   [[TN=0, FP=3],
2025-12-21 10:35:56,997 - ml.src.training.sequence_evaluation - INFO -    [FN=0, TP=22]]
2025-12-21 10:35:57,005 - ml.src.pipelines.walk_forward_validation - INFO -   Results: WIN_RATE=88.00%, Precision=0.8800, Recall=1.0000, F1=0.9362
2025-12-21 10:35:57,006 - ml.src.pipelines.walk_forward_validation - INFO - Fold 10:
2025-12-21 10:35:57,006 - ml.src.pipelines.walk_forward_validation - INFO -   Train: [450:600] = 150 samples
2025-12-21 10:35:57,006 - ml.src.pipelines.walk_forward_validation - INFO -          2025-12-09 18:40 to 2025-12-11 18:50
2025-12-21 10:35:57,006 - ml.src.pipelines.walk_forward_validation - INFO -   Test:  [600:625] = 25 samples
2025-12-21 10:35:57,007 - ml.src.pipelines.walk_forward_validation - INFO -          2025-12-11 18:55 to 2025-12-11 20:55
2025-12-21 10:35:57,166 - ml.src.training.sequence_xgb_trainer - INFO - Class balance (train): pos=24, neg=81, imbalance_ratio=3.38
2025-12-21 10:35:57,166 - ml.src.training.sequence_xgb_trainer - INFO - Applied scale_pos_weight=3.3750 to handle class imbalance
2025-12-21 10:35:57,167 - ml.src.training.sequence_xgb_trainer - INFO - [POINT 1] Cost-Sensitive Learning: using sample weights (mean=1.4571)
2025-12-21 10:35:57,167 - ml.src.training.sequence_xgb_trainer - INFO - Training XGBoost classifier...
2025-12-21 10:35:57,461 - ml.src.training.sequence_xgb_trainer - INFO - Training completed
2025-12-21 10:35:57,465 - ml.src.training.sequence_evaluation - INFO - Probability stats: min=0.4178, max=0.6703, mean=0.5095, std=0.0796
2025-12-21 10:35:57,471 - ml.src.training.sequence_evaluation - WARNING - [WARNING] Model has very low discriminative power (ROC-AUC=0.3294). Results may be random.
2025-12-21 10:35:57,474 - ml.src.training.sequence_evaluation - INFO - Using HYBRID optimization: EV with precision AND recall floors...
2025-12-21 10:35:57,960 - ml.src.training.sequence_evaluation - WARNING - No threshold met BOTH precision >= 0.55 AND recall >= 0.20 with >= 10 trades. Falling back to F1-optimized with precision floor.
2025-12-21 10:35:58,136 - ml.src.training.sequence_evaluation - WARNING - No threshold met precision >= 0.55 with >= 10 trades. Falling back to maximizing precision with stability constraint.
2025-12-21 10:35:58,464 - ml.src.training.sequence_evaluation - INFO - Confusion matrix@thr=0.20:
2025-12-21 10:35:58,464 - ml.src.training.sequence_evaluation - INFO -   [[TN=0, FP=18],
2025-12-21 10:35:58,464 - ml.src.training.sequence_evaluation - INFO -    [FN=0, TP=7]]
2025-12-21 10:35:58,475 - ml.src.pipelines.walk_forward_validation - INFO -   Results: WIN_RATE=28.00%, Precision=0.2800, Recall=1.0000, F1=0.4375
2025-12-21 10:35:58,475 - ml.src.pipelines.walk_forward_validation - INFO - Fold 11:
2025-12-21 10:35:58,475 - ml.src.pipelines.walk_forward_validation - INFO -   Train: [500:650] = 150 samples
2025-12-21 10:35:58,475 - ml.src.pipelines.walk_forward_validation - INFO -          2025-12-10 19:35 to 2025-12-12 09:00
2025-12-21 10:35:58,475 - ml.src.pipelines.walk_forward_validation - INFO -   Test:  [650:675] = 25 samples
2025-12-21 10:35:58,475 - ml.src.pipelines.walk_forward_validation - INFO -          2025-12-12 09:05 to 2025-12-12 11:05
2025-12-21 10:35:58,628 - ml.src.training.sequence_xgb_trainer - INFO - Class balance (train): pos=38, neg=67, imbalance_ratio=1.76
2025-12-21 10:35:58,628 - ml.src.training.sequence_xgb_trainer - INFO - Applied scale_pos_weight=1.7632 to handle class imbalance
2025-12-21 10:35:58,628 - ml.src.training.sequence_xgb_trainer - INFO - [POINT 1] Cost-Sensitive Learning: using sample weights (mean=1.7238)
2025-12-21 10:35:58,628 - ml.src.training.sequence_xgb_trainer - INFO - Training XGBoost classifier...
2025-12-21 10:35:58,919 - ml.src.training.sequence_xgb_trainer - INFO - Training completed
2025-12-21 10:35:58,923 - ml.src.training.sequence_evaluation - INFO - Probability stats: min=0.4845, max=0.6476, mean=0.5948, std=0.0517
2025-12-21 10:35:58,928 - ml.src.training.sequence_evaluation - INFO - Using HYBRID optimization: EV with precision AND recall floors...
2025-12-21 10:35:59,409 - ml.src.training.sequence_evaluation - INFO - Hybrid-optimized threshold: 0.49 with EV=1.0000 (precision=0.6190, recall=1.0000, win_coeff=1.0, loss_coeff=-1.0)
2025-12-21 10:35:59,410 - ml.src.training.sequence_evaluation - INFO - Confusion matrix@thr=0.49:
2025-12-21 10:35:59,410 - ml.src.training.sequence_evaluation - INFO -   [[TN=4, FP=8],
2025-12-21 10:35:59,410 - ml.src.training.sequence_evaluation - INFO -    [FN=0, TP=13]]
2025-12-21 10:35:59,418 - ml.src.pipelines.walk_forward_validation - INFO -   Results: WIN_RATE=61.90%, Precision=0.6190, Recall=1.0000, F1=0.7647
2025-12-21 10:35:59,418 - ml.src.pipelines.walk_forward_validation - INFO - Fold 12:
2025-12-21 10:35:59,418 - ml.src.pipelines.walk_forward_validation - INFO -   Train: [550:700] = 150 samples
2025-12-21 10:35:59,418 - ml.src.pipelines.walk_forward_validation - INFO -          2025-12-11 14:45 to 2025-12-12 13:10
2025-12-21 10:35:59,418 - ml.src.pipelines.walk_forward_validation - INFO -   Test:  [700:725] = 25 samples
2025-12-21 10:35:59,419 - ml.src.pipelines.walk_forward_validation - INFO -          2025-12-12 13:15 to 2025-12-12 18:15
2025-12-21 10:35:59,575 - ml.src.training.sequence_xgb_trainer - INFO - Class balance (train): pos=42, neg=63, imbalance_ratio=1.50
2025-12-21 10:35:59,575 - ml.src.training.sequence_xgb_trainer - INFO - Applied scale_pos_weight=1.5000 to handle class imbalance
2025-12-21 10:35:59,575 - ml.src.training.sequence_xgb_trainer - INFO - [POINT 1] Cost-Sensitive Learning: using sample weights (mean=1.8000)
2025-12-21 10:35:59,576 - ml.src.training.sequence_xgb_trainer - INFO - Training XGBoost classifier...
2025-12-21 10:35:59,873 - ml.src.training.sequence_xgb_trainer - INFO - Training completed
2025-12-21 10:35:59,877 - ml.src.training.sequence_evaluation - INFO - Probability stats: min=0.6452, max=0.8115, mean=0.7301, std=0.0460
2025-12-21 10:35:59,883 - ml.src.training.sequence_evaluation - INFO - Using HYBRID optimization: EV with precision AND recall floors...
2025-12-21 10:36:00,510 - ml.src.training.sequence_evaluation - WARNING - No threshold met BOTH precision >= 0.55 AND recall >= 0.20 with >= 10 trades. Falling back to F1-optimized with precision floor.
2025-12-21 10:36:00,762 - ml.src.training.sequence_evaluation - WARNING - No threshold met precision >= 0.55 with >= 10 trades. Falling back to maximizing precision with stability constraint.
2025-12-21 10:36:01,225 - ml.src.training.sequence_evaluation - INFO - Confusion matrix@thr=0.72:
2025-12-21 10:36:01,225 - ml.src.training.sequence_evaluation - INFO -   [[TN=12, FP=11],
2025-12-21 10:36:01,225 - ml.src.training.sequence_evaluation - INFO -    [FN=0, TP=2]]
2025-12-21 10:36:01,231 - ml.src.pipelines.walk_forward_validation - INFO -   Results: WIN_RATE=15.38%, Precision=0.1538, Recall=1.0000, F1=0.2667
2025-12-21 10:36:01,231 - ml.src.pipelines.walk_forward_validation - INFO - Fold 13:
2025-12-21 10:36:01,231 - ml.src.pipelines.walk_forward_validation - INFO -   Train: [600:750] = 150 samples
2025-12-21 10:36:01,231 - ml.src.pipelines.walk_forward_validation - INFO -          2025-12-11 18:55 to 2025-12-15 10:00
2025-12-21 10:36:01,232 - ml.src.pipelines.walk_forward_validation - INFO -   Test:  [750:775] = 25 samples
2025-12-21 10:36:01,232 - ml.src.pipelines.walk_forward_validation - INFO -          2025-12-15 10:05 to 2025-12-15 12:05
2025-12-21 10:36:01,379 - ml.src.training.sequence_xgb_trainer - INFO - Class balance (train): pos=37, neg=68, imbalance_ratio=1.84
2025-12-21 10:36:01,379 - ml.src.training.sequence_xgb_trainer - INFO - Applied scale_pos_weight=1.8378 to handle class imbalance
2025-12-21 10:36:01,379 - ml.src.training.sequence_xgb_trainer - INFO - [POINT 1] Cost-Sensitive Learning: using sample weights (mean=1.7048)
2025-12-21 10:36:01,379 - ml.src.training.sequence_xgb_trainer - INFO - Training XGBoost classifier...
2025-12-21 10:36:01,722 - ml.src.training.sequence_xgb_trainer - INFO - Training completed
2025-12-21 10:36:01,725 - ml.src.training.sequence_evaluation - INFO - Probability stats: min=0.5862, max=0.7931, mean=0.7011, std=0.0597
2025-12-21 10:36:01,728 - ml.src.training.sequence_evaluation - INFO - Using HYBRID optimization: EV with precision AND recall floors...
2025-12-21 10:36:02,371 - ml.src.training.sequence_evaluation - WARNING - No threshold met BOTH precision >= 0.55 AND recall >= 0.20 with >= 10 trades. Falling back to F1-optimized with precision floor.
2025-12-21 10:36:02,673 - ml.src.training.sequence_evaluation - WARNING - No threshold met precision >= 0.55 with >= 10 trades. Falling back to maximizing precision with stability constraint.
2025-12-21 10:36:03,328 - ml.src.training.sequence_evaluation - INFO - Confusion matrix@thr=0.72:
2025-12-21 10:36:03,329 - ml.src.training.sequence_evaluation - INFO -   [[TN=15, FP=5],
2025-12-21 10:36:03,329 - ml.src.training.sequence_evaluation - INFO -    [FN=0, TP=5]]
2025-12-21 10:36:03,337 - ml.src.pipelines.walk_forward_validation - INFO -   Results: WIN_RATE=50.00%, Precision=0.5000, Recall=1.0000, F1=0.6667
2025-12-21 10:36:03,338 - ml.src.pipelines.walk_forward_validation - INFO - Fold 14:
2025-12-21 10:36:03,338 - ml.src.pipelines.walk_forward_validation - INFO -   Train: [650:800] = 150 samples
2025-12-21 10:36:03,338 - ml.src.pipelines.walk_forward_validation - INFO -          2025-12-12 09:05 to 2025-12-15 14:10
2025-12-21 10:36:03,338 - ml.src.pipelines.walk_forward_validation - INFO -   Test:  [800:825] = 25 samples
2025-12-21 10:36:03,339 - ml.src.pipelines.walk_forward_validation - INFO -          2025-12-15 14:35 to 2025-12-16 14:55
2025-12-21 10:36:03,529 - ml.src.training.sequence_xgb_trainer - INFO - Class balance (train): pos=20, neg=85, imbalance_ratio=4.25
2025-12-21 10:36:03,529 - ml.src.training.sequence_xgb_trainer - INFO - Applied scale_pos_weight=4.2500 to handle class imbalance
2025-12-21 10:36:03,529 - ml.src.training.sequence_xgb_trainer - INFO - [POINT 1] Cost-Sensitive Learning: using sample weights (mean=1.3810)
2025-12-21 10:36:03,529 - ml.src.training.sequence_xgb_trainer - INFO - Training XGBoost classifier...
2025-12-21 10:36:03,822 - ml.src.training.sequence_xgb_trainer - INFO - Training completed
2025-12-21 10:36:03,825 - ml.src.training.sequence_evaluation - INFO - Probability stats: min=0.4615, max=0.7269, mean=0.6412, std=0.0773
2025-12-21 10:36:03,829 - ml.src.training.sequence_evaluation - WARNING - [WARNING] Model has very low discriminative power (ROC-AUC=0.1987). Results may be random.
2025-12-21 10:36:03,832 - ml.src.training.sequence_evaluation - INFO - Using HYBRID optimization: EV with precision AND recall floors...
2025-12-21 10:36:04,378 - ml.src.training.sequence_evaluation - WARNING - No threshold met BOTH precision >= 0.55 AND recall >= 0.20 with >= 10 trades. Falling back to F1-optimized with precision floor.
2025-12-21 10:36:04,582 - ml.src.training.sequence_evaluation - WARNING - No threshold met precision >= 0.55 with >= 10 trades. Falling back to maximizing precision with stability constraint.
2025-12-21 10:36:04,994 - ml.src.training.sequence_evaluation - INFO - Confusion matrix@thr=0.47:
2025-12-21 10:36:04,994 - ml.src.training.sequence_evaluation - INFO -   [[TN=1, FP=12],
2025-12-21 10:36:04,994 - ml.src.training.sequence_evaluation - INFO -    [FN=0, TP=12]]
2025-12-21 10:36:05,001 - ml.src.pipelines.walk_forward_validation - INFO -   Results: WIN_RATE=50.00%, Precision=0.5000, Recall=1.0000, F1=0.6667
2025-12-21 10:36:05,002 - ml.src.pipelines.walk_forward_validation - INFO - Fold 15:
2025-12-21 10:36:05,002 - ml.src.pipelines.walk_forward_validation - INFO -   Train: [700:850] = 150 samples
2025-12-21 10:36:05,002 - ml.src.pipelines.walk_forward_validation - INFO -          2025-12-12 13:15 to 2025-12-16 17:05
2025-12-21 10:36:05,002 - ml.src.pipelines.walk_forward_validation - INFO -   Test:  [850:875] = 25 samples
2025-12-21 10:36:05,002 - ml.src.pipelines.walk_forward_validation - INFO -          2025-12-16 17:10 to 2025-12-16 19:10
2025-12-21 10:36:05,161 - ml.src.training.sequence_xgb_trainer - INFO - Class balance (train): pos=12, neg=93, imbalance_ratio=7.75
2025-12-21 10:36:05,161 - ml.src.training.sequence_xgb_trainer - INFO - Applied scale_pos_weight=7.7500 to handle class imbalance
2025-12-21 10:36:05,161 - ml.src.training.sequence_xgb_trainer - INFO - [POINT 1] Cost-Sensitive Learning: using sample weights (mean=1.2286)
2025-12-21 10:36:05,162 - ml.src.training.sequence_xgb_trainer - INFO - Training XGBoost classifier...
2025-12-21 10:36:05,434 - ml.src.training.sequence_xgb_trainer - INFO - Training completed
2025-12-21 10:36:05,437 - ml.src.training.sequence_evaluation - INFO - Probability stats: min=0.4379, max=0.6080, mean=0.5310, std=0.0578
2025-12-21 10:36:05,442 - ml.src.training.sequence_evaluation - INFO - Using HYBRID optimization: EV with precision AND recall floors...
2025-12-21 10:36:05,895 - ml.src.training.sequence_evaluation - WARNING - No threshold met BOTH precision >= 0.55 AND recall >= 0.20 with >= 10 trades. Falling back to F1-optimized with precision floor.
2025-12-21 10:36:06,070 - ml.src.training.sequence_evaluation - WARNING - No threshold met precision >= 0.55 with >= 10 trades. Falling back to maximizing precision with stability constraint.
2025-12-21 10:36:06,385 - ml.src.training.sequence_evaluation - INFO - Confusion matrix@thr=0.57:
2025-12-21 10:36:06,385 - ml.src.training.sequence_evaluation - INFO -   [[TN=15, FP=9],
2025-12-21 10:36:06,386 - ml.src.training.sequence_evaluation - INFO -    [FN=0, TP=1]]
2025-12-21 10:36:06,392 - ml.src.pipelines.walk_forward_validation - INFO -   Results: WIN_RATE=10.00%, Precision=0.1000, Recall=1.0000, F1=0.1818
2025-12-21 10:36:06,393 - ml.src.pipelines.walk_forward_validation - INFO - Fold 16:
2025-12-21 10:36:06,393 - ml.src.pipelines.walk_forward_validation - INFO -   Train: [750:900] = 150 samples
2025-12-21 10:36:06,393 - ml.src.pipelines.walk_forward_validation - INFO -          2025-12-15 10:05 to 2025-12-16 21:40
2025-12-21 10:36:06,393 - ml.src.pipelines.walk_forward_validation - INFO -   Test:  [900:925] = 25 samples
2025-12-21 10:36:06,393 - ml.src.pipelines.walk_forward_validation - INFO -          2025-12-16 21:45 to 2025-12-17 10:05
2025-12-21 10:36:06,554 - ml.src.training.sequence_xgb_trainer - INFO - Class balance (train): pos=17, neg=88, imbalance_ratio=5.18
2025-12-21 10:36:06,555 - ml.src.training.sequence_xgb_trainer - INFO - Applied scale_pos_weight=5.1765 to handle class imbalance
2025-12-21 10:36:06,555 - ml.src.training.sequence_xgb_trainer - INFO - [POINT 1] Cost-Sensitive Learning: using sample weights (mean=1.3238)
2025-12-21 10:36:06,555 - ml.src.training.sequence_xgb_trainer - INFO - Training XGBoost classifier...
2025-12-21 10:36:06,796 - ml.src.training.sequence_xgb_trainer - INFO - Training completed
2025-12-21 10:36:06,800 - ml.src.training.sequence_evaluation - INFO - Probability stats: min=0.4179, max=0.7059, mean=0.5199, std=0.0797
2025-12-21 10:36:06,803 - ml.src.training.sequence_evaluation - INFO - Using HYBRID optimization: EV with precision AND recall floors...
2025-12-21 10:36:07,230 - ml.src.training.sequence_evaluation - WARNING - No threshold met BOTH precision >= 0.55 AND recall >= 0.20 with >= 10 trades. Falling back to F1-optimized with precision floor.
2025-12-21 10:36:07,372 - ml.src.training.sequence_evaluation - WARNING - No threshold met precision >= 0.55 with >= 10 trades. Falling back to maximizing precision with stability constraint.
2025-12-21 10:36:07,657 - ml.src.training.sequence_evaluation - INFO - Confusion matrix@thr=0.50:
2025-12-21 10:36:07,657 - ml.src.training.sequence_evaluation - INFO -   [[TN=13, FP=9],
2025-12-21 10:36:07,657 - ml.src.training.sequence_evaluation - INFO -    [FN=0, TP=3]]
2025-12-21 10:36:07,663 - ml.src.pipelines.walk_forward_validation - INFO -   Results: WIN_RATE=25.00%, Precision=0.2500, Recall=1.0000, F1=0.4000
2025-12-21 10:36:07,663 - ml.src.pipelines.walk_forward_validation - INFO - Fold 17:
2025-12-21 10:36:07,663 - ml.src.pipelines.walk_forward_validation - INFO -   Train: [800:950] = 150 samples
2025-12-21 10:36:07,664 - ml.src.pipelines.walk_forward_validation - INFO -          2025-12-15 14:35 to 2025-12-17 13:20
2025-12-21 10:36:07,664 - ml.src.pipelines.walk_forward_validation - INFO -   Test:  [950:975] = 25 samples
2025-12-21 10:36:07,664 - ml.src.pipelines.walk_forward_validation - INFO -          2025-12-17 13:25 to 2025-12-17 16:00
2025-12-21 10:36:07,825 - ml.src.training.sequence_xgb_trainer - INFO - Class balance (train): pos=25, neg=80, imbalance_ratio=3.20
2025-12-21 10:36:07,826 - ml.src.training.sequence_xgb_trainer - INFO - Applied scale_pos_weight=3.2000 to handle class imbalance
2025-12-21 10:36:07,826 - ml.src.training.sequence_xgb_trainer - INFO - [POINT 1] Cost-Sensitive Learning: using sample weights (mean=1.4762)
2025-12-21 10:36:07,826 - ml.src.training.sequence_xgb_trainer - INFO - Training XGBoost classifier...
2025-12-21 10:36:08,083 - ml.src.training.sequence_xgb_trainer - INFO - Training completed
2025-12-21 10:36:08,086 - ml.src.training.sequence_evaluation - INFO - Probability stats: min=0.4102, max=0.6566, mean=0.5266, std=0.0871
2025-12-21 10:36:08,090 - ml.src.training.sequence_evaluation - WARNING - [WARNING] Model has very low discriminative power (ROC-AUC=0.4737). Results may be random.
2025-12-21 10:36:08,093 - ml.src.training.sequence_evaluation - INFO - Using HYBRID optimization: EV with precision AND recall floors...
2025-12-21 10:36:08,575 - ml.src.training.sequence_evaluation - WARNING - No threshold met BOTH precision >= 0.55 AND recall >= 0.20 with >= 10 trades. Falling back to F1-optimized with precision floor.
2025-12-21 10:36:08,731 - ml.src.training.sequence_evaluation - WARNING - No threshold met precision >= 0.55 with >= 10 trades. Falling back to maximizing precision with stability constraint.
2025-12-21 10:36:09,068 - ml.src.training.sequence_evaluation - INFO - Confusion matrix@thr=0.52:
2025-12-21 10:36:09,068 - ml.src.training.sequence_evaluation - INFO -   [[TN=10, FP=9],
2025-12-21 10:36:09,069 - ml.src.training.sequence_evaluation - INFO -    [FN=2, TP=4]]
2025-12-21 10:36:09,074 - ml.src.pipelines.walk_forward_validation - INFO -   Results: WIN_RATE=30.77%, Precision=0.3077, Recall=0.6667, F1=0.4211
2025-12-21 10:36:09,074 - ml.src.pipelines.walk_forward_validation - INFO - Fold 18:
2025-12-21 10:36:09,074 - ml.src.pipelines.walk_forward_validation - INFO -   Train: [850:1,000] = 150 samples
2025-12-21 10:36:09,075 - ml.src.pipelines.walk_forward_validation - INFO -          2025-12-16 17:10 to 2025-12-17 18:10
2025-12-21 10:36:09,075 - ml.src.pipelines.walk_forward_validation - INFO -   Test:  [1,000:1,025] = 25 samples
2025-12-21 10:36:09,075 - ml.src.pipelines.walk_forward_validation - INFO -          2025-12-17 18:15 to 2025-12-17 20:15
2025-12-21 10:36:09,240 - ml.src.training.sequence_xgb_trainer - INFO - Class balance (train): pos=26, neg=79, imbalance_ratio=3.04
2025-12-21 10:36:09,241 - ml.src.training.sequence_xgb_trainer - INFO - Applied scale_pos_weight=3.0385 to handle class imbalance
2025-12-21 10:36:09,241 - ml.src.training.sequence_xgb_trainer - INFO - [POINT 1] Cost-Sensitive Learning: using sample weights (mean=1.4952)
2025-12-21 10:36:09,241 - ml.src.training.sequence_xgb_trainer - INFO - Training XGBoost classifier...
2025-12-21 10:36:09,542 - ml.src.training.sequence_xgb_trainer - INFO - Training completed
2025-12-21 10:36:09,546 - ml.src.training.sequence_evaluation - INFO - Probability stats: min=0.4114, max=0.4576, mean=0.4144, std=0.0099
2025-12-21 10:36:09,551 - ml.src.training.sequence_evaluation - WARNING - [WARNING] Model has very low discriminative power (ROC-AUC=0.4091). Results may be random.
2025-12-21 10:36:09,554 - ml.src.training.sequence_evaluation - INFO - Using HYBRID optimization: EV with precision AND recall floors...
2025-12-21 10:36:09,874 - ml.src.training.sequence_evaluation - WARNING - No threshold met BOTH precision >= 0.55 AND recall >= 0.20 with >= 10 trades. Falling back to F1-optimized with precision floor.
2025-12-21 10:36:09,974 - ml.src.training.sequence_evaluation - WARNING - No threshold met precision >= 0.55 with >= 10 trades. Falling back to maximizing precision with stability constraint.
2025-12-21 10:36:10,181 - ml.src.training.sequence_evaluation - INFO - Confusion matrix@thr=0.20:
2025-12-21 10:36:10,181 - ml.src.training.sequence_evaluation - INFO -   [[TN=0, FP=22],
2025-12-21 10:36:10,181 - ml.src.training.sequence_evaluation - INFO -    [FN=0, TP=3]]
2025-12-21 10:36:10,190 - ml.src.pipelines.walk_forward_validation - INFO -   Results: WIN_RATE=12.00%, Precision=0.1200, Recall=1.0000, F1=0.2143
2025-12-21 10:36:10,190 - ml.src.pipelines.walk_forward_validation - INFO - 
================================================================================
2025-12-21 10:36:10,190 - ml.src.pipelines.walk_forward_validation - INFO - WALK-FORWARD VALIDATION RESULTS
2025-12-21 10:36:10,190 - ml.src.pipelines.walk_forward_validation - INFO - ================================================================================
2025-12-21 10:36:10,191 - ml.src.pipelines.walk_forward_validation - INFO - 
Aggregated Results (18 folds):

2025-12-21 10:36:10,191 - ml.src.pipelines.walk_forward_validation - INFO -   WIN RATE:   31.58% ± 21.19% (range: 0.00% - 88.00%)
2025-12-21 10:36:10,191 - ml.src.pipelines.walk_forward_validation - INFO -   Precision:  0.3158 ± 0.2119 (range: 0.0000 - 0.8800)
2025-12-21 10:36:10,191 - ml.src.pipelines.walk_forward_validation - INFO -   Recall:     0.9259 ± 0.2372 (range: 0.0000 - 1.0000)
2025-12-21 10:36:10,191 - ml.src.pipelines.walk_forward_validation - INFO -   F1 Score:   0.4406 ± 0.2317
2025-12-21 10:36:10,191 - ml.src.pipelines.walk_forward_validation - INFO -   ROC-AUC:    nan ± nan
2025-12-21 10:36:10,192 - ml.src.pipelines.walk_forward_validation - INFO - 
================================================================================
2025-12-21 10:36:10,192 - __main__ - INFO - 
================================================================================
2025-12-21 10:36:10,192 - __main__ - INFO - COMPARISON: Single Split vs Walk-Forward CV
2025-12-21 10:36:10,192 - __main__ - INFO - ================================================================================
2025-12-21 10:36:10,192 - __main__ - INFO - Baseline (single 70/15/15 split):     WIN_RATE = 85.71%
2025-12-21 10:36:10,192 - __main__ - INFO - Walk-Forward CV (18 folds): WIN_RATE = 31.58% ± 21.19%
2025-12-21 10:36:10,200 - __main__ - WARNING -      This suggests model may be overfitting or trading lookahead patterns.
2025-12-21 10:36:10,200 - __main__ - WARNING -      Baseline 85.71% may NOT be reliable for live trading.
2025-12-21 10:36:10,201 - __main__ - INFO - ================================================================================
2025-12-21 10:57:42,342 - __main__ - INFO - 
================================================================================
2025-12-21 10:57:42,342 - __main__ - INFO - WALK-FORWARD VALIDATION ANALYSIS
2025-12-21 10:57:42,342 - __main__ - INFO - ================================================================================
2025-12-21 10:57:42,343 - __main__ - INFO - Years: 2025
2025-12-21 10:57:42,343 - __main__ - INFO - Train window: 200 samples (~1000 minutes)
2025-12-21 10:57:42,343 - __main__ - INFO - Test window: 30 samples (~150 minutes)
2025-12-21 10:57:42,343 - __main__ - INFO - Step size: 50 samples (~250 minutes)
2025-12-21 10:57:42,344 - __main__ - INFO - ================================================================================

2025-12-21 10:57:42,344 - __main__ - INFO - Loading data...
2025-12-21 10:57:42,345 - ml.src.data_loading.loaders - INFO - Year filter applied: loading only [2025]
2025-12-21 10:57:42,389 - __main__ - INFO - Loaded 18,875 M1 candles
2025-12-21 10:57:42,390 - __main__ - INFO - Aggregating to M5...
2025-12-21 10:57:42,390 - ml.src.features.engineer_m5 - INFO - Aggregating 18875 M1 candles to M5...
2025-12-21 10:57:42,401 - ml.src.features.engineer_m5 - INFO - Aggregated to 3776 M5 candles (5.0x compression)
2025-12-21 10:57:42,402 - __main__ - INFO - Aggregated to 3,776 M5 candles
2025-12-21 10:57:42,402 - __main__ - INFO - Engineering features...
2025-12-21 10:57:42,402 - ml.src.features.engineer_m5 - INFO - Engineering M5 features...
2025-12-21 10:57:42,402 - ml.src.features.engineer_m5 - INFO - Aggregating 3776 M1 candles to M5...
2025-12-21 10:57:42,408 - ml.src.features.engineer_m5 - INFO - Aggregated to 3776 M5 candles (1.0x compression)
2025-12-21 10:57:42,410 - ml.src.features.engineer_m5 - INFO - Computing M5 primary features...
2025-12-21 10:57:42,623 - ml.src.features.engineer_m5 - INFO - Computing M15 context from M5...
2025-12-21 10:57:42,705 - ml.src.features.engineer_m5 - INFO - Computing M60 context from M5...
2025-12-21 10:57:42,737 - ml.src.features.engineer_m5 - INFO - M5 feature engineering complete: 3776 rows × 24 features
2025-12-21 10:57:42,738 - ml.src.features.engineer_m5 - INFO - Timeframe: M5 (5-minute candles)
2025-12-21 10:57:42,738 - ml.src.features.engineer_m5 - INFO - Date range: 2025-12-01 00:00:00 to 2025-12-18 17:35:00
2025-12-21 10:57:42,739 - __main__ - INFO - Engineered 24 features
2025-12-21 10:57:42,739 - __main__ - INFO - Creating targets...
2025-12-21 10:57:42,739 - ml.src.targets.target_maker - INFO - Creating targets (SL/TP simulation) for 3,776 candles...
2025-12-21 10:57:42,739 - ml.src.targets.target_maker - INFO - Parameters: SL=1×ATR, TP=3.0×ATR, min_hold=2min, max_horizon=60min
2025-12-21 10:57:42,740 - ml.src.targets.target_maker - INFO - Calculating M1 ATR(14) for SL/TP targets (fallback)
2025-12-21 10:57:42,743 - ml.src.targets.target_maker - INFO - Target creation complete: 3,716 valid targets
2025-12-21 10:57:42,744 - __main__ - INFO - Created targets: 871 positive, 2,845 negative
2025-12-21 10:57:42,745 - __main__ - INFO - Building sequences...
2025-12-21 10:57:42,748 - ml.src.sequences.sequencer - INFO - M5 alignment filter disabled; keeping all timestamps irrespective of minute alignment
2025-12-21 10:57:42,749 - ml.src.sequences.sequencer - INFO - Applied Trend Filter (dist_sma_200 > 0.00, ADX > 15.00): kept 1711/3667 (46.7%)
2025-12-21 10:57:42,749 - ml.src.sequences.sequencer - INFO - Pullback filter disabled; not constraining RSI_M5
2025-12-21 10:57:42,749 - ml.src.sequences.sequencer - INFO - Session filter 'london_ny': keeping 1,039 / 3,667 windows (28.3%)
2025-12-21 10:57:42,751 - __main__ - INFO - Built 1,039 sequences
2025-12-21 10:57:42,752 - ml.src.pipelines.walk_forward_validation - INFO - 
================================================================================
2025-12-21 10:57:42,752 - ml.src.pipelines.walk_forward_validation - INFO - [POINT 6] WALK-FORWARD CROSS-VALIDATION - Time-Series Validation
2025-12-21 10:57:42,752 - ml.src.pipelines.walk_forward_validation - INFO - ================================================================================
2025-12-21 10:57:42,752 - ml.src.pipelines.walk_forward_validation - INFO - Data size: 1,039 samples (1039 timestamps)
2025-12-21 10:57:42,753 - ml.src.pipelines.walk_forward_validation - INFO - Train window: 200 samples (~1000 minutes)
2025-12-21 10:57:42,753 - ml.src.pipelines.walk_forward_validation - INFO - Test window: 30 samples (~150 minutes)
2025-12-21 10:57:42,753 - ml.src.pipelines.walk_forward_validation - INFO - Step size: 50 samples (~250 minutes)
2025-12-21 10:57:42,753 - ml.src.pipelines.walk_forward_validation - INFO - No lookahead bias: test set is ALWAYS future relative to training set
2025-12-21 10:57:42,754 - ml.src.pipelines.walk_forward_validation - INFO - ================================================================================

2025-12-21 10:57:42,754 - ml.src.pipelines.walk_forward_validation - INFO - Fold 1:
2025-12-21 10:57:42,754 - ml.src.pipelines.walk_forward_validation - INFO -   Train: [0:200] = 200 samples
2025-12-21 10:57:42,754 - ml.src.pipelines.walk_forward_validation - INFO -          2025-12-01 08:15 to 2025-12-04 18:05
2025-12-21 10:57:42,755 - ml.src.pipelines.walk_forward_validation - INFO -   Test:  [200:230] = 30 samples
2025-12-21 10:57:42,755 - ml.src.pipelines.walk_forward_validation - INFO -          2025-12-04 18:10 to 2025-12-04 20:35
2025-12-21 10:57:42,888 - ml.src.training.sequence_xgb_trainer - INFO - Class balance (train): pos=23, neg=117, imbalance_ratio=5.09
2025-12-21 10:57:42,889 - ml.src.training.sequence_xgb_trainer - INFO - Applied scale_pos_weight=5.0870 to handle class imbalance
2025-12-21 10:57:42,889 - ml.src.training.sequence_xgb_trainer - INFO - [POINT 1] Cost-Sensitive Learning: using sample weights (mean=1.3286)
2025-12-21 10:57:42,889 - ml.src.training.sequence_xgb_trainer - INFO - Training XGBoost classifier...
2025-12-21 10:57:43,157 - ml.src.training.sequence_xgb_trainer - INFO - Training completed
2025-12-21 10:57:43,160 - ml.src.training.sequence_evaluation - INFO - Probability stats: min=0.4130, max=0.5772, mean=0.4551, std=0.0480
2025-12-21 10:57:43,166 - ml.src.training.sequence_evaluation - INFO - Using HYBRID optimization: EV with precision AND recall floors...
2025-12-21 10:57:43,431 - ml.src.training.sequence_evaluation - WARNING - No threshold met BOTH precision >= 0.55 AND recall >= 0.20 with >= 10 trades. Falling back to F1-optimized with precision floor.
2025-12-21 10:57:43,521 - ml.src.training.sequence_evaluation - WARNING - No threshold met precision >= 0.55 with >= 10 trades. Falling back to maximizing precision with stability constraint.
2025-12-21 10:57:43,700 - ml.src.training.sequence_evaluation - INFO - Confusion matrix@thr=0.20:
2025-12-21 10:57:43,700 - ml.src.training.sequence_evaluation - INFO -   [[TN=0, FP=30],
2025-12-21 10:57:43,701 - ml.src.training.sequence_evaluation - INFO -    [FN=0, TP=0]]
2025-12-21 10:57:43,706 - ml.src.pipelines.walk_forward_validation - INFO -   Results: WIN_RATE=0.00%, Precision=0.0000, Recall=0.0000, F1=0.0000
2025-12-21 10:57:43,706 - ml.src.pipelines.walk_forward_validation - INFO - Fold 2:
2025-12-21 10:57:43,706 - ml.src.pipelines.walk_forward_validation - INFO -   Train: [50:250] = 200 samples
2025-12-21 10:57:43,707 - ml.src.pipelines.walk_forward_validation - INFO -          2025-12-01 13:00 to 2025-12-05 09:40
2025-12-21 10:57:43,707 - ml.src.pipelines.walk_forward_validation - INFO -   Test:  [250:280] = 30 samples
2025-12-21 10:57:43,707 - ml.src.pipelines.walk_forward_validation - INFO -          2025-12-05 09:45 to 2025-12-05 12:10
2025-12-21 10:57:43,836 - ml.src.training.sequence_xgb_trainer - INFO - Class balance (train): pos=17, neg=123, imbalance_ratio=7.24
2025-12-21 10:57:43,836 - ml.src.training.sequence_xgb_trainer - INFO - Applied scale_pos_weight=7.2353 to handle class imbalance
2025-12-21 10:57:43,837 - ml.src.training.sequence_xgb_trainer - INFO - [POINT 1] Cost-Sensitive Learning: using sample weights (mean=1.2429)
2025-12-21 10:57:43,837 - ml.src.training.sequence_xgb_trainer - INFO - Training XGBoost classifier...
2025-12-21 10:57:44,137 - ml.src.training.sequence_xgb_trainer - INFO - Training completed
2025-12-21 10:57:44,139 - ml.src.training.sequence_evaluation - INFO - Probability stats: min=0.4391, max=0.6075, mean=0.5146, std=0.0624
2025-12-21 10:57:44,142 - ml.src.training.sequence_evaluation - INFO - Using HYBRID optimization: EV with precision AND recall floors...
2025-12-21 10:57:44,464 - ml.src.training.sequence_evaluation - WARNING - No threshold met BOTH precision >= 0.55 AND recall >= 0.20 with >= 10 trades. Falling back to F1-optimized with precision floor.
2025-12-21 10:57:44,585 - ml.src.training.sequence_evaluation - WARNING - No threshold met precision >= 0.55 with >= 10 trades. Falling back to maximizing precision with stability constraint.
2025-12-21 10:57:44,830 - ml.src.training.sequence_evaluation - INFO - Confusion matrix@thr=0.47:
2025-12-21 10:57:44,831 - ml.src.training.sequence_evaluation - INFO -   [[TN=12, FP=9],
2025-12-21 10:57:44,831 - ml.src.training.sequence_evaluation - INFO -    [FN=0, TP=9]]
2025-12-21 10:57:44,836 - ml.src.pipelines.walk_forward_validation - INFO -   Results: WIN_RATE=50.00%, Precision=0.5000, Recall=1.0000, F1=0.6667
2025-12-21 10:57:44,836 - ml.src.pipelines.walk_forward_validation - INFO - Fold 3:
2025-12-21 10:57:44,837 - ml.src.pipelines.walk_forward_validation - INFO -   Train: [100:300] = 200 samples
2025-12-21 10:57:44,837 - ml.src.pipelines.walk_forward_validation - INFO -          2025-12-02 21:50 to 2025-12-05 13:50
2025-12-21 10:57:44,837 - ml.src.pipelines.walk_forward_validation - INFO -   Test:  [300:330] = 30 samples
2025-12-21 10:57:44,838 - ml.src.pipelines.walk_forward_validation - INFO -          2025-12-05 13:55 to 2025-12-08 11:30
2025-12-21 10:57:44,967 - ml.src.training.sequence_xgb_trainer - INFO - Class balance (train): pos=15, neg=125, imbalance_ratio=8.33
2025-12-21 10:57:44,968 - ml.src.training.sequence_xgb_trainer - INFO - Applied scale_pos_weight=8.3333 to handle class imbalance
2025-12-21 10:57:44,968 - ml.src.training.sequence_xgb_trainer - INFO - [POINT 1] Cost-Sensitive Learning: using sample weights (mean=1.2143)
2025-12-21 10:57:44,968 - ml.src.training.sequence_xgb_trainer - INFO - Training XGBoost classifier...
2025-12-21 10:57:45,155 - ml.src.training.sequence_xgb_trainer - INFO - Training completed
2025-12-21 10:57:45,158 - ml.src.training.sequence_evaluation - INFO - Probability stats: min=0.4053, max=0.5428, mean=0.4338, std=0.0332
2025-12-21 10:57:45,162 - ml.src.training.sequence_evaluation - INFO - Using HYBRID optimization: EV with precision AND recall floors...
2025-12-21 10:57:45,402 - ml.src.training.sequence_evaluation - WARNING - No threshold met BOTH precision >= 0.55 AND recall >= 0.20 with >= 10 trades. Falling back to F1-optimized with precision floor.
2025-12-21 10:57:45,483 - ml.src.training.sequence_evaluation - WARNING - No threshold met precision >= 0.55 with >= 10 trades. Falling back to maximizing precision with stability constraint.
2025-12-21 10:57:45,643 - ml.src.training.sequence_evaluation - INFO - Confusion matrix@thr=0.41:
2025-12-21 10:57:45,643 - ml.src.training.sequence_evaluation - INFO -   [[TN=10, FP=12],
2025-12-21 10:57:45,644 - ml.src.training.sequence_evaluation - INFO -    [FN=1, TP=7]]
2025-12-21 10:57:45,649 - ml.src.pipelines.walk_forward_validation - INFO -   Results: WIN_RATE=36.84%, Precision=0.3684, Recall=0.8750, F1=0.5185
2025-12-21 10:57:45,649 - ml.src.pipelines.walk_forward_validation - INFO - Fold 4:
2025-12-21 10:57:45,650 - ml.src.pipelines.walk_forward_validation - INFO -   Train: [150:350] = 200 samples
2025-12-21 10:57:45,650 - ml.src.pipelines.walk_forward_validation - INFO -          2025-12-04 10:05 to 2025-12-08 14:10
2025-12-21 10:57:45,650 - ml.src.pipelines.walk_forward_validation - INFO -   Test:  [350:380] = 30 samples
2025-12-21 10:57:45,651 - ml.src.pipelines.walk_forward_validation - INFO -          2025-12-08 14:15 to 2025-12-09 10:50
2025-12-21 10:57:45,775 - ml.src.training.sequence_xgb_trainer - INFO - Class balance (train): pos=20, neg=120, imbalance_ratio=6.00
2025-12-21 10:57:45,775 - ml.src.training.sequence_xgb_trainer - INFO - Applied scale_pos_weight=6.0000 to handle class imbalance
2025-12-21 10:57:45,775 - ml.src.training.sequence_xgb_trainer - INFO - [POINT 1] Cost-Sensitive Learning: using sample weights (mean=1.2857)
2025-12-21 10:57:45,776 - ml.src.training.sequence_xgb_trainer - INFO - Training XGBoost classifier...
2025-12-21 10:57:46,033 - ml.src.training.sequence_xgb_trainer - INFO - Training completed
2025-12-21 10:57:46,036 - ml.src.training.sequence_evaluation - INFO - Probability stats: min=0.4110, max=0.6625, mean=0.4523, std=0.0548
2025-12-21 10:57:46,041 - ml.src.training.sequence_evaluation - INFO - Using HYBRID optimization: EV with precision AND recall floors...
2025-12-21 10:57:46,310 - ml.src.training.sequence_evaluation - WARNING - No threshold met BOTH precision >= 0.55 AND recall >= 0.20 with >= 10 trades. Falling back to F1-optimized with precision floor.
2025-12-21 10:57:46,403 - ml.src.training.sequence_evaluation - WARNING - No threshold met precision >= 0.55 with >= 10 trades. Falling back to maximizing precision with stability constraint.
2025-12-21 10:57:46,584 - ml.src.training.sequence_evaluation - INFO - Confusion matrix@thr=0.45:
2025-12-21 10:57:46,585 - ml.src.training.sequence_evaluation - INFO -   [[TN=17, FP=7],
2025-12-21 10:57:46,585 - ml.src.training.sequence_evaluation - INFO -    [FN=0, TP=6]]
2025-12-21 10:57:46,590 - ml.src.pipelines.walk_forward_validation - INFO -   Results: WIN_RATE=46.15%, Precision=0.4615, Recall=1.0000, F1=0.6316
2025-12-21 10:57:46,591 - ml.src.pipelines.walk_forward_validation - INFO - Fold 5:
2025-12-21 10:57:46,591 - ml.src.pipelines.walk_forward_validation - INFO -   Train: [200:400] = 200 samples
2025-12-21 10:57:46,592 - ml.src.pipelines.walk_forward_validation - INFO -          2025-12-04 18:10 to 2025-12-09 13:25
2025-12-21 10:57:46,592 - ml.src.pipelines.walk_forward_validation - INFO -   Test:  [400:430] = 30 samples
2025-12-21 10:57:46,592 - ml.src.pipelines.walk_forward_validation - INFO -          2025-12-09 13:35 to 2025-12-09 16:55
2025-12-21 10:57:46,719 - ml.src.training.sequence_xgb_trainer - INFO - Class balance (train): pos=32, neg=108, imbalance_ratio=3.38
2025-12-21 10:57:46,720 - ml.src.training.sequence_xgb_trainer - INFO - Applied scale_pos_weight=3.3750 to handle class imbalance
2025-12-21 10:57:46,720 - ml.src.training.sequence_xgb_trainer - INFO - [POINT 1] Cost-Sensitive Learning: using sample weights (mean=1.4571)
2025-12-21 10:57:46,720 - ml.src.training.sequence_xgb_trainer - INFO - Training XGBoost classifier...
2025-12-21 10:57:47,040 - ml.src.training.sequence_xgb_trainer - INFO - Training completed
2025-12-21 10:57:47,043 - ml.src.training.sequence_evaluation - INFO - Probability stats: min=0.4231, max=0.5219, mean=0.4596, std=0.0304
2025-12-21 10:57:47,046 - ml.src.training.sequence_evaluation - INFO - Using HYBRID optimization: EV with precision AND recall floors...
2025-12-21 10:57:47,341 - ml.src.training.sequence_evaluation - WARNING - No threshold met BOTH precision >= 0.55 AND recall >= 0.20 with >= 10 trades. Falling back to F1-optimized with precision floor.
2025-12-21 10:57:47,436 - ml.src.training.sequence_evaluation - WARNING - No threshold met precision >= 0.55 with >= 10 trades. Falling back to maximizing precision with stability constraint.
2025-12-21 10:57:47,625 - ml.src.training.sequence_evaluation - INFO - Confusion matrix@thr=0.48:
2025-12-21 10:57:47,625 - ml.src.training.sequence_evaluation - INFO -   [[TN=18, FP=8],
2025-12-21 10:57:47,626 - ml.src.training.sequence_evaluation - INFO -    [FN=1, TP=3]]
2025-12-21 10:57:47,633 - ml.src.pipelines.walk_forward_validation - INFO -   Results: WIN_RATE=27.27%, Precision=0.2727, Recall=0.7500, F1=0.4000
2025-12-21 10:57:47,633 - ml.src.pipelines.walk_forward_validation - INFO - Fold 6:
2025-12-21 10:57:47,633 - ml.src.pipelines.walk_forward_validation - INFO -   Train: [250:450] = 200 samples
2025-12-21 10:57:47,634 - ml.src.pipelines.walk_forward_validation - INFO -          2025-12-05 09:45 to 2025-12-09 18:35
2025-12-21 10:57:47,634 - ml.src.pipelines.walk_forward_validation - INFO -   Test:  [450:480] = 30 samples
2025-12-21 10:57:47,634 - ml.src.pipelines.walk_forward_validation - INFO -          2025-12-09 18:40 to 2025-12-09 21:05
2025-12-21 10:57:47,907 - ml.src.training.sequence_xgb_trainer - INFO - Class balance (train): pos=34, neg=106, imbalance_ratio=3.12
2025-12-21 10:57:47,921 - ml.src.training.sequence_xgb_trainer - INFO - Applied scale_pos_weight=3.1176 to handle class imbalance
2025-12-21 10:57:47,921 - ml.src.training.sequence_xgb_trainer - INFO - [POINT 1] Cost-Sensitive Learning: using sample weights (mean=1.4857)
2025-12-21 10:57:47,922 - ml.src.training.sequence_xgb_trainer - INFO - Training XGBoost classifier...
2025-12-21 10:57:48,315 - ml.src.training.sequence_xgb_trainer - INFO - Training completed
2025-12-21 10:57:48,318 - ml.src.training.sequence_evaluation - INFO - Probability stats: min=0.4820, max=0.7310, mean=0.6161, std=0.0758
2025-12-21 10:57:48,322 - ml.src.training.sequence_evaluation - WARNING - [WARNING] Model has very low discriminative power (ROC-AUC=0.1358). Results may be random.
2025-12-21 10:57:48,324 - ml.src.training.sequence_evaluation - INFO - Using HYBRID optimization: EV with precision AND recall floors...
2025-12-21 10:57:48,729 - ml.src.training.sequence_evaluation - WARNING - No threshold met BOTH precision >= 0.55 AND recall >= 0.20 with >= 10 trades. Falling back to F1-optimized with precision floor.
2025-12-21 10:57:48,887 - ml.src.training.sequence_evaluation - WARNING - No threshold met precision >= 0.55 with >= 10 trades. Falling back to maximizing precision with stability constraint.
2025-12-21 10:57:49,199 - ml.src.training.sequence_evaluation - INFO - Confusion matrix@thr=0.49:
2025-12-21 10:57:49,199 - ml.src.training.sequence_evaluation - INFO -   [[TN=2, FP=25],
2025-12-21 10:57:49,200 - ml.src.training.sequence_evaluation - INFO -    [FN=0, TP=3]]
2025-12-21 10:57:49,205 - ml.src.pipelines.walk_forward_validation - INFO -   Results: WIN_RATE=10.71%, Precision=0.1071, Recall=1.0000, F1=0.1935
2025-12-21 10:57:49,205 - ml.src.pipelines.walk_forward_validation - INFO - Fold 7:
2025-12-21 10:57:49,206 - ml.src.pipelines.walk_forward_validation - INFO -   Train: [300:500] = 200 samples
2025-12-21 10:57:49,206 - ml.src.pipelines.walk_forward_validation - INFO -          2025-12-05 13:55 to 2025-12-10 19:30
2025-12-21 10:57:49,206 - ml.src.pipelines.walk_forward_validation - INFO -   Test:  [500:530] = 30 samples
2025-12-21 10:57:49,207 - ml.src.pipelines.walk_forward_validation - INFO -          2025-12-10 19:35 to 2025-12-11 08:50
2025-12-21 10:57:49,334 - ml.src.training.sequence_xgb_trainer - INFO - Class balance (train): pos=20, neg=120, imbalance_ratio=6.00
2025-12-21 10:57:49,334 - ml.src.training.sequence_xgb_trainer - INFO - Applied scale_pos_weight=6.0000 to handle class imbalance
2025-12-21 10:57:49,334 - ml.src.training.sequence_xgb_trainer - INFO - [POINT 1] Cost-Sensitive Learning: using sample weights (mean=1.2857)
2025-12-21 10:57:49,335 - ml.src.training.sequence_xgb_trainer - INFO - Training XGBoost classifier...
2025-12-21 10:57:49,635 - ml.src.training.sequence_xgb_trainer - INFO - Training completed
2025-12-21 10:57:49,638 - ml.src.training.sequence_evaluation - INFO - Probability stats: min=0.4734, max=0.7698, mean=0.5752, std=0.0969
2025-12-21 10:57:49,643 - ml.src.training.sequence_evaluation - INFO - Using HYBRID optimization: EV with precision AND recall floors...
2025-12-21 10:57:50,023 - ml.src.training.sequence_evaluation - INFO - Hybrid-optimized threshold: 0.62 with EV=0.7143 (precision=0.6000, recall=0.8571, win_coeff=1.0, loss_coeff=-1.0)
2025-12-21 10:57:50,024 - ml.src.training.sequence_evaluation - INFO - Confusion matrix@thr=0.62:
2025-12-21 10:57:50,024 - ml.src.training.sequence_evaluation - INFO -   [[TN=19, FP=4],
2025-12-21 10:57:50,024 - ml.src.training.sequence_evaluation - INFO -    [FN=1, TP=6]]
2025-12-21 10:57:50,030 - ml.src.pipelines.walk_forward_validation - INFO -   Results: WIN_RATE=60.00%, Precision=0.6000, Recall=0.8571, F1=0.7059
2025-12-21 10:57:50,030 - ml.src.pipelines.walk_forward_validation - INFO - Fold 8:
2025-12-21 10:57:50,030 - ml.src.pipelines.walk_forward_validation - INFO -   Train: [350:550] = 200 samples
2025-12-21 10:57:50,031 - ml.src.pipelines.walk_forward_validation - INFO -          2025-12-08 14:15 to 2025-12-11 14:40
2025-12-21 10:57:50,031 - ml.src.pipelines.walk_forward_validation - INFO -   Test:  [550:580] = 30 samples
2025-12-21 10:57:50,031 - ml.src.pipelines.walk_forward_validation - INFO -          2025-12-11 14:45 to 2025-12-11 17:10
2025-12-21 10:57:50,153 - ml.src.training.sequence_xgb_trainer - INFO - Class balance (train): pos=21, neg=119, imbalance_ratio=5.67
2025-12-21 10:57:50,154 - ml.src.training.sequence_xgb_trainer - INFO - Applied scale_pos_weight=5.6667 to handle class imbalance
2025-12-21 10:57:50,154 - ml.src.training.sequence_xgb_trainer - INFO - [POINT 1] Cost-Sensitive Learning: using sample weights (mean=1.3000)
2025-12-21 10:57:50,154 - ml.src.training.sequence_xgb_trainer - INFO - Training XGBoost classifier...
2025-12-21 10:57:50,427 - ml.src.training.sequence_xgb_trainer - INFO - Training completed
2025-12-21 10:57:50,430 - ml.src.training.sequence_evaluation - INFO - Probability stats: min=0.4103, max=0.4648, mean=0.4251, std=0.0183
2025-12-21 10:57:50,432 - ml.src.training.sequence_evaluation - INFO - Using HYBRID optimization: EV with precision AND recall floors...
2025-12-21 10:57:50,687 - ml.src.training.sequence_evaluation - INFO - Hybrid-optimized threshold: 0.10 with EV=1.0000 (precision=0.7333, recall=1.0000, win_coeff=1.0, loss_coeff=-1.0)
2025-12-21 10:57:50,688 - ml.src.training.sequence_evaluation - INFO - Confusion matrix@thr=0.10:
2025-12-21 10:57:50,688 - ml.src.training.sequence_evaluation - INFO -   [[TN=0, FP=8],
2025-12-21 10:57:50,688 - ml.src.training.sequence_evaluation - INFO -    [FN=0, TP=22]]
2025-12-21 10:57:50,694 - ml.src.pipelines.walk_forward_validation - INFO -   Results: WIN_RATE=73.33%, Precision=0.7333, Recall=1.0000, F1=0.8462
2025-12-21 10:57:50,694 - ml.src.pipelines.walk_forward_validation - INFO - Fold 9:
2025-12-21 10:57:50,695 - ml.src.pipelines.walk_forward_validation - INFO -   Train: [400:600] = 200 samples
2025-12-21 10:57:50,695 - ml.src.pipelines.walk_forward_validation - INFO -          2025-12-09 13:35 to 2025-12-11 18:50
2025-12-21 10:57:50,695 - ml.src.pipelines.walk_forward_validation - INFO -   Test:  [600:630] = 30 samples
2025-12-21 10:57:50,696 - ml.src.pipelines.walk_forward_validation - INFO -          2025-12-11 18:55 to 2025-12-11 21:20
2025-12-21 10:57:50,823 - ml.src.training.sequence_xgb_trainer - INFO - Class balance (train): pos=22, neg=118, imbalance_ratio=5.36
2025-12-21 10:57:50,823 - ml.src.training.sequence_xgb_trainer - INFO - Applied scale_pos_weight=5.3636 to handle class imbalance
2025-12-21 10:57:50,824 - ml.src.training.sequence_xgb_trainer - INFO - [POINT 1] Cost-Sensitive Learning: using sample weights (mean=1.3143)
2025-12-21 10:57:50,824 - ml.src.training.sequence_xgb_trainer - INFO - Training XGBoost classifier...
2025-12-21 10:57:51,147 - ml.src.training.sequence_xgb_trainer - INFO - Training completed
2025-12-21 10:57:51,149 - ml.src.training.sequence_evaluation - INFO - Probability stats: min=0.4171, max=0.5363, mean=0.4755, std=0.0326
2025-12-21 10:57:51,154 - ml.src.training.sequence_evaluation - INFO - Using HYBRID optimization: EV with precision AND recall floors...
2025-12-21 10:57:51,451 - ml.src.training.sequence_evaluation - WARNING - No threshold met BOTH precision >= 0.55 AND recall >= 0.20 with >= 10 trades. Falling back to F1-optimized with precision floor.
2025-12-21 10:57:51,554 - ml.src.training.sequence_evaluation - WARNING - No threshold met precision >= 0.55 with >= 10 trades. Falling back to maximizing precision with stability constraint.
2025-12-21 10:57:51,753 - ml.src.training.sequence_evaluation - INFO - Confusion matrix@thr=0.47:
2025-12-21 10:57:51,754 - ml.src.training.sequence_evaluation - INFO -   [[TN=9, FP=13],
2025-12-21 10:57:51,754 - ml.src.training.sequence_evaluation - INFO -    [FN=1, TP=7]]
2025-12-21 10:57:51,760 - ml.src.pipelines.walk_forward_validation - INFO -   Results: WIN_RATE=35.00%, Precision=0.3500, Recall=0.8750, F1=0.5000
2025-12-21 10:57:51,760 - ml.src.pipelines.walk_forward_validation - INFO - Fold 10:
2025-12-21 10:57:51,760 - ml.src.pipelines.walk_forward_validation - INFO -   Train: [450:650] = 200 samples
2025-12-21 10:57:51,761 - ml.src.pipelines.walk_forward_validation - INFO -          2025-12-09 18:40 to 2025-12-12 09:00
2025-12-21 10:57:51,761 - ml.src.pipelines.walk_forward_validation - INFO -   Test:  [650:680] = 30 samples
2025-12-21 10:57:51,762 - ml.src.pipelines.walk_forward_validation - INFO -          2025-12-12 09:05 to 2025-12-12 11:30
2025-12-21 10:57:51,897 - ml.src.training.sequence_xgb_trainer - INFO - Class balance (train): pos=42, neg=98, imbalance_ratio=2.33
2025-12-21 10:57:51,897 - ml.src.training.sequence_xgb_trainer - INFO - Applied scale_pos_weight=2.3333 to handle class imbalance
2025-12-21 10:57:51,897 - ml.src.training.sequence_xgb_trainer - INFO - [POINT 1] Cost-Sensitive Learning: using sample weights (mean=1.6000)
2025-12-21 10:57:51,898 - ml.src.training.sequence_xgb_trainer - INFO - Training XGBoost classifier...
2025-12-21 10:57:52,251 - ml.src.training.sequence_xgb_trainer - INFO - Training completed
2025-12-21 10:57:52,254 - ml.src.training.sequence_evaluation - INFO - Probability stats: min=0.4180, max=0.6786, mean=0.5163, std=0.0664
2025-12-21 10:57:52,259 - ml.src.training.sequence_evaluation - INFO - Using HYBRID optimization: EV with precision AND recall floors...
2025-12-21 10:57:52,580 - ml.src.training.sequence_evaluation - INFO - Hybrid-optimized threshold: 0.47 with EV=0.5385 (precision=0.5556, recall=0.7692, win_coeff=1.0, loss_coeff=-1.0)
2025-12-21 10:57:52,581 - ml.src.training.sequence_evaluation - INFO - Confusion matrix@thr=0.47:
2025-12-21 10:57:52,581 - ml.src.training.sequence_evaluation - INFO -   [[TN=9, FP=8],
2025-12-21 10:57:52,581 - ml.src.training.sequence_evaluation - INFO -    [FN=3, TP=10]]
2025-12-21 10:57:52,587 - ml.src.pipelines.walk_forward_validation - INFO -   Results: WIN_RATE=55.56%, Precision=0.5556, Recall=0.7692, F1=0.6452
2025-12-21 10:57:52,587 - ml.src.pipelines.walk_forward_validation - INFO - Fold 11:
2025-12-21 10:57:52,587 - ml.src.pipelines.walk_forward_validation - INFO -   Train: [500:700] = 200 samples
2025-12-21 10:57:52,588 - ml.src.pipelines.walk_forward_validation - INFO -          2025-12-10 19:35 to 2025-12-12 13:10
2025-12-21 10:57:52,588 - ml.src.pipelines.walk_forward_validation - INFO -   Test:  [700:730] = 30 samples
2025-12-21 10:57:52,589 - ml.src.pipelines.walk_forward_validation - INFO -          2025-12-12 13:15 to 2025-12-15 08:20
2025-12-21 10:57:52,712 - ml.src.training.sequence_xgb_trainer - INFO - Class balance (train): pos=48, neg=92, imbalance_ratio=1.92
2025-12-21 10:57:52,713 - ml.src.training.sequence_xgb_trainer - INFO - Applied scale_pos_weight=1.9167 to handle class imbalance
2025-12-21 10:57:52,713 - ml.src.training.sequence_xgb_trainer - INFO - [POINT 1] Cost-Sensitive Learning: using sample weights (mean=1.6857)
2025-12-21 10:57:52,713 - ml.src.training.sequence_xgb_trainer - INFO - Training XGBoost classifier...
2025-12-21 10:57:53,070 - ml.src.training.sequence_xgb_trainer - INFO - Training completed
2025-12-21 10:57:53,072 - ml.src.training.sequence_evaluation - INFO - Probability stats: min=0.4625, max=0.7413, mean=0.6429, std=0.0777
2025-12-21 10:57:53,077 - ml.src.training.sequence_evaluation - INFO - Using HYBRID optimization: EV with precision AND recall floors...
2025-12-21 10:57:53,500 - ml.src.training.sequence_evaluation - WARNING - No threshold met BOTH precision >= 0.55 AND recall >= 0.20 with >= 10 trades. Falling back to F1-optimized with precision floor.
2025-12-21 10:57:53,664 - ml.src.training.sequence_evaluation - WARNING - No threshold met precision >= 0.55 with >= 10 trades. Falling back to maximizing precision with stability constraint.
2025-12-21 10:57:53,994 - ml.src.training.sequence_evaluation - INFO - Confusion matrix@thr=0.66:
2025-12-21 10:57:53,994 - ml.src.training.sequence_evaluation - INFO -   [[TN=14, FP=13],
2025-12-21 10:57:53,994 - ml.src.training.sequence_evaluation - INFO -    [FN=1, TP=2]]
2025-12-21 10:57:54,000 - ml.src.pipelines.walk_forward_validation - INFO -   Results: WIN_RATE=13.33%, Precision=0.1333, Recall=0.6667, F1=0.2222
2025-12-21 10:57:54,000 - ml.src.pipelines.walk_forward_validation - INFO - Fold 12:
2025-12-21 10:57:54,000 - ml.src.pipelines.walk_forward_validation - INFO -   Train: [550:750] = 200 samples
2025-12-21 10:57:54,001 - ml.src.pipelines.walk_forward_validation - INFO -          2025-12-11 14:45 to 2025-12-15 10:00
2025-12-21 10:57:54,001 - ml.src.pipelines.walk_forward_validation - INFO -   Test:  [750:780] = 30 samples
2025-12-21 10:57:54,002 - ml.src.pipelines.walk_forward_validation - INFO -          2025-12-15 10:05 to 2025-12-15 12:30
2025-12-21 10:57:54,129 - ml.src.training.sequence_xgb_trainer - INFO - Class balance (train): pos=55, neg=85, imbalance_ratio=1.55
2025-12-21 10:57:54,129 - ml.src.training.sequence_xgb_trainer - INFO - Applied scale_pos_weight=1.5455 to handle class imbalance
2025-12-21 10:57:54,129 - ml.src.training.sequence_xgb_trainer - INFO - [POINT 1] Cost-Sensitive Learning: using sample weights (mean=1.7857)
2025-12-21 10:57:54,130 - ml.src.training.sequence_xgb_trainer - INFO - Training XGBoost classifier...
2025-12-21 10:57:54,465 - ml.src.training.sequence_xgb_trainer - INFO - Training completed
2025-12-21 10:57:54,467 - ml.src.training.sequence_evaluation - INFO - Probability stats: min=0.7262, max=0.8317, mean=0.7789, std=0.0307
2025-12-21 10:57:54,472 - ml.src.training.sequence_evaluation - INFO - Using HYBRID optimization: EV with precision AND recall floors...
2025-12-21 10:57:54,966 - ml.src.training.sequence_evaluation - WARNING - No threshold met BOTH precision >= 0.55 AND recall >= 0.20 with >= 10 trades. Falling back to F1-optimized with precision floor.
2025-12-21 10:57:55,174 - ml.src.training.sequence_evaluation - WARNING - No threshold met precision >= 0.55 with >= 10 trades. Falling back to maximizing precision with stability constraint.
2025-12-21 10:57:55,568 - ml.src.training.sequence_evaluation - INFO - Confusion matrix@thr=0.79:
2025-12-21 10:57:55,568 - ml.src.training.sequence_evaluation - INFO -   [[TN=19, FP=6],
2025-12-21 10:57:55,568 - ml.src.training.sequence_evaluation - INFO -    [FN=1, TP=4]]
2025-12-21 10:57:55,573 - ml.src.pipelines.walk_forward_validation - INFO -   Results: WIN_RATE=40.00%, Precision=0.4000, Recall=0.8000, F1=0.5333
2025-12-21 10:57:55,574 - ml.src.pipelines.walk_forward_validation - INFO - Fold 13:
2025-12-21 10:57:55,574 - ml.src.pipelines.walk_forward_validation - INFO -   Train: [600:800] = 200 samples
2025-12-21 10:57:55,575 - ml.src.pipelines.walk_forward_validation - INFO -          2025-12-11 18:55 to 2025-12-15 14:10
2025-12-21 10:57:55,575 - ml.src.pipelines.walk_forward_validation - INFO -   Test:  [800:830] = 30 samples
2025-12-21 10:57:55,575 - ml.src.pipelines.walk_forward_validation - INFO -          2025-12-15 14:35 to 2025-12-16 15:20
2025-12-21 10:57:55,701 - ml.src.training.sequence_xgb_trainer - INFO - Class balance (train): pos=40, neg=100, imbalance_ratio=2.50
2025-12-21 10:57:55,702 - ml.src.training.sequence_xgb_trainer - INFO - Applied scale_pos_weight=2.5000 to handle class imbalance
2025-12-21 10:57:55,702 - ml.src.training.sequence_xgb_trainer - INFO - [POINT 1] Cost-Sensitive Learning: using sample weights (mean=1.5714)
2025-12-21 10:57:55,702 - ml.src.training.sequence_xgb_trainer - INFO - Training XGBoost classifier...
2025-12-21 10:57:56,091 - ml.src.training.sequence_xgb_trainer - INFO - Training completed
2025-12-21 10:57:56,094 - ml.src.training.sequence_evaluation - INFO - Probability stats: min=0.4789, max=0.7271, mean=0.6333, std=0.0613
2025-12-21 10:57:56,097 - ml.src.training.sequence_evaluation - WARNING - [WARNING] Model has very low discriminative power (ROC-AUC=0.2176). Results may be random.
2025-12-21 10:57:56,099 - ml.src.training.sequence_evaluation - INFO - Using HYBRID optimization: EV with precision AND recall floors...
2025-12-21 10:57:56,499 - ml.src.training.sequence_evaluation - WARNING - No threshold met BOTH precision >= 0.55 AND recall >= 0.20 with >= 10 trades. Falling back to F1-optimized with precision floor.
2025-12-21 10:57:56,659 - ml.src.training.sequence_evaluation - WARNING - No threshold met precision >= 0.55 with >= 10 trades. Falling back to maximizing precision with stability constraint.
2025-12-21 10:57:56,969 - ml.src.training.sequence_evaluation - INFO - Confusion matrix@thr=0.20:
2025-12-21 10:57:56,970 - ml.src.training.sequence_evaluation - INFO -   [[TN=0, FP=18],
2025-12-21 10:57:56,970 - ml.src.training.sequence_evaluation - INFO -    [FN=0, TP=12]]
2025-12-21 10:57:56,975 - ml.src.pipelines.walk_forward_validation - INFO -   Results: WIN_RATE=40.00%, Precision=0.4000, Recall=1.0000, F1=0.5714
2025-12-21 10:57:56,976 - ml.src.pipelines.walk_forward_validation - INFO - Fold 14:
2025-12-21 10:57:56,976 - ml.src.pipelines.walk_forward_validation - INFO -   Train: [650:850] = 200 samples
2025-12-21 10:57:56,977 - ml.src.pipelines.walk_forward_validation - INFO -          2025-12-12 09:05 to 2025-12-16 17:05
2025-12-21 10:57:56,977 - ml.src.pipelines.walk_forward_validation - INFO -   Test:  [850:880] = 30 samples
2025-12-21 10:57:56,978 - ml.src.pipelines.walk_forward_validation - INFO -          2025-12-16 17:10 to 2025-12-16 20:00
2025-12-21 10:57:57,111 - ml.src.training.sequence_xgb_trainer - INFO - Class balance (train): pos=25, neg=115, imbalance_ratio=4.60
2025-12-21 10:57:57,112 - ml.src.training.sequence_xgb_trainer - INFO - Applied scale_pos_weight=4.6000 to handle class imbalance
2025-12-21 10:57:57,112 - ml.src.training.sequence_xgb_trainer - INFO - [POINT 1] Cost-Sensitive Learning: using sample weights (mean=1.3571)
2025-12-21 10:57:57,112 - ml.src.training.sequence_xgb_trainer - INFO - Training XGBoost classifier...
2025-12-21 10:57:57,422 - ml.src.training.sequence_xgb_trainer - INFO - Training completed
2025-12-21 10:57:57,424 - ml.src.training.sequence_evaluation - INFO - Probability stats: min=0.5466, max=0.6701, mean=0.5949, std=0.0341
2025-12-21 10:57:57,429 - ml.src.training.sequence_evaluation - INFO - Using HYBRID optimization: EV with precision AND recall floors...
2025-12-21 10:57:57,800 - ml.src.training.sequence_evaluation - WARNING - No threshold met BOTH precision >= 0.55 AND recall >= 0.20 with >= 10 trades. Falling back to F1-optimized with precision floor.
2025-12-21 10:57:57,940 - ml.src.training.sequence_evaluation - WARNING - No threshold met precision >= 0.55 with >= 10 trades. Falling back to maximizing precision with stability constraint.
2025-12-21 10:57:58,210 - ml.src.training.sequence_evaluation - INFO - Confusion matrix@thr=0.59:
2025-12-21 10:57:58,210 - ml.src.training.sequence_evaluation - INFO -   [[TN=18, FP=11],
2025-12-21 10:57:58,210 - ml.src.training.sequence_evaluation - INFO -    [FN=0, TP=1]]
2025-12-21 10:57:58,216 - ml.src.pipelines.walk_forward_validation - INFO -   Results: WIN_RATE=8.33%, Precision=0.0833, Recall=1.0000, F1=0.1538
2025-12-21 10:57:58,216 - ml.src.pipelines.walk_forward_validation - INFO - Fold 15:
2025-12-21 10:57:58,216 - ml.src.pipelines.walk_forward_validation - INFO -   Train: [700:900] = 200 samples
2025-12-21 10:57:58,217 - ml.src.pipelines.walk_forward_validation - INFO -          2025-12-12 13:15 to 2025-12-16 21:40
2025-12-21 10:57:58,217 - ml.src.pipelines.walk_forward_validation - INFO -   Test:  [900:930] = 30 samples
2025-12-21 10:57:58,217 - ml.src.pipelines.walk_forward_validation - INFO -          2025-12-16 21:45 to 2025-12-17 10:45
2025-12-21 10:57:58,345 - ml.src.training.sequence_xgb_trainer - INFO - Class balance (train): pos=20, neg=120, imbalance_ratio=6.00
2025-12-21 10:57:58,346 - ml.src.training.sequence_xgb_trainer - INFO - Applied scale_pos_weight=6.0000 to handle class imbalance
2025-12-21 10:57:58,346 - ml.src.training.sequence_xgb_trainer - INFO - [POINT 1] Cost-Sensitive Learning: using sample weights (mean=1.2857)
2025-12-21 10:57:58,346 - ml.src.training.sequence_xgb_trainer - INFO - Training XGBoost classifier...
2025-12-21 10:57:58,666 - ml.src.training.sequence_xgb_trainer - INFO - Training completed
2025-12-21 10:57:58,668 - ml.src.training.sequence_evaluation - INFO - Probability stats: min=0.4247, max=0.6017, mean=0.5249, std=0.0448
2025-12-21 10:57:58,673 - ml.src.training.sequence_evaluation - INFO - Using HYBRID optimization: EV with precision AND recall floors...
2025-12-21 10:57:59,006 - ml.src.training.sequence_evaluation - WARNING - No threshold met BOTH precision >= 0.55 AND recall >= 0.20 with >= 10 trades. Falling back to F1-optimized with precision floor.
2025-12-21 10:57:59,125 - ml.src.training.sequence_evaluation - WARNING - No threshold met precision >= 0.55 with >= 10 trades. Falling back to maximizing precision with stability constraint.
2025-12-21 10:57:59,360 - ml.src.training.sequence_evaluation - INFO - Confusion matrix@thr=0.54:
2025-12-21 10:57:59,360 - ml.src.training.sequence_evaluation - INFO -   [[TN=16, FP=10],
2025-12-21 10:57:59,361 - ml.src.training.sequence_evaluation - INFO -    [FN=0, TP=4]]
2025-12-21 10:57:59,366 - ml.src.pipelines.walk_forward_validation - INFO -   Results: WIN_RATE=28.57%, Precision=0.2857, Recall=1.0000, F1=0.4444
2025-12-21 10:57:59,367 - ml.src.pipelines.walk_forward_validation - INFO - Fold 16:
2025-12-21 10:57:59,367 - ml.src.pipelines.walk_forward_validation - INFO -   Train: [750:950] = 200 samples
2025-12-21 10:57:59,367 - ml.src.pipelines.walk_forward_validation - INFO -          2025-12-15 10:05 to 2025-12-17 13:20
2025-12-21 10:57:59,368 - ml.src.pipelines.walk_forward_validation - INFO -   Test:  [950:980] = 30 samples
2025-12-21 10:57:59,368 - ml.src.pipelines.walk_forward_validation - INFO -          2025-12-17 13:25 to 2025-12-17 16:30
2025-12-21 10:57:59,494 - ml.src.training.sequence_xgb_trainer - INFO - Class balance (train): pos=19, neg=121, imbalance_ratio=6.37
2025-12-21 10:57:59,494 - ml.src.training.sequence_xgb_trainer - INFO - Applied scale_pos_weight=6.3684 to handle class imbalance
2025-12-21 10:57:59,495 - ml.src.training.sequence_xgb_trainer - INFO - [POINT 1] Cost-Sensitive Learning: using sample weights (mean=1.2714)
2025-12-21 10:57:59,495 - ml.src.training.sequence_xgb_trainer - INFO - Training XGBoost classifier...
2025-12-21 10:57:59,775 - ml.src.training.sequence_xgb_trainer - INFO - Training completed
2025-12-21 10:57:59,778 - ml.src.training.sequence_evaluation - INFO - Probability stats: min=0.4337, max=0.8061, mean=0.6286, std=0.1037
2025-12-21 10:57:59,784 - ml.src.training.sequence_evaluation - INFO - Using HYBRID optimization: EV with precision AND recall floors...
2025-12-21 10:58:00,222 - ml.src.training.sequence_evaluation - WARNING - No threshold met BOTH precision >= 0.55 AND recall >= 0.20 with >= 10 trades. Falling back to F1-optimized with precision floor.
2025-12-21 10:58:00,385 - ml.src.training.sequence_evaluation - WARNING - No threshold met precision >= 0.55 with >= 10 trades. Falling back to maximizing precision with stability constraint.
2025-12-21 10:58:00,712 - ml.src.training.sequence_evaluation - INFO - Confusion matrix@thr=0.65:
2025-12-21 10:58:00,713 - ml.src.training.sequence_evaluation - INFO -   [[TN=15, FP=9],
2025-12-21 10:58:00,713 - ml.src.training.sequence_evaluation - INFO -    [FN=1, TP=5]]
2025-12-21 10:58:00,718 - ml.src.pipelines.walk_forward_validation - INFO -   Results: WIN_RATE=35.71%, Precision=0.3571, Recall=0.8333, F1=0.5000
2025-12-21 10:58:00,718 - ml.src.pipelines.walk_forward_validation - INFO - Fold 17:
2025-12-21 10:58:00,719 - ml.src.pipelines.walk_forward_validation - INFO -   Train: [800:1,000] = 200 samples
2025-12-21 10:58:00,719 - ml.src.pipelines.walk_forward_validation - INFO -          2025-12-15 14:35 to 2025-12-17 18:10
2025-12-21 10:58:00,719 - ml.src.pipelines.walk_forward_validation - INFO -   Test:  [1,000:1,030] = 30 samples
2025-12-21 10:58:00,720 - ml.src.pipelines.walk_forward_validation - INFO -          2025-12-17 18:15 to 2025-12-17 21:10
2025-12-21 10:58:00,846 - ml.src.training.sequence_xgb_trainer - INFO - Class balance (train): pos=30, neg=110, imbalance_ratio=3.67
2025-12-21 10:58:00,846 - ml.src.training.sequence_xgb_trainer - INFO - Applied scale_pos_weight=3.6667 to handle class imbalance
2025-12-21 10:58:00,846 - ml.src.training.sequence_xgb_trainer - INFO - [POINT 1] Cost-Sensitive Learning: using sample weights (mean=1.4286)
2025-12-21 10:58:00,847 - ml.src.training.sequence_xgb_trainer - INFO - Training XGBoost classifier...
2025-12-21 10:58:01,128 - ml.src.training.sequence_xgb_trainer - INFO - Training completed
2025-12-21 10:58:01,131 - ml.src.training.sequence_evaluation - INFO - Probability stats: min=0.4073, max=0.5489, mean=0.4529, std=0.0398
2025-12-21 10:58:01,135 - ml.src.training.sequence_evaluation - WARNING - [WARNING] Model has very low discriminative power (ROC-AUC=0.4074). Results may be random.
2025-12-21 10:58:01,137 - ml.src.training.sequence_evaluation - INFO - Using HYBRID optimization: EV with precision AND recall floors...
2025-12-21 10:58:01,420 - ml.src.training.sequence_evaluation - WARNING - No threshold met BOTH precision >= 0.55 AND recall >= 0.20 with >= 10 trades. Falling back to F1-optimized with precision floor.
2025-12-21 10:58:01,518 - ml.src.training.sequence_evaluation - WARNING - No threshold met precision >= 0.55 with >= 10 trades. Falling back to maximizing precision with stability constraint.
2025-12-21 10:58:01,717 - ml.src.training.sequence_evaluation - INFO - Confusion matrix@thr=0.20:
2025-12-21 10:58:01,717 - ml.src.training.sequence_evaluation - INFO -   [[TN=0, FP=27],
2025-12-21 10:58:01,717 - ml.src.training.sequence_evaluation - INFO -    [FN=0, TP=3]]
2025-12-21 10:58:01,722 - ml.src.pipelines.walk_forward_validation - INFO -   Results: WIN_RATE=10.00%, Precision=0.1000, Recall=1.0000, F1=0.1818
2025-12-21 10:58:01,723 - ml.src.pipelines.walk_forward_validation - INFO - 
================================================================================
2025-12-21 10:58:01,723 - ml.src.pipelines.walk_forward_validation - INFO - WALK-FORWARD VALIDATION RESULTS
2025-12-21 10:58:01,723 - ml.src.pipelines.walk_forward_validation - INFO - ================================================================================
2025-12-21 10:58:01,724 - ml.src.pipelines.walk_forward_validation - INFO - 
Aggregated Results (17 folds):

2025-12-21 10:58:01,724 - ml.src.pipelines.walk_forward_validation - INFO -   WIN RATE:   33.58% ± 19.71% (range: 0.00% - 73.33%)
2025-12-21 10:58:01,725 - ml.src.pipelines.walk_forward_validation - INFO -   Precision:  0.3358 ± 0.1971 (range: 0.0000 - 0.7333)
2025-12-21 10:58:01,725 - ml.src.pipelines.walk_forward_validation - INFO -   Recall:     0.8486 ± 0.2372 (range: 0.0000 - 1.0000)
2025-12-21 10:58:01,725 - ml.src.pipelines.walk_forward_validation - INFO -   F1 Score:   0.4538 ± 0.2241
2025-12-21 10:58:01,726 - ml.src.pipelines.walk_forward_validation - INFO -   ROC-AUC:    nan ± nan
2025-12-21 10:58:01,726 - ml.src.pipelines.walk_forward_validation - INFO - 
================================================================================
2025-12-21 10:58:01,727 - __main__ - INFO - 
================================================================================
2025-12-21 10:58:01,727 - __main__ - INFO - COMPARISON: Single Split vs Walk-Forward CV
2025-12-21 10:58:01,727 - __main__ - INFO - ================================================================================
2025-12-21 10:58:01,727 - __main__ - INFO - Baseline (single 70/15/15 split):     WIN_RATE = 85.71%
2025-12-21 10:58:01,728 - __main__ - INFO - Walk-Forward CV (17 folds): WIN_RATE = 33.58% ± 19.71%
2025-12-21 10:58:01,733 - __main__ - WARNING -      This suggests model may be overfitting or trading lookahead patterns.
2025-12-21 10:58:01,734 - __main__ - WARNING -      Baseline 85.71% may NOT be reliable for live trading.
2025-12-21 10:58:01,734 - __main__ - INFO - ================================================================================
2025-12-22 12:56:52,980 - __main__ - INFO - 
================================================================================
2025-12-22 12:56:52,986 - __main__ - INFO - WALK-FORWARD VALIDATION ANALYSIS
2025-12-22 12:56:52,987 - __main__ - INFO - ================================================================================
2025-12-22 12:56:52,987 - __main__ - INFO - Years: all available
2025-12-22 12:56:52,987 - __main__ - INFO - Train window: 500 samples (~2500 minutes)
2025-12-22 12:56:52,988 - __main__ - INFO - Test window: 100 samples (~500 minutes)
2025-12-22 12:56:52,988 - __main__ - INFO - Step size: 50 samples (~250 minutes)
2025-12-22 12:56:52,988 - __main__ - INFO - ================================================================================

2025-12-22 12:56:52,988 - __main__ - INFO - Loading data...
2025-12-22 12:57:05,068 - __main__ - INFO - Loaded 6,529,676 M1 candles
2025-12-22 12:57:05,068 - __main__ - INFO - Aggregating to M5...
2025-12-22 12:57:05,069 - ml.src.features.engineer_m5 - INFO - Aggregating 6529676 M1 candles to M5...
